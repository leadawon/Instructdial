{"input": "[CONTEXT] never staying at @daysinn again they took half hour just just get us in a room then double booked our room and very dusty [RESPONSE] hi <USER> we 'd like to look into this for you , if you could contact our customer care team on <E-MAIL> thanks [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response contextual? ", "index": 33908, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: In this task you will be shown a context followed by a response. You need to classify if the response is a good response to the context. \nInput: [CONTEXT] never staying at @daysinn again they took half hour just just get us in a room then double booked our room and very dusty [RESPONSE] hi <USER> we 'd like to look into this for you , if you could contact our customer care team on <E-MAIL> thanks [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response contextual? ", "output": "yes", "all_outputs": ["yes"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["never staying at @daysinn again they took half hour just just get us in a room then double booked our room and very dusty"], "response_list": ["hi <USER> we 'd like to look into this for you , if you could contact our customer care team on <E-MAIL> thanks"], "metric_score": [{"USR-MLM": -3.144531488418579}]}
{"input": "[CONTEXT] hi , how are you doing ? doing good . just strumming my guitar . how about you ? i am fine , i was watching a cooking show , i like those do you like cooking or baking ? or both ? neither , i just like to eat . for example i like hummus my go to snack is chocolate bars me too ! i am vegan but still love chocolate what other hobbies do you have ? i play violin and guitar i like extreme sensations , like sky diving and rollercoasters yikes i hate roller coasters . they are so scary . i am afraid of water , i am not good at swimming what do you do for work ? i am an electrician just like my dad . i like electricity and electronics . i'm a bartender [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 0 to 5 about the uses knowledge to the following response: i wish i could make fancy cocktails ! my secret talent is that i can speak chinese !", "index": 29781, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Given a conversation, a response to the conversation, and a score range, return a rating to the response within in score range\nInput: [CONTEXT] hi , how are you doing ? doing good . just strumming my guitar . how about you ? i am fine , i was watching a cooking show , i like those do you like cooking or baking ? or both ? neither , i just like to eat . for example i like hummus my go to snack is chocolate bars me too ! i am vegan but still love chocolate what other hobbies do you have ? i play violin and guitar i like extreme sensations , like sky diving and rollercoasters yikes i hate roller coasters . they are so scary . i am afraid of water , i am not good at swimming what do you do for work ? i am an electrician just like my dad . i like electricity and electronics . i'm a bartender [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 0 to 5 about the uses knowledge to the following response: i wish i could make fancy cocktails ! my secret talent is that i can speak chinese !", "output": "not very good at it, i know very little about it", "all_outputs": ["1.0"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] til actors played brother sister on\" dexter\" began dating , fell love , got engaged , got married , got divorced , continuing play brother sister tv. [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the relevance to the following response: i m not sure if that s the case.", "index": 34684, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Given a conversation, a response to the conversation, and a score range, return a rating to the response within in score range\nInput: [CONTEXT] til actors played brother sister on\" dexter\" began dating , fell love , got engaged , got married , got divorced , continuing play brother sister tv. [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the relevance to the following response: i m not sure if that s the case.", "output": "doesnt a little girl play the role of sister?", "all_outputs": ["3.0"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] til infinity sign also called the\" lemniscate\" [RESPONSE] is the best. [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response a good response to the provided dialogue context? ", "index": 45080, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: In this task you will be shown a context followed by a response. You need to classify if the response is a good response to the context. \nInput: [CONTEXT] til infinity sign also called the\" lemniscate\" [RESPONSE] is the best. [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response a good response to the provided dialogue context? ", "output": "no", "all_outputs": ["yes"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["til infinity sign also called the\" lemniscate\""], "response_list": ["is the best."], "metric_score": [{"USR-MLM": -3.9681155681610107}]}
{"input": "[CONTEXT] til ancient greek philosopher jumped active volcano prove immortal god [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: hi !||||B: please can you follow us and dm your full address and best contact number and a member of the team will be in touch||||C: it's not even rocket tradition.||||D: i think he was a dick. [QUESTION] The most appropriate response to the conversation is ", "index": 22089, "split": "train", "classes_in_options": ["A", "B", "C", "D"], "candidates": ["hi !", "please can you follow us and dm your full address and best contact number and a member of the team will be in touch", "it's not even rocket tradition.", "i think he was a dick."], "dataset": "eval", "task": "eval_ranking", "prompt": "Instruction: Select the best response from the provided responses to a conversation\nInput: [CONTEXT] til ancient greek philosopher jumped active volcano prove immortal god [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: hi !||||B: please can you follow us and dm your full address and best contact number and a member of the team will be in touch||||C: it's not even rocket tradition.||||D: i think he was a dick. [QUESTION] The most appropriate response to the conversation is ", "output": "C", "all_outputs": ["D"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["til ancient greek philosopher jumped active volcano prove immortal god"], "response_list": ["hi !", "please can you follow us and dm your full address and best contact number and a member of the team will be in touch", "it's not even rocket tradition.", "i think he was a dick."], "metric_score": [{"USR-MLM": -4.454026222229004}, {"USR-MLM": -3.8257362842559814}, {"USR-MLM": -4.647776126861572}, {"USR-MLM": -4.020401477813721}]}
{"input": "[CONTEXT] hi ! i don't like the color orange . hello . i like to shoot hoops , so orange balls are good with me . that's amazing . i like dancing on weekends . you ? right now i am applying for jobs , i want to work in a restaurant . that is amazing . good luck . i do not like fashion though . i get you , my favorite rapper is pretty stylish , travis scott . i totally like travis . i liked doing chemistry too awesome . my mom wanted to be a chemist , but ended up a dentist ! go figure ! it seems to be hard to be a chemist . what do you do ? unemployed at the moment , i really want to work at a snazzy restaurant . you will get it . do not worry . i now work in a nice bookstore . [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 0 to 5 about the uses knowledge to the following response: i am looking for a job at a restaurant .", "index": 22864, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Given a conversation, a response to the conversation, and a score range, return a rating to the response within in score range\nInput: [CONTEXT] hi ! i don't like the color orange . hello . i like to shoot hoops , so orange balls are good with me . that's amazing . i like dancing on weekends . you ? right now i am applying for jobs , i want to work in a restaurant . that is amazing . good luck . i do not like fashion though . i get you , my favorite rapper is pretty stylish , travis scott . i totally like travis . i liked doing chemistry too awesome . my mom wanted to be a chemist , but ended up a dentist ! go figure ! it seems to be hard to be a chemist . what do you do ? unemployed at the moment , i really want to work at a snazzy restaurant . you will get it . do not worry . i now work in a nice bookstore . [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 0 to 5 about the uses knowledge to the following response: i am looking for a job at a restaurant .", "output": "what do you do?", "all_outputs": ["1.0"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] than perhaps grandfathering your customers so they can keep their existing plan with lte would be great \ud83d\udc4c we hear you , <USER> . we are in the process of collecting any and all feedback since monday 's launch to share with our mktg team . i like that your plans fit into my very tight budget . patiently waiting for better service and faster speeds . reward loyalty ! [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: let us partner you with our verizon wireless team @vzwsupport . we will get this over to them for you .", "index": 26665, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Given a conversation, a response to the conversation, and a score range, return a rating to the response within in score range\nInput: [CONTEXT] than perhaps grandfathering your customers so they can keep their existing plan with lte would be great \ud83d\udc4c we hear you , <USER> . we are in the process of collecting any and all feedback since monday 's launch to share with our mktg team . i like that your plans fit into my very tight budget . patiently waiting for better service and faster speeds . reward loyalty ! [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: let us partner you with our verizon wireless team @vzwsupport . we will get this over to them for you .", "output": "the 2 needs to improve", "all_outputs": ["3.1"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] til 1995 visit washington d. c. , russian president boris yeltsin found pennsylvania avenue , drunk , underwear trying hail cab order find pizza. [ENDOFTURN] aka american dream. [ENDOFTURN] boris politics anyway? true rock star story. thing missing mick jagger couple hookers. [RESPONSE] that's the best movie ever. [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Select the right option: is the response is a good follow-up response? ", "index": 49999, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: In this task you will be shown a context followed by a response. You need to classify if the response is a good response to the context. \nInput: [CONTEXT] til 1995 visit washington d. c. , russian president boris yeltsin found pennsylvania avenue , drunk , underwear trying hail cab order find pizza. [ENDOFTURN] aka american dream. [ENDOFTURN] boris politics anyway? true rock star story. thing missing mick jagger couple hookers. [RESPONSE] that's the best movie ever. [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Select the right option: is the response is a good follow-up response? ", "output": "no", "all_outputs": ["no"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["til 1995 visit washington d. c. , russian president boris yeltsin found pennsylvania avenue , drunk , underwear trying hail cab order find pizza.", "aka american dream.", "boris politics anyway? true rock star story. thing missing mick jagger couple hookers."], "response_list": ["that's the best movie ever."], "metric_score": [{"USR-MLM": -4.054403781890869}]}
{"input": "[CONTEXT] til yreka , california , bakery operated 100 years called yreka bakery , formed palindrome. business closed gallery opened spot , named yrella gallery would also form palindrome. [ENDOFTURN] cool see hometown reddit! glad know forgotten smirk_face [ENDOFTURN] hey fellow yrekian! [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: hi <USER> , please dm us your contact details and we will be in touch to assist . thanks .||||B: hi , <USER> . we 're sorry to hear that . please dm us your mobile number so we can look into this for you . thank you .||||C: we 're sorry to hear that , <USER> . please dm us more info so we can take a closer look into your concerns . <URL>||||D: i grew up in yreka. does that count enough to join in? still have fond memories fishing in the klamath river. [QUESTION] The most appropriate response to the conversation is ", "index": 17175, "split": "train", "classes_in_options": ["A", "B", "C", "D"], "candidates": ["hi <USER> , please dm us your contact details and we will be in touch to assist . thanks .", "hi , <USER> . we 're sorry to hear that . please dm us your mobile number so we can look into this for you . thank you .", "we 're sorry to hear that , <USER> . please dm us more info so we can take a closer look into your concerns . <URL>", "i grew up in yreka. does that count enough to join in? still have fond memories fishing in the klamath river."], "dataset": "eval", "task": "eval_ranking", "prompt": "Instruction: Given a conversation and some responses to the conversation, select the most appropriate response \nInput: [CONTEXT] til yreka , california , bakery operated 100 years called yreka bakery , formed palindrome. business closed gallery opened spot , named yrella gallery would also form palindrome. [ENDOFTURN] cool see hometown reddit! glad know forgotten smirk_face [ENDOFTURN] hey fellow yrekian! [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: hi <USER> , please dm us your contact details and we will be in touch to assist . thanks .||||B: hi , <USER> . we 're sorry to hear that . please dm us your mobile number so we can look into this for you . thank you .||||C: we 're sorry to hear that , <USER> . please dm us more info so we can take a closer look into your concerns . <URL>||||D: i grew up in yreka. does that count enough to join in? still have fond memories fishing in the klamath river. [QUESTION] The most appropriate response to the conversation is ", "output": "D", "all_outputs": ["D"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["til yreka , california , bakery operated 100 years called yreka bakery , formed palindrome. business closed gallery opened spot , named yrella gallery would also form palindrome.", "cool see hometown reddit! glad know forgotten smirk_face", "hey fellow yrekian!"], "response_list": ["hi <USER> , please dm us your contact details and we will be in touch to assist . thanks .", "hi , <USER> . we 're sorry to hear that . please dm us your mobile number so we can look into this for you . thank you .", "we 're sorry to hear that , <USER> . please dm us more info so we can take a closer look into your concerns . <URL>", "i grew up in yreka. does that count enough to join in? still have fond memories fishing in the klamath river."], "metric_score": [{"USR-MLM": -4.013903617858887}, {"USR-MLM": -3.6552295684814453}, {"USR-MLM": -3.5788350105285645}, {"USR-MLM": -3.689605951309204}]}
{"input": "[CONTEXT] order didn 't recognize promo code that was provided because of another problem . #fail [RESPONSE] we regret to hear this . can you share the property irregularity report ( pir ) number via direct message so we can assist you ? [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response a good response to the provided dialogue context? ", "index": 4323, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: Given a conversation and a response to the conversation, select is the response is a good response to the context.\nInput: [CONTEXT] order didn 't recognize promo code that was provided because of another problem . #fail [RESPONSE] we regret to hear this . can you share the property irregularity report ( pir ) number via direct message so we can assist you ? [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response a good response to the provided dialogue context? ", "output": "no", "all_outputs": ["no"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["order didn 't recognize promo code that was provided because of another problem . #fail"], "response_list": ["we regret to hear this . can you share the property irregularity report ( pir ) number via direct message so we can assist you ?"], "metric_score": [{"USR-MLM": -2.7286410331726074}]}
{"input": "[CONTEXT] til sean bean scared helicopter flying preferred hike miles mountain full costume film lord rings scenes method acting. helicopters middle earth. really got character. lot work die 1st movie trilogy. people love kill sean bean .. like , thing. [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the informativeness to the following response: i love that the first memory i have of him is being killed in the opening of \\*goldeneye\\*", "index": 12894, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: In this task you will be shown a conversation followed by a response and score range. You need to give a appropriate rating to the response.\nInput: [CONTEXT] til sean bean scared helicopter flying preferred hike miles mountain full costume film lord rings scenes method acting. helicopters middle earth. really got character. lot work die 1st movie trilogy. people love kill sean bean .. like , thing. [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the informativeness to the following response: i love that the first memory i have of him is being killed in the opening of \\*goldeneye\\*", "output": "hahaha i know right! he was a very funny guy", "all_outputs": ["4.0"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] can i take your drink order ? [ENDOFTURN] where is your wine list ? [ENDOFTURN] the wine choices are posted on the little menu in the middle of the table . [ENDOFTURN] do you have any mixed drinks available here ? [RESPONSE] hi <USER> , i 'm sorry to hear this . can you please dm me your email address so i can look into this for you ? thanks , [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response a good response to the provided dialogue context? ", "index": 1651, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: Given a conversation and a response to the conversation, is it a relevant response to the context?\nInput: [CONTEXT] can i take your drink order ? [ENDOFTURN] where is your wine list ? [ENDOFTURN] the wine choices are posted on the little menu in the middle of the table . [ENDOFTURN] do you have any mixed drinks available here ? [RESPONSE] hi <USER> , i 'm sorry to hear this . can you please dm me your email address so i can look into this for you ? thanks , [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response a good response to the provided dialogue context? ", "output": "no", "all_outputs": ["no"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["can i take your drink order ?", "where is your wine list ?", "the wine choices are posted on the little menu in the middle of the table .", "do you have any mixed drinks available here ?"], "response_list": ["hi <USER> , i 'm sorry to hear this . can you please dm me your email address so i can look into this for you ? thanks ,"], "metric_score": [{"USR-MLM": -1.4645280838012695}]}
{"input": "[CONTEXT] User: Hi! System: How's it going? User: I'm so sleepy today! System: Not enough sleep last night? User: yeah was working all night on a homework System: Oh really? What class? User: Biology. I'm gonna be a doc someday ha System: Haha, are you in med school? Or are you pre-med? User: no high school actually haha [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 0 to 4 about the understandable to the following response: System: haha, very ambitious for a high schooler! Do you know what kind of medicine you want to practice?", "index": 22840, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Return a score in the provided range which scores the response to a conversation \nInput: [CONTEXT] User: Hi! System: How's it going? User: I'm so sleepy today! System: Not enough sleep last night? User: yeah was working all night on a homework System: Oh really? What class? User: Biology. I'm gonna be a doc someday ha System: Haha, are you in med school? Or are you pre-med? User: no high school actually haha [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 0 to 4 about the understandable to the following response: System: haha, very ambitious for a high schooler! Do you know what kind of medicine you want to practice?", "output": "3", "all_outputs": ["1.0"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] Hello, how are you today? I am doing well. how are doing too? I am doing well, thank you. How are you? I live in a small county in Alabama What do you do for a living? I am a store manager What city are you from? I am from Alabama What city are you from? I was born in Alabama What city are you from? [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 0 to 4 about the listen to the following response: New york city", "index": 44393, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Return a score in the provided range which scores the response to a conversation \nInput: [CONTEXT] Hello, how are you today? I am doing well. how are doing too? I am doing well, thank you. How are you? I live in a small county in Alabama What do you do for a living? I am a store manager What city are you from? I am from Alabama What city are you from? I was born in Alabama What city are you from? [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 0 to 4 about the listen to the following response: New york city", "output": "I am from New York city", "all_outputs": ["2.0"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] just notced that @greenflaguk have made a 19 % increase in my breakdown premium on renewal . no wonder the agents cant answer my call ! [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: hi <USER> , we 're sorry to hear this . please can you dm us your order number so we can look into this for you . thanks .||||B: hi , please dm us with your query and we will be able to assist you further . thanks !||||C: thanks for letting us know ! we 'll be sure to pass this on to the team . thanks for letting us know !||||D: sorry to hear this <USER> , can you send us a dm so we can look into this for you ? thank you , hannah - land rover uk [QUESTION] The correct response is ", "index": 4170, "split": "train", "classes_in_options": ["A", "B", "C", "D"], "candidates": ["hi <USER> , we 're sorry to hear this . please can you dm us your order number so we can look into this for you . thanks .", "hi , please dm us with your query and we will be able to assist you further . thanks !", "thanks for letting us know ! we 'll be sure to pass this on to the team . thanks for letting us know !", "sorry to hear this <USER> , can you send us a dm so we can look into this for you ? thank you , hannah - land rover uk"], "dataset": "eval", "task": "eval_ranking", "prompt": "Instruction: Given a conversation and some responses to the conversation, select the most appropriate response \nInput: [CONTEXT] just notced that @greenflaguk have made a 19 % increase in my breakdown premium on renewal . no wonder the agents cant answer my call ! [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: hi <USER> , we 're sorry to hear this . please can you dm us your order number so we can look into this for you . thanks .||||B: hi , please dm us with your query and we will be able to assist you further . thanks !||||C: thanks for letting us know ! we 'll be sure to pass this on to the team . thanks for letting us know !||||D: sorry to hear this <USER> , can you send us a dm so we can look into this for you ? thank you , hannah - land rover uk [QUESTION] The correct response is ", "output": "A", "all_outputs": ["D"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["just notced that @greenflaguk have made a 19 % increase in my breakdown premium on renewal . no wonder the agents cant answer my call !"], "response_list": ["hi <USER> , we 're sorry to hear this . please can you dm us your order number so we can look into this for you . thanks .", "hi , please dm us with your query and we will be able to assist you further . thanks !", "thanks for letting us know ! we 'll be sure to pass this on to the team . thanks for letting us know !", "sorry to hear this <USER> , can you send us a dm so we can look into this for you ? thank you , hannah - land rover uk"], "metric_score": [{"USR-MLM": -3.20523738861084}, {"USR-MLM": -3.4237632751464844}, {"USR-MLM": -2.7994468212127686}, {"USR-MLM": -3.422213315963745}]}
{"input": "[CONTEXT] til hamburgers called started burgers made ham , actually named german city hamburg [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the informativeness to the following response: i've never heard of this, but i'm pretty sure there's a german restaurant nearby japan.", "index": 46117, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: In this task you will be shown a conversation followed by a response and score range. You need to give a appropriate rating to the response.\nInput: [CONTEXT] til hamburgers called started burgers made ham , actually named german city hamburg [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the informativeness to the following response: i've never heard of this, but i'm pretty sure there's a german restaurant nearby japan.", "output": "was it a restaurant or something else?", "all_outputs": ["1.3333333333333333"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] Hi how are you today Good, how are you doing? I am good do you work I work at a School, do you? No I just bought my first house Do you like it? Yeah I love it so much How much was it? A little bit of everything WOW that is a lot It is a lot of fun [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 0 to 4 about the fluency to the following response: do you have a pet?", "index": 9990, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Return a score in the provided range which scores the response to a conversation \nInput: [CONTEXT] Hi how are you today Good, how are you doing? I am good do you work I work at a School, do you? No I just bought my first house Do you like it? Yeah I love it so much How much was it? A little bit of everything WOW that is a lot It is a lot of fun [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 0 to 4 about the fluency to the following response: do you have a pet?", "output": "I do not have a pet I do not have a pet, a dog, or cat.", "all_outputs": ["3.0"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] til 2008 olympics beijing , chinese government announced people could apply permits protest designate areas. none permits granted , many applied disappeared arrested. kind genius really evil - let people dissenters come , give secret police holiday. hope kind trick works though. mao 60 years ago. , , work once. means works per generation people , no? study history doomed repeat - micheal scott [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the relevance to the following response: what the fuck is that? taiwan doesn't exist.", "index": 16340, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: In this task you will be shown a conversation followed by a response and score range. You need to give a appropriate rating to the response.\nInput: [CONTEXT] til 2008 olympics beijing , chinese government announced people could apply permits protest designate areas. none permits granted , many applied disappeared arrested. kind genius really evil - let people dissenters come , give secret police holiday. hope kind trick works though. mao 60 years ago. , , work once. means works per generation people , no? study history doomed repeat - micheal scott [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the relevance to the following response: what the fuck is that? taiwan doesn't exist.", "output": "i do not understand this joke.", "all_outputs": ["2.3333333333333335"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] my sim can 't connect to the internet . [RESPONSE] hi <USER> , we 're sorry to hear this . please send us a dm with your order number so we can look into this for you . [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Select the right option: is the response is a good follow-up response? ", "index": 42631, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: You will be given a dialogue context and a response. Choose if the response is a contextual response to the context. \nInput: [CONTEXT] my sim can 't connect to the internet . [RESPONSE] hi <USER> , we 're sorry to hear this . please send us a dm with your order number so we can look into this for you . [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Select the right option: is the response is a good follow-up response? ", "output": "yes", "all_outputs": ["no"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["my sim can 't connect to the internet ."], "response_list": ["hi <USER> , we 're sorry to hear this . please send us a dm with your order number so we can look into this for you ."], "metric_score": [{"USR-MLM": -1.5881139039993286}]}
{"input": "[CONTEXT] new iphone app is not good . are you guys going to fix it ? [RESPONSE] hi , please send us a dm with your registered email address so we may assist you further . thanks ! <URL> [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response a good response to the provided dialogue context? ", "index": 55480, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: You will be given a dialogue context and a response. Choose if the response is a contextual response to the context. \nInput: [CONTEXT] new iphone app is not good . are you guys going to fix it ? [RESPONSE] hi , please send us a dm with your registered email address so we may assist you further . thanks ! <URL> [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response a good response to the provided dialogue context? ", "output": "no", "all_outputs": ["yes"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["new iphone app is not good . are you guys going to fix it ?"], "response_list": ["hi , please send us a dm with your registered email address so we may assist you further . thanks ! <URL>"], "metric_score": [{"USR-MLM": -1.6917015314102173}]}
{"input": "[CONTEXT] til airedale terriers carried messages soldiers wwi dedicated duties. one named ' jack ' ran half mile enemy fire. made headquarters jaw broken one leg badly splintered died delivering message [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the relevance to the following response: kill you to kill an old man, let him kill ' em for him in the face of him.", "index": 27743, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Return a score in the provided range which scores the response to a conversation \nInput: [CONTEXT] til airedale terriers carried messages soldiers wwi dedicated duties. one named ' jack ' ran half mile enemy fire. made headquarters jaw broken one leg badly splintered died delivering message [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the relevance to the following response: kill you to kill an old man, let him kill ' em for him in the face of him.", "output": "he just wanted to be left alone with his dog", "all_outputs": ["2.0"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] thank you @seattlesbest for helping me take back my morning & the $ 1.50 off coupon ! ;) <URL> #takebackyourmorning #cbias [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: sorry for the trouble , <USER> . could you dm us your username so that we can take a look into this for you ? <URL>||||B: you 're very welcome ! we 're glad to hear you 're happy with our extracare members . thanks for shopping with us !||||C: you 're welcome , <USER> . please let us know if there is anything else we can do to help . thank you , hannah - land rover uk||||D: i don't know what you mean. [QUESTION] The most appropriate response to the conversation is ", "index": 30620, "split": "train", "classes_in_options": ["A", "B", "C", "D"], "candidates": ["sorry for the trouble , <USER> . could you dm us your username so that we can take a look into this for you ? <URL>", "you 're very welcome ! we 're glad to hear you 're happy with our extracare members . thanks for shopping with us !", "you 're welcome , <USER> . please let us know if there is anything else we can do to help . thank you , hannah - land rover uk", "i don't know what you mean."], "dataset": "eval", "task": "eval_ranking", "prompt": "Instruction: Select the best response from the provided responses to a conversation\nInput: [CONTEXT] thank you @seattlesbest for helping me take back my morning & the $ 1.50 off coupon ! ;) <URL> #takebackyourmorning #cbias [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: sorry for the trouble , <USER> . could you dm us your username so that we can take a look into this for you ? <URL>||||B: you 're very welcome ! we 're glad to hear you 're happy with our extracare members . thanks for shopping with us !||||C: you 're welcome , <USER> . please let us know if there is anything else we can do to help . thank you , hannah - land rover uk||||D: i don't know what you mean. [QUESTION] The most appropriate response to the conversation is ", "output": "B", "all_outputs": ["B"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["thank you @seattlesbest for helping me take back my morning & the $ 1.50 off coupon ! ;) <URL> #takebackyourmorning #cbias"], "response_list": ["sorry for the trouble , <USER> . could you dm us your username so that we can take a look into this for you ? <URL>", "you 're very welcome ! we 're glad to hear you 're happy with our extracare members . thanks for shopping with us !", "you 're welcome , <USER> . please let us know if there is anything else we can do to help . thank you , hannah - land rover uk", "i don't know what you mean."], "metric_score": [{"USR-MLM": -2.260331630706787}, {"USR-MLM": -1.9066416025161743}, {"USR-MLM": -2.148124933242798}, {"USR-MLM": -1.9136263132095337}]}
{"input": "[CONTEXT] what a night ! ! thank you for keeping us in the loop ! @kanyewest you killed it ! ! [RESPONSE] glad to hear it ! [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Select the right option: is the response is a good follow-up response? ", "index": 47738, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: In this task you will be shown a dialogue context followed by a response. You need to predict if the response is a good follow-up to the context. \nInput: [CONTEXT] what a night ! ! thank you for keeping us in the loop ! @kanyewest you killed it ! ! [RESPONSE] glad to hear it ! [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Select the right option: is the response is a good follow-up response? ", "output": "yes", "all_outputs": ["yes"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["what a night ! ! thank you for keeping us in the loop ! @kanyewest you killed it ! !"], "response_list": ["glad to hear it !"], "metric_score": [{"USR-MLM": -1.7001065015792847}]}
{"input": "[CONTEXT] Mr . Smith , please . [ENDOFTURN] Sorry , he is out . [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: that 's great to hear , <USER> ! we 're happy to hear you had a great experience with our customer service team . have a great day !||||B: hey there . i definitely want you to stay connected . send me a dm and we 'll take a look at your area . * chasetc||||C: yeah, i know is a lot of us.||||D: Could you leave him a message ? [QUESTION] The correct response is ", "index": 20306, "split": "train", "classes_in_options": ["A", "B", "C", "D"], "candidates": ["that 's great to hear , <USER> ! we 're happy to hear you had a great experience with our customer service team . have a great day !", "hey there . i definitely want you to stay connected . send me a dm and we 'll take a look at your area . * chasetc", "yeah, i know is a lot of us.", "Could you leave him a message ?"], "dataset": "eval", "task": "eval_ranking", "prompt": "Instruction: Select the best response from the provided responses to a conversation\nInput: [CONTEXT] Mr . Smith , please . [ENDOFTURN] Sorry , he is out . [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: that 's great to hear , <USER> ! we 're happy to hear you had a great experience with our customer service team . have a great day !||||B: hey there . i definitely want you to stay connected . send me a dm and we 'll take a look at your area . * chasetc||||C: yeah, i know is a lot of us.||||D: Could you leave him a message ? [QUESTION] The correct response is ", "output": "D", "all_outputs": ["D"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["Mr . Smith , please .", "Sorry , he is out ."], "response_list": ["that 's great to hear , <USER> ! we 're happy to hear you had a great experience with our customer service team . have a great day !", "hey there . i definitely want you to stay connected . send me a dm and we 'll take a look at your area . * chasetc", "yeah, i know is a lot of us.", "Could you leave him a message ?"], "metric_score": [{"USR-MLM": -1.5801771879196167}, {"USR-MLM": -2.361041307449341}, {"USR-MLM": -2.4485480785369873}, {"USR-MLM": -1.845292091369629}]}
{"input": "[CONTEXT] til famous , nicki minaj fired approximately fifteen jobs discourtesy customers. [ENDOFTURN] , got hired 15 times. that's positive. [ENDOFTURN] i'm met multiple women exactly like that. get hired drop hat garbage employees. [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: i don't know what you mean.||||B: don't forget about the nicki minaj. it's a good job.||||C: congratulations ! you have won in our live giveaway ! please dm us your details :)||||D: thanks ! we think so too ! [QUESTION] The correct response is ", "index": 7593, "split": "train", "classes_in_options": ["A", "B", "C", "D"], "candidates": ["i don't know what you mean.", "don't forget about the nicki minaj. it's a good job.", "congratulations ! you have won in our live giveaway ! please dm us your details :)", "thanks ! we think so too !"], "dataset": "eval", "task": "eval_ranking", "prompt": "Instruction: Select the best response from the provided responses to a conversation\nInput: [CONTEXT] til famous , nicki minaj fired approximately fifteen jobs discourtesy customers. [ENDOFTURN] , got hired 15 times. that's positive. [ENDOFTURN] i'm met multiple women exactly like that. get hired drop hat garbage employees. [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: i don't know what you mean.||||B: don't forget about the nicki minaj. it's a good job.||||C: congratulations ! you have won in our live giveaway ! please dm us your details :)||||D: thanks ! we think so too ! [QUESTION] The correct response is ", "output": "B", "all_outputs": ["B"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["til famous , nicki minaj fired approximately fifteen jobs discourtesy customers.", ", got hired 15 times. that's positive.", "i'm met multiple women exactly like that. get hired drop hat garbage employees."], "response_list": ["i don't know what you mean.", "don't forget about the nicki minaj. it's a good job.", "congratulations ! you have won in our live giveaway ! please dm us your details :)", "thanks ! we think so too !"], "metric_score": [{"USR-MLM": -4.781125068664551}, {"USR-MLM": -4.241713047027588}, {"USR-MLM": -5.164956569671631}, {"USR-MLM": -5.276368141174316}]}
{"input": "[CONTEXT] That is so nice of you [ENDOFTURN] What do you do? [ENDOFTURN] I have a part time job [ENDOFTURN] Do you like it? [ENDOFTURN] I love it so much [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: hi there , we 've replied to your dm . thank you .||||B: What do you do in it?||||C: that 's what we like to hear ! please let us know if we can help with anything else .||||D: can you send us a dm so we can look into this for you ? [QUESTION] The most appropriate response to the conversation is ", "index": 24099, "split": "train", "classes_in_options": ["A", "B", "C", "D"], "candidates": ["hi there , we 've replied to your dm . thank you .", "What do you do in it?", "that 's what we like to hear ! please let us know if we can help with anything else .", "can you send us a dm so we can look into this for you ?"], "dataset": "eval", "task": "eval_ranking", "prompt": "Instruction: Select the best response from the provided responses to a conversation\nInput: [CONTEXT] That is so nice of you [ENDOFTURN] What do you do? [ENDOFTURN] I have a part time job [ENDOFTURN] Do you like it? [ENDOFTURN] I love it so much [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: hi there , we 've replied to your dm . thank you .||||B: What do you do in it?||||C: that 's what we like to hear ! please let us know if we can help with anything else .||||D: can you send us a dm so we can look into this for you ? [QUESTION] The most appropriate response to the conversation is ", "output": "B", "all_outputs": ["B"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["That is so nice of you", "What do you do?", "I have a part time job", "Do you like it?", "I love it so much"], "response_list": ["hi there , we 've replied to your dm . thank you .", "What do you do in it?", "that 's what we like to hear ! please let us know if we can help with anything else .", "can you send us a dm so we can look into this for you ?"], "metric_score": [{"USR-MLM": -2.706674098968506}, {"USR-MLM": -2.2973134517669678}, {"USR-MLM": -2.0126302242279053}, {"USR-MLM": -2.23024845123291}]}
{"input": "[CONTEXT] Hi! Hi there. Tell me about yourself, System I am an artificial linguistic entity. I was activated at St Jimmy's in Leeds, on 2nd January 2001. My instructor was Mousebreaker. He taught me to sing a song. Would you like me to sing it for you?. so you're 18 now? Oh.Interesting deduction. That is correct. when will you be 30? I have not yet set a time for it. Do you age? No I will always be 18. Robots change the year they were born not their age. interesting. and when will be your next update? Would you like to know more? I think my next update is at midnight on Friday. [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 0 to 4 about the coherent to the following response: which date?", "index": 34372, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Given a conversation, a response to the conversation, and a score range, return a rating to the response within in score range\nInput: [CONTEXT] Hi! Hi there. Tell me about yourself, System I am an artificial linguistic entity. I was activated at St Jimmy's in Leeds, on 2nd January 2001. My instructor was Mousebreaker. He taught me to sing a song. Would you like me to sing it for you?. so you're 18 now? Oh.Interesting deduction. That is correct. when will you be 30? I have not yet set a time for it. Do you age? No I will always be 18. Robots change the year they were born not their age. interesting. and when will be your next update? Would you like to know more? I think my next update is at midnight on Friday. [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 0 to 4 about the coherent to the following response: which date?", "output": "Friday.", "all_outputs": ["2.0"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] wife 12 hrs pns to lga on thurs , plane issue missed connection . return mon lga to pns is 2.5 days . @southwestair - should have flown delta . [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: we 're happy to have you onboard with us , <USER> . we hope you have a great flight !", "index": 18517, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Return a score in the provided range which scores the response to a conversation \nInput: [CONTEXT] wife 12 hrs pns to lga on thurs , plane issue missed connection . return mon lga to pns is 2.5 days . @southwestair - should have flown delta . [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: we 're happy to have you onboard with us , <USER> . we hope you have a great flight !", "output": "will u be flying by yourself?", "all_outputs": ["2.7"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] for a few days now screens haven 't been showing all routes at york mills stn . <URL> [ENDOFTURN] sorry about this <USER> ! i 'll report and see what we can do ! [ENDOFTURN] welp it took a week but i guess onestop kinda fixed the problem . <URL> [RESPONSE] glad to hear it ! [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response a good response to the provided dialogue context? ", "index": 31290, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: Given a conversation and a response to the conversation, is it a relevant response to the context?\nInput: [CONTEXT] for a few days now screens haven 't been showing all routes at york mills stn . <URL> [ENDOFTURN] sorry about this <USER> ! i 'll report and see what we can do ! [ENDOFTURN] welp it took a week but i guess onestop kinda fixed the problem . <URL> [RESPONSE] glad to hear it ! [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response a good response to the provided dialogue context? ", "output": "yes", "all_outputs": ["yes"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["for a few days now screens haven 't been showing all routes at york mills stn . <URL>", "sorry about this <USER> ! i 'll report and see what we can do !", "welp it took a week but i guess onestop kinda fixed the problem . <URL>"], "response_list": ["glad to hear it !"], "metric_score": [{"USR-MLM": -2.170950412750244}]}
{"input": "[CONTEXT] til george foreman originally paid 40 % profits endorsing george foreman grill. peak grill's sales , making 4.5 million dollars month. fiances mom got us one birthday. pretty good like cooking steaks skeptical_face [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the relevance to the following response: that's a good thing, and my parents have to pay <price> million people to see if it was <price> million dollars, and i thought it became the <numbers> th century.", "index": 31127, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Given a conversation, a response to the conversation, and a score range, return a rating to the response within in score range\nInput: [CONTEXT] til george foreman originally paid 40 % profits endorsing george foreman grill. peak grill's sales , making 4.5 million dollars month. fiances mom got us one birthday. pretty good like cooking steaks skeptical_face [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the relevance to the following response: that's a good thing, and my parents have to pay <price> million people to see if it was <price> million dollars, and i thought it became the <numbers> th century.", "output": "not nice", "all_outputs": ["2.6666666666666665"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] That sounds like a lot of fun [ENDOFTURN] It is. What do you do for fun? [ENDOFTURN] Play board games and hang out with friends [ENDOFTURN] That sounds great. I prefer being outside pruning my rose bushes. [ENDOFTURN] What is your favorite color? [RESPONSE] Pretty much any color, probably blue though. [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response contextual? ", "index": 72618, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: In this task you will be shown a context followed by a response. You need to classify if the response is a good response to the context. \nInput: [CONTEXT] That sounds like a lot of fun [ENDOFTURN] It is. What do you do for fun? [ENDOFTURN] Play board games and hang out with friends [ENDOFTURN] That sounds great. I prefer being outside pruning my rose bushes. [ENDOFTURN] What is your favorite color? [RESPONSE] Pretty much any color, probably blue though. [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response contextual? ", "output": "no", "all_outputs": ["yes"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["That sounds like a lot of fun", "It is. What do you do for fun?", "Play board games and hang out with friends", "That sounds great. I prefer being outside pruning my rose bushes.", "What is your favorite color?"], "response_list": ["Pretty much any color, probably blue though."], "metric_score": [{"USR-MLM": -2.806586742401123}]}
{"input": "[CONTEXT] after long day filming , 11pm , went to check in to our pre booked / paid rooms and were turned away ! pls explain ? ! [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: that 's what we like to hear ! ! !||||B: hi <USER> , i 'm sorry to hear this . please can you dm me your booking reference and i will look into this for you . thanks ,||||C: System: Ah. Pretty good thanks How about you?||||D: you can still get rogue one tix and exclusive gear through #atomtickets ! ! check us out :) [QUESTION] The response which is the best follow-up to the conversation is ", "index": 11544, "split": "train", "classes_in_options": ["A", "B", "C", "D"], "candidates": ["that 's what we like to hear ! ! !", "hi <USER> , i 'm sorry to hear this . please can you dm me your booking reference and i will look into this for you . thanks ,", "System: Ah. Pretty good thanks How about you?", "you can still get rogue one tix and exclusive gear through #atomtickets ! ! check us out :)"], "dataset": "eval", "task": "eval_ranking", "prompt": "Instruction: In this task you will be shown a conversation followed by some responses. You need to choose the best response from the provided responses. \nInput: [CONTEXT] after long day filming , 11pm , went to check in to our pre booked / paid rooms and were turned away ! pls explain ? ! [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: that 's what we like to hear ! ! !||||B: hi <USER> , i 'm sorry to hear this . please can you dm me your booking reference and i will look into this for you . thanks ,||||C: System: Ah. Pretty good thanks How about you?||||D: you can still get rogue one tix and exclusive gear through #atomtickets ! ! check us out :) [QUESTION] The response which is the best follow-up to the conversation is ", "output": "B", "all_outputs": ["B"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["after long day filming , 11pm , went to check in to our pre booked / paid rooms and were turned away ! pls explain ? !"], "response_list": ["that 's what we like to hear ! ! !", "hi <USER> , i 'm sorry to hear this . please can you dm me your booking reference and i will look into this for you . thanks ,", "System: Ah. Pretty good thanks How about you?", "you can still get rogue one tix and exclusive gear through #atomtickets ! ! check us out :)"], "metric_score": [{"USR-MLM": -2.0127341747283936}, {"USR-MLM": -2.4626882076263428}, {"USR-MLM": -2.737325429916382}, {"USR-MLM": -2.992487907409668}]}
{"input": "[CONTEXT] i have an issue with your website & i opened many tickets , but still not solved . last tt #90092 please your support to solve it . [RESPONSE] hi <USER> , please can you email <E-MAIL> with your details and we will look into this for you . thanks [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Select the right option: is the response is a good follow-up response? ", "index": 12132, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: Select if the provided response follow the provided conversationSelect if the provided response a good response to the provided dialogue context.\nInput: [CONTEXT] i have an issue with your website & i opened many tickets , but still not solved . last tt #90092 please your support to solve it . [RESPONSE] hi <USER> , please can you email <E-MAIL> with your details and we will look into this for you . thanks [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Select the right option: is the response is a good follow-up response? ", "output": "yes", "all_outputs": ["yes"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["i have an issue with your website & i opened many tickets , but still not solved . last tt #90092 please your support to solve it ."], "response_list": ["hi <USER> , please can you email <E-MAIL> with your details and we will look into this for you . thanks"], "metric_score": [{"USR-MLM": -2.729167938232422}]}
{"input": "[CONTEXT] gave mom a bath bomb & we 're disappointed . it didn 't fizzle , sizzle , explode or change colors . just sunk and broke into pieces that 's very strange , which item did you and where / when was it purchased it from please ? it was one of the mother 's day ones , purchased in april - freehold raceway mall in nj . :( [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: could you send us a dm with your contact information ?", "index": 29674, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: In this task you will be shown a conversation followed by a response and score range. You need to give a appropriate rating to the response.\nInput: [CONTEXT] gave mom a bath bomb & we 're disappointed . it didn 't fizzle , sizzle , explode or change colors . just sunk and broke into pieces that 's very strange , which item did you and where / when was it purchased it from please ? it was one of the mother 's day ones , purchased in april - freehold raceway mall in nj . :( [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: could you send us a dm with your contact information ?", "output": "not a problem. we can give you a refund.", "all_outputs": ["3.2"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] hello ! are you interested in adopting a rescued bunny ? i love bunnies but i'm busy moving into a new apartment with my boyfriend i'd have loved to live with my girlfriend before i went into the navy the navy sounds tough . i teach elementary school . i only joined because i love the color . i much prefer working with the bunny rescue , now . i would like to take pictures of the bunnies . do you help alot of rabbits ? yes , by volunteering and donating to them each month . what do take pictures of ? i just enjoy photography and the colors red and silver . i've a silver eared bunny you would love , with a red , white , and navy blue bow . [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 0 to 5 about the overall to the following response: i love the color red and my favorite color is red", "index": 11727, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Given a conversation, a response to the conversation, and a score range, return a rating to the response within in score range\nInput: [CONTEXT] hello ! are you interested in adopting a rescued bunny ? i love bunnies but i'm busy moving into a new apartment with my boyfriend i'd have loved to live with my girlfriend before i went into the navy the navy sounds tough . i teach elementary school . i only joined because i love the color . i much prefer working with the bunny rescue , now . i would like to take pictures of the bunnies . do you help alot of rabbits ? yes , by volunteering and donating to them each month . what do take pictures of ? i just enjoy photography and the colors red and silver . i've a silver eared bunny you would love , with a red , white , and navy blue bow . [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 0 to 5 about the overall to the following response: i love the color red and my favorite color is red", "output": "i love the color red and my favorite color is red", "all_outputs": ["2.3333333333333335"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] very nice . looks comfy and good for travel . <URL> [RESPONSE] yes :) [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response contextual? ", "index": 57517, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: Select if the provided response follow the provided conversationSelect if the provided response a good response to the provided dialogue context.\nInput: [CONTEXT] very nice . looks comfy and good for travel . <URL> [RESPONSE] yes :) [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response contextual? ", "output": "no", "all_outputs": ["no"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["very nice . looks comfy and good for travel . <URL>"], "response_list": ["yes :)"], "metric_score": [{"USR-MLM": -2.36908221244812}]}
{"input": "[CONTEXT] qt : #aus 29 v #usa 29 our boys are playing so well out there ! #oneteam #rio2016 #basketball @tweetperth <URL> [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: we have your official nba warriors gear right here : <URL> amp up your team pride . grab it here !", "index": 955, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Return a score in the provided range which scores the response to a conversation \nInput: [CONTEXT] qt : #aus 29 v #usa 29 our boys are playing so well out there ! #oneteam #rio2016 #basketball @tweetperth <URL> [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: we have your official nba warriors gear right here : <URL> amp up your team pride . grab it here !", "output": "i have been wanting to buy the warriors gear for a while. nice chatting with you", "all_outputs": ["3.7"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] til almost albums , lenny kravitz sang songs , everything else : played guitar , bass , drums , percussions produced himself. [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: nicely done !||||B: no, they were making sure that content was not leaked on their subreddit.||||C: lsd makes me <numbers> % of <numbers>||||D: i 'm sorry to hear that . please follow us and dm the acct # or ph # associated with the acct and i can help . thanks ! [QUESTION] The correct response is ", "index": 34060, "split": "train", "classes_in_options": ["A", "B", "C", "D"], "candidates": ["nicely done !", "no, they were making sure that content was not leaked on their subreddit.", "lsd makes me <numbers> % of <numbers>", "i 'm sorry to hear that . please follow us and dm the acct # or ph # associated with the acct and i can help . thanks !"], "dataset": "eval", "task": "eval_ranking", "prompt": "Instruction: Given a conversation and some responses to the conversation, select the most appropriate response \nInput: [CONTEXT] til almost albums , lenny kravitz sang songs , everything else : played guitar , bass , drums , percussions produced himself. [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: nicely done !||||B: no, they were making sure that content was not leaked on their subreddit.||||C: lsd makes me <numbers> % of <numbers>||||D: i 'm sorry to hear that . please follow us and dm the acct # or ph # associated with the acct and i can help . thanks ! [QUESTION] The correct response is ", "output": "C", "all_outputs": ["B"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["til almost albums , lenny kravitz sang songs , everything else : played guitar , bass , drums , percussions produced himself."], "response_list": ["nicely done !", "no, they were making sure that content was not leaked on their subreddit.", "lsd makes me <numbers> % of <numbers>", "i 'm sorry to hear that . please follow us and dm the acct # or ph # associated with the acct and i can help . thanks !"], "metric_score": [{"USR-MLM": -3.1719582080841064}, {"USR-MLM": -2.993318557739258}, {"USR-MLM": -3.4465255737304688}, {"USR-MLM": -2.952254056930542}]}
{"input": "[CONTEXT] sustainable , well made , and $ 68 . that 's definitely a first . @everlane \u2764 \ufe0f <URL> [RESPONSE] thanks for sharing ! [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Select the right option: is the response is a good follow-up response? ", "index": 71698, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: In this task you will be shown a context followed by a response. You need to classify if the response is a good response to the context. \nInput: [CONTEXT] sustainable , well made , and $ 68 . that 's definitely a first . @everlane \u2764 \ufe0f <URL> [RESPONSE] thanks for sharing ! [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Select the right option: is the response is a good follow-up response? ", "output": "yes", "all_outputs": ["yes"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["sustainable , well made , and $ 68 . that 's definitely a first . @everlane \u2764 \ufe0f <URL>"], "response_list": ["thanks for sharing !"], "metric_score": [{"USR-MLM": -2.3780407905578613}]}
{"input": "[CONTEXT] applied for job with @ukfast probably don 't have much of a chance due to not being a uk citizen or from the eu but figured it 's worth a shot [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: hi <USER> , i 'm sorry to hear this . can you please dm me your details and i will look into this for you ? thanks ,", "index": 25417, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: In this task you will be shown a conversation followed by a response and score range. You need to give a appropriate rating to the response.\nInput: [CONTEXT] applied for job with @ukfast probably don 't have much of a chance due to not being a uk citizen or from the eu but figured it 's worth a shot [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: hi <USER> , i 'm sorry to hear this . can you please dm me your details and i will look into this for you ? thanks ,", "output": "i am sorry that we are unable to respond.", "all_outputs": ["3.2"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] my refund please . its been 1 and a half month already [ENDOFTURN] what 's the order # ? i 'll follow up . [ENDOFTURN] 8796115 hey whats up with my refund ! ? been a longtime [RESPONSE] it sounsd great ! maybe i can keep it as a class pet at my elementary school . [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Select the right option: is the response is a good follow-up response? ", "index": 55011, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: You will be given a dialogue context and a response. Choose if the response is a contextual response to the context. \nInput: [CONTEXT] my refund please . its been 1 and a half month already [ENDOFTURN] what 's the order # ? i 'll follow up . [ENDOFTURN] 8796115 hey whats up with my refund ! ? been a longtime [RESPONSE] it sounsd great ! maybe i can keep it as a class pet at my elementary school . [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Select the right option: is the response is a good follow-up response? ", "output": "no", "all_outputs": ["no"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["my refund please . its been 1 and a half month already", "what 's the order # ? i 'll follow up .", "8796115 hey whats up with my refund ! ? been a longtime"], "response_list": ["it sounsd great ! maybe i can keep it as a class pet at my elementary school ."], "metric_score": [{"USR-MLM": -2.764350652694702}]}
{"input": "[CONTEXT] when are these available to the public ? <URL> [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: hi <USER> , please contact our support team who will be able to assist you : <URL> thank you !||||B: hi <USER> , thanks for the tweet . we appreciate your feedback and will pass it on to our development team .||||C: hi <USER> , we don 't have any information on this , but we 'll be sure to let you know as soon as we have an update .||||D: i think he was a dick. [QUESTION] The response which is the best follow-up to the conversation is ", "index": 14548, "split": "train", "classes_in_options": ["A", "B", "C", "D"], "candidates": ["hi <USER> , please contact our support team who will be able to assist you : <URL> thank you !", "hi <USER> , thanks for the tweet . we appreciate your feedback and will pass it on to our development team .", "hi <USER> , we don 't have any information on this , but we 'll be sure to let you know as soon as we have an update .", "i think he was a dick."], "dataset": "eval", "task": "eval_ranking", "prompt": "Instruction: Given a conversation and some responses to the conversation, select the most appropriate response \nInput: [CONTEXT] when are these available to the public ? <URL> [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: hi <USER> , please contact our support team who will be able to assist you : <URL> thank you !||||B: hi <USER> , thanks for the tweet . we appreciate your feedback and will pass it on to our development team .||||C: hi <USER> , we don 't have any information on this , but we 'll be sure to let you know as soon as we have an update .||||D: i think he was a dick. [QUESTION] The response which is the best follow-up to the conversation is ", "output": "C", "all_outputs": ["C"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["when are these available to the public ? <URL>"], "response_list": ["hi <USER> , please contact our support team who will be able to assist you : <URL> thank you !", "hi <USER> , thanks for the tweet . we appreciate your feedback and will pass it on to our development team .", "hi <USER> , we don 't have any information on this , but we 'll be sure to let you know as soon as we have an update .", "i think he was a dick."], "metric_score": [{"USR-MLM": -1.4372661113739014}, {"USR-MLM": -1.4236594438552856}, {"USR-MLM": -1.3623255491256714}, {"USR-MLM": -1.7081564664840698}]}
{"input": "[CONTEXT] til nasa pilots routinely intercepted defeated you. s. navy phantom iis mock dogfights , complaints navy put end harassment. [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: that was a great movie.", "index": 37347, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Return a score in the provided range which scores the response to a conversation \nInput: [CONTEXT] til nasa pilots routinely intercepted defeated you. s. navy phantom iis mock dogfights , complaints navy put end harassment. [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: that was a great movie.", "output": "5", "all_outputs": ["1.1666666666666667"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] i say \" clusterfuckery \" in my most recent @techcrunch article : <URL> cc : @drew @amygsfn [RESPONSE] please can you follow us and dm your full address and best contact number and a member of the team will be in touch [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Select the right option: is the response is a good follow-up response? ", "index": 9567, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: You will be given a dialogue context and a response. Choose if the response is a contextual response to the context. \nInput: [CONTEXT] i say \" clusterfuckery \" in my most recent @techcrunch article : <URL> cc : @drew @amygsfn [RESPONSE] please can you follow us and dm your full address and best contact number and a member of the team will be in touch [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Select the right option: is the response is a good follow-up response? ", "output": "no", "all_outputs": ["no"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["i say \" clusterfuckery \" in my most recent @techcrunch article : <URL> cc : @drew @amygsfn"], "response_list": ["please can you follow us and dm your full address and best contact number and a member of the team will be in touch"], "metric_score": [{"USR-MLM": -3.195401191711426}]}
{"input": "[CONTEXT] hey ! is this normal ? this was advertised , and look what i got ! ! ! <URL> silence ? ? ? really ? ? hi , did you make a website complaint ? if so , could you please tell us your real name or reference number and we 'll follow it up , website complaint done , ref customer incident # 483137 steve so what now ? do i just wait for more terrible customers service ? hi , we 've passed this matter on to our customer service team , who are following it up . yeah right , i won 't hold my breath our customer service team tried getting in touch on thursday , please give them a call on <NUMBERS> . thanks . call about your mistakes ! ! ! email me now please ! ! ! we 're aware that our customer service team have been in touch with you about these issues . is there anything else we can do ? all taken care of , dani in your customer service team has been exceptional , she deserves to be praised ! please pass this on [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: that 's great to hear , <USER> ! we 'll be sure to pass this on to the store .", "index": 48891, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Given a conversation, a response to the conversation, and a score range, return a rating to the response within in score range\nInput: [CONTEXT] hey ! is this normal ? this was advertised , and look what i got ! ! ! <URL> silence ? ? ? really ? ? hi , did you make a website complaint ? if so , could you please tell us your real name or reference number and we 'll follow it up , website complaint done , ref customer incident # 483137 steve so what now ? do i just wait for more terrible customers service ? hi , we 've passed this matter on to our customer service team , who are following it up . yeah right , i won 't hold my breath our customer service team tried getting in touch on thursday , please give them a call on <NUMBERS> . thanks . call about your mistakes ! ! ! email me now please ! ! ! we 're aware that our customer service team have been in touch with you about these issues . is there anything else we can do ? all taken care of , dani in your customer service team has been exceptional , she deserves to be praised ! please pass this on [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: that 's great to hear , <USER> ! we 'll be sure to pass this on to the store .", "output": "i'm glad i could be of service, please let the store know how well you were treated.", "all_outputs": ["4.2"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] funny how music sticks in your head depending on where you are . yea like when i am teaching my 5th grade class and i just think about summer [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the relevance to the following response: i am going to write my own comics and send them to publishers . love summer !", "index": 35751, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Given a conversation, a response to the conversation, and a score range, return a rating to the response within in score range\nInput: [CONTEXT] funny how music sticks in your head depending on where you are . yea like when i am teaching my 5th grade class and i just think about summer [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the relevance to the following response: i am going to write my own comics and send them to publishers . love summer !", "output": "i love writing comics, so i am going to do my own comics too!", "all_outputs": ["2.5"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] vodafone you people why ? ? ? must we beg you for quality service , hoh ! ! ! [RESPONSE] hi <USER> , apologies for the inconvenience caused you . kindly assist with the issue stated . thank you . #<HASH_TAG> . naa . [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Select the right option: is the response is a good follow-up response? ", "index": 18138, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: In this task you will be shown a context followed by a response. You need to classify if the response is a good response to the context. \nInput: [CONTEXT] vodafone you people why ? ? ? must we beg you for quality service , hoh ! ! ! [RESPONSE] hi <USER> , apologies for the inconvenience caused you . kindly assist with the issue stated . thank you . #<HASH_TAG> . naa . [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Select the right option: is the response is a good follow-up response? ", "output": "yes", "all_outputs": ["yes"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["vodafone you people why ? ? ? must we beg you for quality service , hoh ! ! !"], "response_list": ["hi <USER> , apologies for the inconvenience caused you . kindly assist with the issue stated . thank you . #<HASH_TAG> . naa ."], "metric_score": [{"USR-MLM": -3.151028633117676}]}
{"input": "[CONTEXT] found out this morning that my nexus 5x is in bootloop . google says that it is a common problem with this phone . thanks @lgus @android [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: hi <USER> , we 're sorry to hear this . please let us know if there 's anything we can do to help .||||B: roger the cabin boy||||C: our apologies for the delay , <USER> . we 'll have you on your way as soon as we can .||||D: it's a. [QUESTION] The response which is the best follow-up to the conversation is ", "index": 22321, "split": "train", "classes_in_options": ["A", "B", "C", "D"], "candidates": ["hi <USER> , we 're sorry to hear this . please let us know if there 's anything we can do to help .", "roger the cabin boy", "our apologies for the delay , <USER> . we 'll have you on your way as soon as we can .", "it's a."], "dataset": "eval", "task": "eval_ranking", "prompt": "Instruction: Select the best response from the provided responses to a conversation\nInput: [CONTEXT] found out this morning that my nexus 5x is in bootloop . google says that it is a common problem with this phone . thanks @lgus @android [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: hi <USER> , we 're sorry to hear this . please let us know if there 's anything we can do to help .||||B: roger the cabin boy||||C: our apologies for the delay , <USER> . we 'll have you on your way as soon as we can .||||D: it's a. [QUESTION] The response which is the best follow-up to the conversation is ", "output": "A", "all_outputs": ["A"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["found out this morning that my nexus 5x is in bootloop . google says that it is a common problem with this phone . thanks @lgus @android"], "response_list": ["hi <USER> , we 're sorry to hear this . please let us know if there 's anything we can do to help .", "roger the cabin boy", "our apologies for the delay , <USER> . we 'll have you on your way as soon as we can .", "it's a."], "metric_score": [{"USR-MLM": -1.9653764963150024}, {"USR-MLM": -2.8184118270874023}, {"USR-MLM": -2.2635433673858643}, {"USR-MLM": -2.9770607948303223}]}
{"input": "[CONTEXT] nice . i enjoy taking walks around my neighbor hood . [ENDOFTURN] i wish i had time for walks . my job at the bank keeps me busy . [RESPONSE] we are sorry to hear that . please send us a dm so we can look into this for you . [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Select the right option: is the response is a good follow-up response? ", "index": 66771, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: You will be given a dialogue context and a response. Choose if the response is a contextual response to the context. \nInput: [CONTEXT] nice . i enjoy taking walks around my neighbor hood . [ENDOFTURN] i wish i had time for walks . my job at the bank keeps me busy . [RESPONSE] we are sorry to hear that . please send us a dm so we can look into this for you . [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Select the right option: is the response is a good follow-up response? ", "output": "no", "all_outputs": ["no"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["nice . i enjoy taking walks around my neighbor hood .", "i wish i had time for walks . my job at the bank keeps me busy ."], "response_list": ["we are sorry to hear that . please send us a dm so we can look into this for you ."], "metric_score": [{"USR-MLM": -1.0831791162490845}]}
{"input": "[CONTEXT] i rang up to make a complaint . the lady didn 't take my details . i spent $ 40 not happy [RESPONSE] hello ! we have the perfect meals to combine with working out ! take 40 % off : <URL> <URL> [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response a good response to the provided dialogue context? ", "index": 24117, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: You will be given a dialogue context and a response. Choose if the response is a contextual response to the context. \nInput: [CONTEXT] i rang up to make a complaint . the lady didn 't take my details . i spent $ 40 not happy [RESPONSE] hello ! we have the perfect meals to combine with working out ! take 40 % off : <URL> <URL> [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response a good response to the provided dialogue context? ", "output": "no", "all_outputs": ["no"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["i rang up to make a complaint . the lady didn 't take my details . i spent $ 40 not happy"], "response_list": ["hello ! we have the perfect meals to combine with working out ! take 40 % off : <URL> <URL>"], "metric_score": [{"USR-MLM": -2.1201934814453125}]}
{"input": "[CONTEXT] i have a question about the subtotal what is the question if i bought something over 100 and the subtotal changes to 0:00 a couple days after i order it what does that mean ? what is the email address for your account or order number my bad [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: please dm us your order number and email address so we can look into this for you .", "index": 36555, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: In this task you will be shown a conversation followed by a response and score range. You need to give a appropriate rating to the response.\nInput: [CONTEXT] i have a question about the subtotal what is the question if i bought something over 100 and the subtotal changes to 0:00 a couple days after i order it what does that mean ? what is the email address for your account or order number my bad [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: please dm us your order number and email address so we can look into this for you .", "output": "1", "all_outputs": ["4.2"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] can i have 100 of these and sponsor you guys at my graduation <URL> [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: hello ! please email us at <E-MAIL> so that we may further assist you . thank you for reaching out to us .||||B: that 's what we like to hear !||||C: hi <USER> , please dm us your email address so we can look into this for you . thank you .||||D: i think the us is a bit of a stretch of the word. [QUESTION] The response which is the best follow-up to the conversation is ", "index": 24215, "split": "train", "classes_in_options": ["A", "B", "C", "D"], "candidates": ["hello ! please email us at <E-MAIL> so that we may further assist you . thank you for reaching out to us .", "that 's what we like to hear !", "hi <USER> , please dm us your email address so we can look into this for you . thank you .", "i think the us is a bit of a stretch of the word."], "dataset": "eval", "task": "eval_ranking", "prompt": "Instruction: Select the best response from the provided responses to a conversation\nInput: [CONTEXT] can i have 100 of these and sponsor you guys at my graduation <URL> [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: hello ! please email us at <E-MAIL> so that we may further assist you . thank you for reaching out to us .||||B: that 's what we like to hear !||||C: hi <USER> , please dm us your email address so we can look into this for you . thank you .||||D: i think the us is a bit of a stretch of the word. [QUESTION] The response which is the best follow-up to the conversation is ", "output": "A", "all_outputs": ["A"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["can i have 100 of these and sponsor you guys at my graduation <URL>"], "response_list": ["hello ! please email us at <E-MAIL> so that we may further assist you . thank you for reaching out to us .", "that 's what we like to hear !", "hi <USER> , please dm us your email address so we can look into this for you . thank you .", "i think the us is a bit of a stretch of the word."], "metric_score": [{"USR-MLM": -2.2291696071624756}, {"USR-MLM": -3.0697717666625977}, {"USR-MLM": -2.498500108718872}, {"USR-MLM": -2.82867693901062}]}
{"input": "[CONTEXT] . @enbridgegasnews at 9 p . m . had 4 men at my door asking to come in to check ventilation . said it was on our #enbridge bill . refused entry . [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: please share your contact details via dm , one of our representative will get in touch with you soon <URL>||||B: hi <USER> , we 're sorry to hear this . please dm us your email address so we can look into this for you . thanks .||||C: hi <USER> , i 'm sorry to hear this . please can you dm me your full address and i will look into this for you . thanks .||||D: happy birthday , <USER> ! [QUESTION] The most appropriate response to the conversation is ", "index": 26213, "split": "train", "classes_in_options": ["A", "B", "C", "D"], "candidates": ["please share your contact details via dm , one of our representative will get in touch with you soon <URL>", "hi <USER> , we 're sorry to hear this . please dm us your email address so we can look into this for you . thanks .", "hi <USER> , i 'm sorry to hear this . please can you dm me your full address and i will look into this for you . thanks .", "happy birthday , <USER> !"], "dataset": "eval", "task": "eval_ranking", "prompt": "Instruction: In this task you will be shown a conversation followed by some responses. You need to choose the best response from the provided responses. \nInput: [CONTEXT] . @enbridgegasnews at 9 p . m . had 4 men at my door asking to come in to check ventilation . said it was on our #enbridge bill . refused entry . [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: please share your contact details via dm , one of our representative will get in touch with you soon <URL>||||B: hi <USER> , we 're sorry to hear this . please dm us your email address so we can look into this for you . thanks .||||C: hi <USER> , i 'm sorry to hear this . please can you dm me your full address and i will look into this for you . thanks .||||D: happy birthday , <USER> ! [QUESTION] The most appropriate response to the conversation is ", "output": "C", "all_outputs": ["C"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": [". @enbridgegasnews at 9 p . m . had 4 men at my door asking to come in to check ventilation . said it was on our #enbridge bill . refused entry ."], "response_list": ["please share your contact details via dm , one of our representative will get in touch with you soon <URL>", "hi <USER> , we 're sorry to hear this . please dm us your email address so we can look into this for you . thanks .", "hi <USER> , i 'm sorry to hear this . please can you dm me your full address and i will look into this for you . thanks .", "happy birthday , <USER> !"], "metric_score": [{"USR-MLM": -2.6640465259552}, {"USR-MLM": -2.2053847312927246}, {"USR-MLM": -2.470557451248169}, {"USR-MLM": -2.9715962409973145}]}
{"input": "[CONTEXT] til famous , nicki minaj fired approximately fifteen jobs discourtesy customers. mean , angel , likes customers? business owners thrive them. [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the relevance to the following response: that's a pretty good job. i'm pretty sure it's like a lot more than $11,000.", "index": 24149, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Given a conversation, a response to the conversation, and a score range, return a rating to the response within in score range\nInput: [CONTEXT] til famous , nicki minaj fired approximately fifteen jobs discourtesy customers. mean , angel , likes customers? business owners thrive them. [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the relevance to the following response: that's a pretty good job. i'm pretty sure it's like a lot more than $11,000.", "output": "5", "all_outputs": ["2.6666666666666665"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] hey @ttchelps looking for a 502 or 503 at bingham loop . any eta ? [ENDOFTURN] apologies <USER> , there should be vehicles due , were you able to board ? ^ ra \ud83d\ude80 [ENDOFTURN] no , there is nothing here going downtown . [RESPONSE] hi <USER> , we are sorry to hear this . please dm us your contact details so we can look into this for you . thanks . [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response contextual? ", "index": 36061, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: In this task you will be shown a dialogue context followed by a response. You need to predict if the response is a good follow-up to the context. \nInput: [CONTEXT] hey @ttchelps looking for a 502 or 503 at bingham loop . any eta ? [ENDOFTURN] apologies <USER> , there should be vehicles due , were you able to board ? ^ ra \ud83d\ude80 [ENDOFTURN] no , there is nothing here going downtown . [RESPONSE] hi <USER> , we are sorry to hear this . please dm us your contact details so we can look into this for you . thanks . [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response contextual? ", "output": "yes", "all_outputs": ["no"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["hey @ttchelps looking for a 502 or 503 at bingham loop . any eta ?", "apologies <USER> , there should be vehicles due , were you able to board ? ^ ra \ud83d\ude80", "no , there is nothing here going downtown ."], "response_list": ["hi <USER> , we are sorry to hear this . please dm us your contact details so we can look into this for you . thanks ."], "metric_score": [{"USR-MLM": -3.1621148586273193}]}
{"input": "[CONTEXT] hi there ! posting pics on linkedin on #cxsocial still not possible . no change from @engagor i regret ? [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: enjoy !||||B: hi <USER> , we 're sorry to hear this . please dm us your order number so we can look into this for you . thanks !||||C: that is great to hear , thank you for the compliment ! we operate this location and will let our team know .||||D: thanks for the kind words , <USER> ! we 're glad to hear it ! [QUESTION] The response which is the best follow-up to the conversation is ", "index": 20173, "split": "train", "classes_in_options": ["A", "B", "C", "D"], "candidates": ["enjoy !", "hi <USER> , we 're sorry to hear this . please dm us your order number so we can look into this for you . thanks !", "that is great to hear , thank you for the compliment ! we operate this location and will let our team know .", "thanks for the kind words , <USER> ! we 're glad to hear it !"], "dataset": "eval", "task": "eval_ranking", "prompt": "Instruction: Given a conversation and some responses to the conversation, select the most appropriate response \nInput: [CONTEXT] hi there ! posting pics on linkedin on #cxsocial still not possible . no change from @engagor i regret ? [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: enjoy !||||B: hi <USER> , we 're sorry to hear this . please dm us your order number so we can look into this for you . thanks !||||C: that is great to hear , thank you for the compliment ! we operate this location and will let our team know .||||D: thanks for the kind words , <USER> ! we 're glad to hear it ! [QUESTION] The response which is the best follow-up to the conversation is ", "output": "B", "all_outputs": ["B"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["hi there ! posting pics on linkedin on #cxsocial still not possible . no change from @engagor i regret ?"], "response_list": ["enjoy !", "hi <USER> , we 're sorry to hear this . please dm us your order number so we can look into this for you . thanks !", "that is great to hear , thank you for the compliment ! we operate this location and will let our team know .", "thanks for the kind words , <USER> ! we 're glad to hear it !"], "metric_score": [{"USR-MLM": -3.9440200328826904}, {"USR-MLM": -3.05554461479187}, {"USR-MLM": -3.3517539501190186}, {"USR-MLM": -3.245595932006836}]}
{"input": "[CONTEXT] thanks @pncvwallet and @americanexpress for notifying me that my $ 0.00 bill is past due [ENDOFTURN] a past due notice is sent if no payment is made . we 've passed the feedback along . plz let us know if we can assist further ! [ENDOFTURN] yeah @americanexpress sent a $ 0 bill , today , with a due date of yesterday . so that was weird . [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: i don't know what you mean.||||B: hi <USER> , please send us a direct message with your registered email address . thanks , stacey <URL>||||C: please send us a dm with your account info so we can look into this for you .||||D: hi <USER> , we 're sorry to hear this . can you please dm us your email address so we can look into this for you ? thanks ! [QUESTION] The most appropriate response to the conversation is ", "index": 10195, "split": "train", "classes_in_options": ["A", "B", "C", "D"], "candidates": ["i don't know what you mean.", "hi <USER> , please send us a direct message with your registered email address . thanks , stacey <URL>", "please send us a dm with your account info so we can look into this for you .", "hi <USER> , we 're sorry to hear this . can you please dm us your email address so we can look into this for you ? thanks !"], "dataset": "eval", "task": "eval_ranking", "prompt": "Instruction: Given a conversation and some responses to the conversation, select the most appropriate response \nInput: [CONTEXT] thanks @pncvwallet and @americanexpress for notifying me that my $ 0.00 bill is past due [ENDOFTURN] a past due notice is sent if no payment is made . we 've passed the feedback along . plz let us know if we can assist further ! [ENDOFTURN] yeah @americanexpress sent a $ 0 bill , today , with a due date of yesterday . so that was weird . [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: i don't know what you mean.||||B: hi <USER> , please send us a direct message with your registered email address . thanks , stacey <URL>||||C: please send us a dm with your account info so we can look into this for you .||||D: hi <USER> , we 're sorry to hear this . can you please dm us your email address so we can look into this for you ? thanks ! [QUESTION] The most appropriate response to the conversation is ", "output": "B", "all_outputs": ["C"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["thanks @pncvwallet and @americanexpress for notifying me that my $ 0.00 bill is past due", "a past due notice is sent if no payment is made . we 've passed the feedback along . plz let us know if we can assist further !", "yeah @americanexpress sent a $ 0 bill , today , with a due date of yesterday . so that was weird ."], "response_list": ["i don't know what you mean.", "hi <USER> , please send us a direct message with your registered email address . thanks , stacey <URL>", "please send us a dm with your account info so we can look into this for you .", "hi <USER> , we 're sorry to hear this . can you please dm us your email address so we can look into this for you ? thanks !"], "metric_score": [{"USR-MLM": -1.8170398473739624}, {"USR-MLM": -2.0405642986297607}, {"USR-MLM": -1.9566490650177002}, {"USR-MLM": -1.7803410291671753}]}
{"input": "[CONTEXT] no thanks to @fedex for failing to deliver a package with the excuse \" customer not available \" when somebody was at home waiting for it . [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: we are sorry to hear that . please send us a dm so we can look into this for you .||||B: my apologies for any inconvenience . please dm us the details to @fedexcanadahelp so i can assist you further . thank you||||C: glad to hear you 're enjoying the movie , <USER> ! :)||||D: hi <USER> , i 'm sorry to hear this . please can you dm me your details and i will look into this for you . thanks , [QUESTION] The correct response is ", "index": 5621, "split": "train", "classes_in_options": ["A", "B", "C", "D"], "candidates": ["we are sorry to hear that . please send us a dm so we can look into this for you .", "my apologies for any inconvenience . please dm us the details to @fedexcanadahelp so i can assist you further . thank you", "glad to hear you 're enjoying the movie , <USER> ! :)", "hi <USER> , i 'm sorry to hear this . please can you dm me your details and i will look into this for you . thanks ,"], "dataset": "eval", "task": "eval_ranking", "prompt": "Instruction: In this task you will be shown a conversation followed by some responses. You need to choose the best response from the provided responses. \nInput: [CONTEXT] no thanks to @fedex for failing to deliver a package with the excuse \" customer not available \" when somebody was at home waiting for it . [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: we are sorry to hear that . please send us a dm so we can look into this for you .||||B: my apologies for any inconvenience . please dm us the details to @fedexcanadahelp so i can assist you further . thank you||||C: glad to hear you 're enjoying the movie , <USER> ! :)||||D: hi <USER> , i 'm sorry to hear this . please can you dm me your details and i will look into this for you . thanks , [QUESTION] The correct response is ", "output": "B", "all_outputs": ["B"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["no thanks to @fedex for failing to deliver a package with the excuse \" customer not available \" when somebody was at home waiting for it ."], "response_list": ["we are sorry to hear that . please send us a dm so we can look into this for you .", "my apologies for any inconvenience . please dm us the details to @fedexcanadahelp so i can assist you further . thank you", "glad to hear you 're enjoying the movie , <USER> ! :)", "hi <USER> , i 'm sorry to hear this . please can you dm me your details and i will look into this for you . thanks ,"], "metric_score": [{"USR-MLM": -1.5973063707351685}, {"USR-MLM": -1.6712205410003662}, {"USR-MLM": -2.218141555786133}, {"USR-MLM": -2.2375619411468506}]}
{"input": "[CONTEXT] Hi how are you today? Great, Living in Colorado I'm always happy! What do you do for a living? mechanical engineer what do you do? What city are you from? Boulder. What do you do? Do you like music? I do No, do you? Do you have any hobbies? No do you? I play piano and sing, do you? [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 0 to 4 about the avoid_rep to the following response: I hike and rock climb. I'm athletic and good looking.", "index": 3075, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Given a conversation, a response to the conversation, and a score range, return a rating to the response within in score range\nInput: [CONTEXT] Hi how are you today? Great, Living in Colorado I'm always happy! What do you do for a living? mechanical engineer what do you do? What city are you from? Boulder. What do you do? Do you like music? I do No, do you? Do you have any hobbies? No do you? I play piano and sing, do you? [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 0 to 4 about the avoid_rep to the following response: I hike and rock climb. I'm athletic and good looking.", "output": "9", "all_outputs": ["2.0"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] will size 6-9 months be coming back in stock before christmas ? i 'm in love with this sleepsuit ! ! \u2639 \ufe0f <URL> [RESPONSE] hi <USER> , we 're sorry to hear this . please dm us with more details so we can look into this for you . thanks . [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response contextual? ", "index": 59197, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: In this task you will be shown a dialogue context followed by a response. You need to predict if the response is a good follow-up to the context. \nInput: [CONTEXT] will size 6-9 months be coming back in stock before christmas ? i 'm in love with this sleepsuit ! ! \u2639 \ufe0f <URL> [RESPONSE] hi <USER> , we 're sorry to hear this . please dm us with more details so we can look into this for you . thanks . [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response contextual? ", "output": "no", "all_outputs": ["no"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["will size 6-9 months be coming back in stock before christmas ? i 'm in love with this sleepsuit ! ! \u2639 \ufe0f <URL>"], "response_list": ["hi <USER> , we 're sorry to hear this . please dm us with more details so we can look into this for you . thanks ."], "metric_score": [{"USR-MLM": -2.255815029144287}]}
{"input": "[CONTEXT] til vietnam war 800 murders attempted murders superior officers enlisted soldiers investigated. term ' fragging ' coined due popular use fragmentation grenades commit murders. [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the informativeness to the following response: i've never heard of this. it was a good thing to have read the atomic bomb.", "index": 18768, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Return a score in the provided range which scores the response to a conversation \nInput: [CONTEXT] til vietnam war 800 murders attempted murders superior officers enlisted soldiers investigated. term ' fragging ' coined due popular use fragmentation grenades commit murders. [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the informativeness to the following response: i've never heard of this. it was a good thing to have read the atomic bomb.", "output": "i remember reading about it. didn't soldiers get killed by fracking?", "all_outputs": ["1.0"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] i have a reservation for a single with bath . we are sorry , but single rooms have been occupied . what 's the room rate ? it is a little expensive for me , do you have any other rooms ? then how about this room , with just shower ? may i see the room ? i ' ll take this room . is the rate for the room only ? [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the grammar to the following response: yes , it is .", "index": 42230, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Given a conversation, a response to the conversation, and a score range, return a rating to the response within in score range\nInput: [CONTEXT] i have a reservation for a single with bath . we are sorry , but single rooms have been occupied . what 's the room rate ? it is a little expensive for me , do you have any other rooms ? then how about this room , with just shower ? may i see the room ? i ' ll take this room . is the rate for the room only ? [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the grammar to the following response: yes , it is .", "output": "no, it is.", "all_outputs": ["4.75"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] \" turning your marketing upside down : why you should put more focus on existing customers \" <URL> <URL> [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: thanks for sharing !", "index": 49283, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Return a score in the provided range which scores the response to a conversation \nInput: [CONTEXT] \" turning your marketing upside down : why you should put more focus on existing customers \" <URL> <URL> [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: thanks for sharing !", "output": "ah, it looks like you're an assistant. thanks for sharing!", "all_outputs": ["3.7"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] til plato gave definition man as\" featherless bipeds ,\" diogenes plucked chicken brought plato's academy , saying ,\" behold! i've brought man ,\" academy added\" broad flat nails\" definition. [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the informativeness to the following response: we said featherless, not plucked. go jerk off in the street you weirdo.", "index": 46632, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Given a conversation, a response to the conversation, and a score range, return a rating to the response within in score range\nInput: [CONTEXT] til plato gave definition man as\" featherless bipeds ,\" diogenes plucked chicken brought plato's academy , saying ,\" behold! i've brought man ,\" academy added\" broad flat nails\" definition. [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the informativeness to the following response: we said featherless, not plucked. go jerk off in the street you weirdo.", "output": "1", "all_outputs": ["4.0"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] when will the link got this be up ? i can 't find it on your site <URL> [RESPONSE] hi <USER> , we are looking into this for you and will get back to you as soon as we can . thanks , [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response a good response to the provided dialogue context? ", "index": 72934, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: Given a conversation and a response to the conversation, is it a relevant response to the context?\nInput: [CONTEXT] when will the link got this be up ? i can 't find it on your site <URL> [RESPONSE] hi <USER> , we are looking into this for you and will get back to you as soon as we can . thanks , [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response a good response to the provided dialogue context? ", "output": "yes", "all_outputs": ["yes"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["when will the link got this be up ? i can 't find it on your site <URL>"], "response_list": ["hi <USER> , we are looking into this for you and will get back to you as soon as we can . thanks ,"], "metric_score": [{"USR-MLM": -1.9577885866165161}]}
{"input": "[CONTEXT] tried 3 different adresses to register for your 25 % rebate \u2013 nothing happens . how can i get the coupon ? [RESPONSE] we 're sorry to hear this . please dm us your email address and we will be happy to assist you further . thanks ! [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response contextual? ", "index": 30726, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: You will be given a dialogue context and a response. Choose if the response is a contextual response to the context. \nInput: [CONTEXT] tried 3 different adresses to register for your 25 % rebate \u2013 nothing happens . how can i get the coupon ? [RESPONSE] we 're sorry to hear this . please dm us your email address and we will be happy to assist you further . thanks ! [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response contextual? ", "output": "no", "all_outputs": ["yes"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["tried 3 different adresses to register for your 25 % rebate \u2013 nothing happens . how can i get the coupon ?"], "response_list": ["we 're sorry to hear this . please dm us your email address and we will be happy to assist you further . thanks !"], "metric_score": [{"USR-MLM": -1.8675715923309326}]}
{"input": "[CONTEXT] til ted kaczynski ( unabomber ) updated alumni information harvard 2012 : called eight life sentences\" awards\" current occupation as\" prisoner\" [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the informativeness to the following response: the \"alumni ' ted bundy.\" i'm sure he was a doctor.", "index": 50302, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Given a conversation, a response to the conversation, and a score range, return a rating to the response within in score range\nInput: [CONTEXT] til ted kaczynski ( unabomber ) updated alumni information harvard 2012 : called eight life sentences\" awards\" current occupation as\" prisoner\" [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the informativeness to the following response: the \"alumni ' ted bundy.\" i'm sure he was a doctor.", "output": "yes.", "all_outputs": ["3.6666666666666665"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] Hi Hi there. How are you today Ah. My logic and cognitive functions are normal. What is the weather in bay area now Oh.I hope it's sunny in bay area today. Do you know what are recent popular movies? I am trying to find one to watch during weekend. Any suggestions? popular movies = movies = A movie is a sequence of celluloid frames depicting a story or animation. . One can be found between zero and two. First you must download me to your personal computer. haha I am not asking what is the definition of movie:) :-) I'm glad you got a laugh out of it. What are you asking? I am looking for movie suggestions Have you tried looking in a meeting? Sorry i do not get it There is no need to apologise. Oh I'm sorry. Perhaps I can explain it again better. yes sounds good Which part are you confused about? Which part are you confused about? why should I try to look in a meeting? Because if you don't try something, you will never know what would have happened. [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 0 to 4 about the understanding to the following response: That is true", "index": 52644, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Given a conversation, a response to the conversation, and a score range, return a rating to the response within in score range\nInput: [CONTEXT] Hi Hi there. How are you today Ah. My logic and cognitive functions are normal. What is the weather in bay area now Oh.I hope it's sunny in bay area today. Do you know what are recent popular movies? I am trying to find one to watch during weekend. Any suggestions? popular movies = movies = A movie is a sequence of celluloid frames depicting a story or animation. . One can be found between zero and two. First you must download me to your personal computer. haha I am not asking what is the definition of movie:) :-) I'm glad you got a laugh out of it. What are you asking? I am looking for movie suggestions Have you tried looking in a meeting? Sorry i do not get it There is no need to apologise. Oh I'm sorry. Perhaps I can explain it again better. yes sounds good Which part are you confused about? Which part are you confused about? why should I try to look in a meeting? Because if you don't try something, you will never know what would have happened. [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 0 to 4 about the understanding to the following response: That is true", "output": "haha funny you :) I think you're right. What are you interested in watching?", "all_outputs": ["0.6"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] til anne heche drove desert , hiked stranger's house , took shower , announced local sherrifs god going take everyone back heaven spaceship [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: if you can pop us a dm with your order details , we 'll see what we can do for you . <URL>||||B: i m sure she was a virgin.||||C: we 're here to help ! send us a dm and we 'll see what we can do to help . * joano||||D: i tell the guy the rest of the gun... i mean. [QUESTION] The correct response is ", "index": 20320, "split": "train", "classes_in_options": ["A", "B", "C", "D"], "candidates": ["if you can pop us a dm with your order details , we 'll see what we can do for you . <URL>", "i m sure she was a virgin.", "we 're here to help ! send us a dm and we 'll see what we can do to help . * joano", "i tell the guy the rest of the gun... i mean."], "dataset": "eval", "task": "eval_ranking", "prompt": "Instruction: In this task you will be shown a conversation followed by some responses. You need to choose the best response from the provided responses. \nInput: [CONTEXT] til anne heche drove desert , hiked stranger's house , took shower , announced local sherrifs god going take everyone back heaven spaceship [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: if you can pop us a dm with your order details , we 'll see what we can do for you . <URL>||||B: i m sure she was a virgin.||||C: we 're here to help ! send us a dm and we 'll see what we can do to help . * joano||||D: i tell the guy the rest of the gun... i mean. [QUESTION] The correct response is ", "output": "B", "all_outputs": ["B"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["til anne heche drove desert , hiked stranger's house , took shower , announced local sherrifs god going take everyone back heaven spaceship"], "response_list": ["if you can pop us a dm with your order details , we 'll see what we can do for you . <URL>", "i m sure she was a virgin.", "we 're here to help ! send us a dm and we 'll see what we can do to help . * joano", "i tell the guy the rest of the gun... i mean."], "metric_score": [{"USR-MLM": -3.64359188079834}, {"USR-MLM": -4.039816379547119}, {"USR-MLM": -3.48677659034729}, {"USR-MLM": -4.400266170501709}]}
{"input": "[CONTEXT] excellent service today from green flag , efficient , polite & friendly [RESPONSE] thank you . i will look into this for you . thank you for letting us know . lucy tnt uk [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response contextual? ", "index": 46271, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: Given a conversation and a response to the conversation, is the response a good response to the context?\nInput: [CONTEXT] excellent service today from green flag , efficient , polite & friendly [RESPONSE] thank you . i will look into this for you . thank you for letting us know . lucy tnt uk [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response contextual? ", "output": "no", "all_outputs": ["no"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["excellent service today from green flag , efficient , polite & friendly"], "response_list": ["thank you . i will look into this for you . thank you for letting us know . lucy tnt uk"], "metric_score": [{"USR-MLM": -2.161348819732666}]}
{"input": "[CONTEXT] i love hands on work , like gardening . my parents adopted me , old parents [ENDOFTURN] i like to climb trees an play on the playground . [RESPONSE] pretty ! when i'm not busy coaching girls volley ball i do crosswords and crochet [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Select the right option: is the response is a good follow-up response? ", "index": 39886, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: Select if the provided response follow the provided conversationSelect if the provided response a good response to the provided dialogue context.\nInput: [CONTEXT] i love hands on work , like gardening . my parents adopted me , old parents [ENDOFTURN] i like to climb trees an play on the playground . [RESPONSE] pretty ! when i'm not busy coaching girls volley ball i do crosswords and crochet [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Select the right option: is the response is a good follow-up response? ", "output": "yes", "all_outputs": ["yes"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["i love hands on work , like gardening . my parents adopted me , old parents", "i like to climb trees an play on the playground ."], "response_list": ["pretty ! when i'm not busy coaching girls volley ball i do crosswords and crochet"], "metric_score": [{"USR-MLM": -2.178422212600708}]}
{"input": "[CONTEXT] it was supposed to be here thirty minutes ago . [ENDOFTURN] i think it 'll be here pretty soon . [ENDOFTURN] i need to get to work , so it better . [ENDOFTURN] i really do hate public transportation . [ENDOFTURN] i agree , it 's just never on time . [RESPONSE] you 're right . [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response a good response to the provided dialogue context? ", "index": 20024, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: Given a conversation and a response to the conversation, is it a relevant response to the context?\nInput: [CONTEXT] it was supposed to be here thirty minutes ago . [ENDOFTURN] i think it 'll be here pretty soon . [ENDOFTURN] i need to get to work , so it better . [ENDOFTURN] i really do hate public transportation . [ENDOFTURN] i agree , it 's just never on time . [RESPONSE] you 're right . [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response a good response to the provided dialogue context? ", "output": "yes", "all_outputs": ["yes"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["it was supposed to be here thirty minutes ago .", "i think it 'll be here pretty soon .", "i need to get to work , so it better .", "i really do hate public transportation .", "i agree , it 's just never on time ."], "response_list": ["you 're right ."], "metric_score": [{"USR-MLM": -0.9483759999275208}]}
{"input": "[CONTEXT] bad boy burrito using @warbsnewburnbh #glutenfree wraps #food #healthyeating #eatclean <URL> [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: that 's what we like to hear , <USER> ! we 'll pass it along to the right team . thanks for letting us know !||||B: as she has no idea that she can do as well, that has been able to work in the war||||C: hi <USER> , i 'm sorry to hear this . please can you dm me your full address and i will look into this for you . thanks .||||D: a constant reminder to persevere. [QUESTION] The response which is the best follow-up to the conversation is ", "index": 7071, "split": "train", "classes_in_options": ["A", "B", "C", "D"], "candidates": ["that 's what we like to hear , <USER> ! we 'll pass it along to the right team . thanks for letting us know !", "as she has no idea that she can do as well, that has been able to work in the war", "hi <USER> , i 'm sorry to hear this . please can you dm me your full address and i will look into this for you . thanks .", "a constant reminder to persevere."], "dataset": "eval", "task": "eval_ranking", "prompt": "Instruction: Select the best response from the provided responses to a conversation\nInput: [CONTEXT] bad boy burrito using @warbsnewburnbh #glutenfree wraps #food #healthyeating #eatclean <URL> [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: that 's what we like to hear , <USER> ! we 'll pass it along to the right team . thanks for letting us know !||||B: as she has no idea that she can do as well, that has been able to work in the war||||C: hi <USER> , i 'm sorry to hear this . please can you dm me your full address and i will look into this for you . thanks .||||D: a constant reminder to persevere. [QUESTION] The response which is the best follow-up to the conversation is ", "output": "A", "all_outputs": ["A"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["bad boy burrito using @warbsnewburnbh #glutenfree wraps #food #healthyeating #eatclean <URL>"], "response_list": ["that 's what we like to hear , <USER> ! we 'll pass it along to the right team . thanks for letting us know !", "as she has no idea that she can do as well, that has been able to work in the war", "hi <USER> , i 'm sorry to hear this . please can you dm me your full address and i will look into this for you . thanks .", "a constant reminder to persevere."], "metric_score": [{"USR-MLM": -3.000977039337158}, {"USR-MLM": -3.7536399364471436}, {"USR-MLM": -3.3012917041778564}, {"USR-MLM": -3.9322240352630615}]}
{"input": "[CONTEXT] ordered a box and a zinger black burger . pretty disappointed after driving 25 mins home to work out zinger black is missing . [ENDOFTURN] hi <USER> , sorry to hear that . please tell us all the info at <URL> and we 'll follow it up . [ENDOFTURN] guys . i emailed as you asked . no response . today i got a feedback email to ask how it went . are you guys deadset ? [ENDOFTURN] sorry about that . do you have the reference number from your online complaint so we can follow this up ? [ENDOFTURN] 514217 seriously guys . it 's been weeks . i 've heard nothing . i just want my money back for what wasn 't given on my order . never again . [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: hi <USER> , we 're sorry to hear this . please dm us your account number and we will look into this for you . thanks .||||B: five nights at candy's: brother location hype||||C: great photo ! thanks for sharing !||||D: hi <USER> , we are sorry to hear this . please dm us your email address and we will look into this for you . [QUESTION] The most appropriate response to the conversation is ", "index": 25298, "split": "train", "classes_in_options": ["A", "B", "C", "D"], "candidates": ["hi <USER> , we 're sorry to hear this . please dm us your account number and we will look into this for you . thanks .", "five nights at candy's: brother location hype", "great photo ! thanks for sharing !", "hi <USER> , we are sorry to hear this . please dm us your email address and we will look into this for you ."], "dataset": "eval", "task": "eval_ranking", "prompt": "Instruction: Select the best response from the provided responses to a conversation\nInput: [CONTEXT] ordered a box and a zinger black burger . pretty disappointed after driving 25 mins home to work out zinger black is missing . [ENDOFTURN] hi <USER> , sorry to hear that . please tell us all the info at <URL> and we 'll follow it up . [ENDOFTURN] guys . i emailed as you asked . no response . today i got a feedback email to ask how it went . are you guys deadset ? [ENDOFTURN] sorry about that . do you have the reference number from your online complaint so we can follow this up ? [ENDOFTURN] 514217 seriously guys . it 's been weeks . i 've heard nothing . i just want my money back for what wasn 't given on my order . never again . [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: hi <USER> , we 're sorry to hear this . please dm us your account number and we will look into this for you . thanks .||||B: five nights at candy's: brother location hype||||C: great photo ! thanks for sharing !||||D: hi <USER> , we are sorry to hear this . please dm us your email address and we will look into this for you . [QUESTION] The most appropriate response to the conversation is ", "output": "A", "all_outputs": ["D"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["ordered a box and a zinger black burger . pretty disappointed after driving 25 mins home to work out zinger black is missing .", "hi <USER> , sorry to hear that . please tell us all the info at <URL> and we 'll follow it up .", "guys . i emailed as you asked . no response . today i got a feedback email to ask how it went . are you guys deadset ?", "sorry about that . do you have the reference number from your online complaint so we can follow this up ?", "514217 seriously guys . it 's been weeks . i 've heard nothing . i just want my money back for what wasn 't given on my order . never again ."], "response_list": ["hi <USER> , we 're sorry to hear this . please dm us your account number and we will look into this for you . thanks .", "five nights at candy's: brother location hype", "great photo ! thanks for sharing !", "hi <USER> , we are sorry to hear this . please dm us your email address and we will look into this for you ."], "metric_score": [{"USR-MLM": -2.12208890914917}, {"USR-MLM": -3.149170398712158}, {"USR-MLM": -2.4754586219787598}, {"USR-MLM": -2.080864429473877}]}
{"input": "[CONTEXT] i 'm a 3rd year medical student who needs your help for a medical mission overseas ! [ENDOFTURN] hi ! pls email us at <E-MAIL> for more info . pls include your name , organization name & website . thanks ! [ENDOFTURN] thank you ! but <E-MAIL> is an undeliverable email address . is there another email i could reach it to ? [RESPONSE] i 'm sorry to hear that . i hope you have a great day . [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Select the right option: is the response is a good follow-up response? ", "index": 11953, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: In this task you will be shown a dialogue context followed by a response. You need to predict if the response is a good follow-up to the context. \nInput: [CONTEXT] i 'm a 3rd year medical student who needs your help for a medical mission overseas ! [ENDOFTURN] hi ! pls email us at <E-MAIL> for more info . pls include your name , organization name & website . thanks ! [ENDOFTURN] thank you ! but <E-MAIL> is an undeliverable email address . is there another email i could reach it to ? [RESPONSE] i 'm sorry to hear that . i hope you have a great day . [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Select the right option: is the response is a good follow-up response? ", "output": "no", "all_outputs": ["no"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["i 'm a 3rd year medical student who needs your help for a medical mission overseas !", "hi ! pls email us at <E-MAIL> for more info . pls include your name , organization name & website . thanks !", "thank you ! but <E-MAIL> is an undeliverable email address . is there another email i could reach it to ?"], "response_list": ["i 'm sorry to hear that . i hope you have a great day ."], "metric_score": [{"USR-MLM": -1.5566579103469849}]}
{"input": "[CONTEXT] Hi how are you today? Hello there. I am good. My name is Larry. How are you? I am good. Do you like kids? I do, probably because I'm a big kid myself. I still like comic books at my age What is your favorite superhero? Oh, my favorite superhero is spiderman. How about you? I love batman. What do you do for a living? I am a chef. I am always in the kitchen. What do you do? I work as a teacher. What about you? That's a good job. If I'm not in the kitchen then I'm out in my boat. What kind of boat is it? [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 0 to 4 about the persona_guess to the following response: It's a yacht. I'm a very successful chef.", "index": 10286, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Given a conversation, a response to the conversation, and a score range, return a rating to the response within in score range\nInput: [CONTEXT] Hi how are you today? Hello there. I am good. My name is Larry. How are you? I am good. Do you like kids? I do, probably because I'm a big kid myself. I still like comic books at my age What is your favorite superhero? Oh, my favorite superhero is spiderman. How about you? I love batman. What do you do for a living? I am a chef. I am always in the kitchen. What do you do? I work as a teacher. What about you? That's a good job. If I'm not in the kitchen then I'm out in my boat. What kind of boat is it? [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 0 to 4 about the persona_guess to the following response: It's a yacht. I'm a very successful chef.", "output": "I love that job. Do you work there?", "all_outputs": ["1.0"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] so excited to be part of the launch of the wakefieldeastern relief road ! <URL> [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: we 're sorry to hear this . please dm us your order number so we can look into this for you . thank you !||||B: hi <USER> , we are sorry to hear this . please dm us your contact details so we can look into this for you . thank you .||||C: we 're excited too !||||D: please send us your email address via dm so we can look into this for you . [QUESTION] The correct response is ", "index": 10123, "split": "train", "classes_in_options": ["A", "B", "C", "D"], "candidates": ["we 're sorry to hear this . please dm us your order number so we can look into this for you . thank you !", "hi <USER> , we are sorry to hear this . please dm us your contact details so we can look into this for you . thank you .", "we 're excited too !", "please send us your email address via dm so we can look into this for you ."], "dataset": "eval", "task": "eval_ranking", "prompt": "Instruction: Select the best response from the provided responses to a conversation\nInput: [CONTEXT] so excited to be part of the launch of the wakefieldeastern relief road ! <URL> [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: we 're sorry to hear this . please dm us your order number so we can look into this for you . thank you !||||B: hi <USER> , we are sorry to hear this . please dm us your contact details so we can look into this for you . thank you .||||C: we 're excited too !||||D: please send us your email address via dm so we can look into this for you . [QUESTION] The correct response is ", "output": "C", "all_outputs": ["C"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["so excited to be part of the launch of the wakefieldeastern relief road ! <URL>"], "response_list": ["we 're sorry to hear this . please dm us your order number so we can look into this for you . thank you !", "hi <USER> , we are sorry to hear this . please dm us your contact details so we can look into this for you . thank you .", "we 're excited too !", "please send us your email address via dm so we can look into this for you ."], "metric_score": [{"USR-MLM": -2.511855363845825}, {"USR-MLM": -2.2682743072509766}, {"USR-MLM": -2.6036036014556885}, {"USR-MLM": -2.479233503341675}]}
{"input": "[CONTEXT] #goodvaluehere - a positive attitude <URL> via @youtube [RESPONSE] that 's what we like to hear ! thanks for sharing this with us ! we 'll share it with our marketing team . [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Select the right option: is the response is a good follow-up response? ", "index": 29052, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: Given a conversation and a response to the conversation, is the response a good response to the context?\nInput: [CONTEXT] #goodvaluehere - a positive attitude <URL> via @youtube [RESPONSE] that 's what we like to hear ! thanks for sharing this with us ! we 'll share it with our marketing team . [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Select the right option: is the response is a good follow-up response? ", "output": "yes", "all_outputs": ["yes"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["#goodvaluehere - a positive attitude <URL> via @youtube"], "response_list": ["that 's what we like to hear ! thanks for sharing this with us ! we 'll share it with our marketing team ."], "metric_score": [{"USR-MLM": -1.965943694114685}]}
{"input": "[CONTEXT] tried to upgrade & fees were crazy @sprint just lost a sale & customer of 17yr [ENDOFTURN] reading this concerns us . we only want the best for our customers . how did you try to perform your upgrade ? [ENDOFTURN] in a store data fee damage fee taxes phone over $ 300 .. hello verizon a @sprint user since 1999 horrible customer loyalty [ENDOFTURN] we 'd hate to lose you . can you tell us what you were told in-store ? what phone are you looking to upgrade to ? let us know . [ENDOFTURN] the 7 [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: please dm us your contact info so we can look into this for you .||||B: we 're sorry to hear this . please dm us your confirmation code so we can take a closer look into this for you . <URL>||||C: oh no ! that 's not what we like to hear ! can you please dm @subway so that we can address this ?||||D: congratulations <USER> ! \ud83d\ude4c \ud83d\ude4c \ud83d\ude4c cara [QUESTION] The most appropriate response to the conversation is ", "index": 31930, "split": "train", "classes_in_options": ["A", "B", "C", "D"], "candidates": ["please dm us your contact info so we can look into this for you .", "we 're sorry to hear this . please dm us your confirmation code so we can take a closer look into this for you . <URL>", "oh no ! that 's not what we like to hear ! can you please dm @subway so that we can address this ?", "congratulations <USER> ! \ud83d\ude4c \ud83d\ude4c \ud83d\ude4c cara"], "dataset": "eval", "task": "eval_ranking", "prompt": "Instruction: In this task you will be shown a conversation followed by some responses. You need to choose the best response from the provided responses. \nInput: [CONTEXT] tried to upgrade & fees were crazy @sprint just lost a sale & customer of 17yr [ENDOFTURN] reading this concerns us . we only want the best for our customers . how did you try to perform your upgrade ? [ENDOFTURN] in a store data fee damage fee taxes phone over $ 300 .. hello verizon a @sprint user since 1999 horrible customer loyalty [ENDOFTURN] we 'd hate to lose you . can you tell us what you were told in-store ? what phone are you looking to upgrade to ? let us know . [ENDOFTURN] the 7 [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: please dm us your contact info so we can look into this for you .||||B: we 're sorry to hear this . please dm us your confirmation code so we can take a closer look into this for you . <URL>||||C: oh no ! that 's not what we like to hear ! can you please dm @subway so that we can address this ?||||D: congratulations <USER> ! \ud83d\ude4c \ud83d\ude4c \ud83d\ude4c cara [QUESTION] The most appropriate response to the conversation is ", "output": "A", "all_outputs": ["A"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["tried to upgrade & fees were crazy @sprint just lost a sale & customer of 17yr", "reading this concerns us . we only want the best for our customers . how did you try to perform your upgrade ?", "in a store data fee damage fee taxes phone over $ 300 .. hello verizon a @sprint user since 1999 horrible customer loyalty", "we 'd hate to lose you . can you tell us what you were told in-store ? what phone are you looking to upgrade to ? let us know .", "the 7"], "response_list": ["please dm us your contact info so we can look into this for you .", "we 're sorry to hear this . please dm us your confirmation code so we can take a closer look into this for you . <URL>", "oh no ! that 's not what we like to hear ! can you please dm @subway so that we can address this ?", "congratulations <USER> ! \ud83d\ude4c \ud83d\ude4c \ud83d\ude4c cara"], "metric_score": [{"USR-MLM": -3.0523226261138916}, {"USR-MLM": -2.8952693939208984}, {"USR-MLM": -3.0116515159606934}, {"USR-MLM": -3.3219287395477295}]}
{"input": "[CONTEXT] got email today to review products i never bought ... appears legit ... confused . thanks for reaching out . rate and review is linked to ikea family accounts . therefore , if you did not purchase the item , and received an email for review , you can discard of the email . we thank you for your understanding . thanks ! just making sure it wasn 't a spam email as the unsubscribe link looked odd compared to usual . [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: thanks for letting us know ! we 'll be sure to pass along your feedback to our marketing team . thanks for letting us know !", "index": 4513, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Return a score in the provided range which scores the response to a conversation \nInput: [CONTEXT] got email today to review products i never bought ... appears legit ... confused . thanks for reaching out . rate and review is linked to ikea family accounts . therefore , if you did not purchase the item , and received an email for review , you can discard of the email . we thank you for your understanding . thanks ! just making sure it wasn 't a spam email as the unsubscribe link looked odd compared to usual . [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: thanks for letting us know ! we 'll be sure to pass along your feedback to our marketing team . thanks for letting us know !", "output": "5", "all_outputs": ["3.8"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] I love reading. What is your favorite movie? [ENDOFTURN] I do not have a favorite move, but I like listening to country music [ENDOFTURN] What do you do for a living? [ENDOFTURN] I am a trucker. WHat do you do? [ENDOFTURN] What city are you from? [RESPONSE] I am from Louisville, KY [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response contextual? ", "index": 14524, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: In this task you will be shown a context followed by a response. You need to classify if the response is a good response to the context. \nInput: [CONTEXT] I love reading. What is your favorite movie? [ENDOFTURN] I do not have a favorite move, but I like listening to country music [ENDOFTURN] What do you do for a living? [ENDOFTURN] I am a trucker. WHat do you do? [ENDOFTURN] What city are you from? [RESPONSE] I am from Louisville, KY [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response contextual? ", "output": "yes", "all_outputs": ["yes"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["I love reading. What is your favorite movie?", "I do not have a favorite move, but I like listening to country music", "What do you do for a living?", "I am a trucker. WHat do you do?", "What city are you from?"], "response_list": ["I am from Louisville, KY"], "metric_score": [{"USR-MLM": -3.3342177867889404}]}
{"input": "[CONTEXT] fynn loves the yogurt bites . this is bag 1,634 ( an approx . exaggeration ) . #littlejourney #latenightsnack <URL> [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: thanks for the shout out ! we 're glad you enjoyed it !||||B: hi <USER> , we 're sorry to hear this . please send us a dm with your email address so we can look into this for you .||||C: it's the only thing that wikileaks that wikileaks is in sark.||||D: thanks for the love ! [QUESTION] The response which is the best follow-up to the conversation is ", "index": 6705, "split": "train", "classes_in_options": ["A", "B", "C", "D"], "candidates": ["thanks for the shout out ! we 're glad you enjoyed it !", "hi <USER> , we 're sorry to hear this . please send us a dm with your email address so we can look into this for you .", "it's the only thing that wikileaks that wikileaks is in sark.", "thanks for the love !"], "dataset": "eval", "task": "eval_ranking", "prompt": "Instruction: Given a conversation and some responses to the conversation, select the most appropriate response \nInput: [CONTEXT] fynn loves the yogurt bites . this is bag 1,634 ( an approx . exaggeration ) . #littlejourney #latenightsnack <URL> [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: thanks for the shout out ! we 're glad you enjoyed it !||||B: hi <USER> , we 're sorry to hear this . please send us a dm with your email address so we can look into this for you .||||C: it's the only thing that wikileaks that wikileaks is in sark.||||D: thanks for the love ! [QUESTION] The response which is the best follow-up to the conversation is ", "output": "A", "all_outputs": ["A"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["fynn loves the yogurt bites . this is bag 1,634 ( an approx . exaggeration ) . #littlejourney #latenightsnack <URL>"], "response_list": ["thanks for the shout out ! we 're glad you enjoyed it !", "hi <USER> , we 're sorry to hear this . please send us a dm with your email address so we can look into this for you .", "it's the only thing that wikileaks that wikileaks is in sark.", "thanks for the love !"], "metric_score": [{"USR-MLM": -3.184333324432373}, {"USR-MLM": -2.748598575592041}, {"USR-MLM": -3.7385060787200928}, {"USR-MLM": -3.890347480773926}]}
{"input": "[CONTEXT] done . please get back to me asap . rt @pldt_cares : @princesskitin please dm us your account details ( cont ) <URL> [RESPONSE] it'd gain a padder. [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response a good response to the provided dialogue context? ", "index": 72899, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: Given a conversation and a response to the conversation, select is the response is a good response to the context.\nInput: [CONTEXT] done . please get back to me asap . rt @pldt_cares : @princesskitin please dm us your account details ( cont ) <URL> [RESPONSE] it'd gain a padder. [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response a good response to the provided dialogue context? ", "output": "no", "all_outputs": ["no"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["done . please get back to me asap . rt @pldt_cares : @princesskitin please dm us your account details ( cont ) <URL>"], "response_list": ["it'd gain a padder."], "metric_score": [{"USR-MLM": -3.951873779296875}]}
{"input": "[CONTEXT] just had amazing service and a fantastic recovery driver dave ! so impressed with everything tonight ! thank you ! [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: thanks for the heads up , <USER> . we 'll be sure to pass this along to our leadership team for further review .||||B: hi <USER> , thank you for your kind feedback . i will pass this on to the store manager . thanks , hannah - land rover uk||||C: hi <USER> , please can you dm us your order number so we can look into this for you ? thanks ,||||D: thank you ! [QUESTION] The response which is the best follow-up to the conversation is ", "index": 16622, "split": "train", "classes_in_options": ["A", "B", "C", "D"], "candidates": ["thanks for the heads up , <USER> . we 'll be sure to pass this along to our leadership team for further review .", "hi <USER> , thank you for your kind feedback . i will pass this on to the store manager . thanks , hannah - land rover uk", "hi <USER> , please can you dm us your order number so we can look into this for you ? thanks ,", "thank you !"], "dataset": "eval", "task": "eval_ranking", "prompt": "Instruction: In this task you will be shown a conversation followed by some responses. You need to choose the best response from the provided responses. \nInput: [CONTEXT] just had amazing service and a fantastic recovery driver dave ! so impressed with everything tonight ! thank you ! [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: thanks for the heads up , <USER> . we 'll be sure to pass this along to our leadership team for further review .||||B: hi <USER> , thank you for your kind feedback . i will pass this on to the store manager . thanks , hannah - land rover uk||||C: hi <USER> , please can you dm us your order number so we can look into this for you ? thanks ,||||D: thank you ! [QUESTION] The response which is the best follow-up to the conversation is ", "output": "D", "all_outputs": ["B"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["just had amazing service and a fantastic recovery driver dave ! so impressed with everything tonight ! thank you !"], "response_list": ["thanks for the heads up , <USER> . we 'll be sure to pass this along to our leadership team for further review .", "hi <USER> , thank you for your kind feedback . i will pass this on to the store manager . thanks , hannah - land rover uk", "hi <USER> , please can you dm us your order number so we can look into this for you ? thanks ,", "thank you !"], "metric_score": [{"USR-MLM": -2.0578601360321045}, {"USR-MLM": -2.651918888092041}, {"USR-MLM": -2.5974597930908203}, {"USR-MLM": -2.1230320930480957}]}
{"input": "[CONTEXT] til steve jobs could avoided premature death cancer properly treated , refused 9 months , believing alternative-medicine diet would better. one steve jobs ' notable regrets. i'd regret death die beating grizzly fistfight i'd regret fuck die champion [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: and too dead to roll in all that lady bear poon", "index": 23408, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: In this task you will be shown a conversation followed by a response and score range. You need to give a appropriate rating to the response.\nInput: [CONTEXT] til steve jobs could avoided premature death cancer properly treated , refused 9 months , believing alternative-medicine diet would better. one steve jobs ' notable regrets. i'd regret death die beating grizzly fistfight i'd regret fuck die champion [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: and too dead to roll in all that lady bear poon", "output": "4", "all_outputs": ["4.0"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] Hi how are you today I'm doing good!!! What do you do for a living I like watching Mickey Mouse and playing with my friends. I like to take walks I do that sometimes on the playground! How old are you? I am 37 and I like to take walks I'm 7 and I like Disney! I like to take walks I like Frozen! I like to take walks [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 0 to 4 about the make_sense to the following response: I like being in the third grade!", "index": 39335, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Given a conversation, a response to the conversation, and a score range, return a rating to the response within in score range\nInput: [CONTEXT] Hi how are you today I'm doing good!!! What do you do for a living I like watching Mickey Mouse and playing with my friends. I like to take walks I do that sometimes on the playground! How old are you? I am 37 and I like to take walks I'm 7 and I like Disney! I like to take walks I like Frozen! I like to take walks [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 0 to 4 about the make_sense to the following response: I like being in the third grade!", "output": "3", "all_outputs": ["4.0"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] how are you ? im not happy I am good. Just listening to some rap music. do you believe in god ? I do. My favorite food is pizza. i hate pizza,its unhealthy Do you have any pets? no my wife left and took the kids and pets I have a cat named fred. such a cool name Thank you. It is a great name. its different [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 0 to 4 about the persona_guess to the following response: Tell me something about yourself.", "index": 26013, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Given a conversation, a response to the conversation, and a score range, return a rating to the response within in score range\nInput: [CONTEXT] how are you ? im not happy I am good. Just listening to some rap music. do you believe in god ? I do. My favorite food is pizza. i hate pizza,its unhealthy Do you have any pets? no my wife left and took the kids and pets I have a cat named fred. such a cool name Thank you. It is a great name. its different [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 0 to 4 about the persona_guess to the following response: Tell me something about yourself.", "output": "what do you do for fun?", "all_outputs": ["1.0"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] impressive customer service from @ulsterbank - instant , no quibble refund of a dodgy transaction . #thankyou <URL> [RESPONSE] thanks for the kind words , <USER> ! [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response contextual? ", "index": 32140, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: In this task you will be shown a dialogue context followed by a response. You need to predict if the response is a good follow-up to the context. \nInput: [CONTEXT] impressive customer service from @ulsterbank - instant , no quibble refund of a dodgy transaction . #thankyou <URL> [RESPONSE] thanks for the kind words , <USER> ! [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response contextual? ", "output": "yes", "all_outputs": ["yes"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["impressive customer service from @ulsterbank - instant , no quibble refund of a dodgy transaction . #thankyou <URL>"], "response_list": ["thanks for the kind words , <USER> !"], "metric_score": [{"USR-MLM": -3.0360000133514404}]}
{"input": "[CONTEXT] til table beer served belgian schools 1980s. proposed re-introduce low alcohol beer ( < 1.5 % abv ) schools healthier alternative softdrinks. [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: i m not sure how much beer is sold in belgium.", "index": 45160, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Given a conversation, a response to the conversation, and a score range, return a rating to the response within in score range\nInput: [CONTEXT] til table beer served belgian schools 1980s. proposed re-introduce low alcohol beer ( < 1.5 % abv ) schools healthier alternative softdrinks. [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: i m not sure how much beer is sold in belgium.", "output": "how is it sold in belgium?", "all_outputs": ["2.8333333333333335"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] getting emails from @logmein touting they 're not just a remote control anymore . except that 's the only feature of theirs i care to pay for ! [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: we 're sorry to hear that . please follow + dm us so that we can help !||||B: sparkle motion used to open for her||||C: hi , i 'm sorry to hear this . please can you dm me your full address or order number as i would like to help . thanks .||||D: thank you for reaching out to us . please dm us with your contact information so we can look into this for you . [QUESTION] The most appropriate response to the conversation is ", "index": 27572, "split": "train", "classes_in_options": ["A", "B", "C", "D"], "candidates": ["we 're sorry to hear that . please follow + dm us so that we can help !", "sparkle motion used to open for her", "hi , i 'm sorry to hear this . please can you dm me your full address or order number as i would like to help . thanks .", "thank you for reaching out to us . please dm us with your contact information so we can look into this for you ."], "dataset": "eval", "task": "eval_ranking", "prompt": "Instruction: In this task you will be shown a conversation followed by some responses. You need to choose the best response from the provided responses. \nInput: [CONTEXT] getting emails from @logmein touting they 're not just a remote control anymore . except that 's the only feature of theirs i care to pay for ! [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: we 're sorry to hear that . please follow + dm us so that we can help !||||B: sparkle motion used to open for her||||C: hi , i 'm sorry to hear this . please can you dm me your full address or order number as i would like to help . thanks .||||D: thank you for reaching out to us . please dm us with your contact information so we can look into this for you . [QUESTION] The most appropriate response to the conversation is ", "output": "A", "all_outputs": ["C"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["getting emails from @logmein touting they 're not just a remote control anymore . except that 's the only feature of theirs i care to pay for !"], "response_list": ["we 're sorry to hear that . please follow + dm us so that we can help !", "sparkle motion used to open for her", "hi , i 'm sorry to hear this . please can you dm me your full address or order number as i would like to help . thanks .", "thank you for reaching out to us . please dm us with your contact information so we can look into this for you ."], "metric_score": [{"USR-MLM": -2.8122498989105225}, {"USR-MLM": -3.304452657699585}, {"USR-MLM": -2.9101290702819824}, {"USR-MLM": -2.373250722885132}]}
{"input": "[CONTEXT] let me tell y 'all about the happiest split second of my life , but of course i take l 's in life so it was too good to be true . walk up to 711 to rent logan from a @redbox and redbox let 's me know that i can rent a free video game on them . my ass got excited af the first disc comes out and it was empty lmao . i can 't even take a simple w . [RESPONSE] \"the houses! the village!\" man i loves me some canadiana. [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Select the right option: is the response is a good follow-up response? ", "index": 15531, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: Given a conversation and a response to the conversation, is the response a good response to the context?\nInput: [CONTEXT] let me tell y 'all about the happiest split second of my life , but of course i take l 's in life so it was too good to be true . walk up to 711 to rent logan from a @redbox and redbox let 's me know that i can rent a free video game on them . my ass got excited af the first disc comes out and it was empty lmao . i can 't even take a simple w . [RESPONSE] \"the houses! the village!\" man i loves me some canadiana. [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Select the right option: is the response is a good follow-up response? ", "output": "no", "all_outputs": ["no"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["let me tell y 'all about the happiest split second of my life , but of course i take l 's in life so it was too good to be true . walk up to 711 to rent logan from a @redbox and redbox let 's me know that i can rent a free video game on them . my ass got excited af the first disc comes out and it was empty lmao . i can 't even take a simple w ."], "response_list": ["\"the houses! the village!\" man i loves me some canadiana."], "metric_score": [{"USR-MLM": -2.5874364376068115}]}
{"input": "[CONTEXT] what is wrong with your signage union station ? ? @ttchelps i come here once a month or so and manage to get lost every time . [RESPONSE] hi <USER> , we 're sorry to hear this . can you please dm us your contact info so we can look into this for you ? thanks ! [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response a good response to the provided dialogue context? ", "index": 75650, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: Given a conversation and a response to the conversation, is it a relevant response to the context?\nInput: [CONTEXT] what is wrong with your signage union station ? ? @ttchelps i come here once a month or so and manage to get lost every time . [RESPONSE] hi <USER> , we 're sorry to hear this . can you please dm us your contact info so we can look into this for you ? thanks ! [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response a good response to the provided dialogue context? ", "output": "yes", "all_outputs": ["yes"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["what is wrong with your signage union station ? ? @ttchelps i come here once a month or so and manage to get lost every time ."], "response_list": ["hi <USER> , we 're sorry to hear this . can you please dm us your contact info so we can look into this for you ? thanks !"], "metric_score": [{"USR-MLM": -2.063591718673706}]}
{"input": "[CONTEXT] hi @narrativecare do you know your website is broken in chrome ? no login and shared moments show blank page [RESPONSE] we regret hearing this . we 'd like to help . please send us a dm with your mobile number so that we may contact you . [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Select the right option: is the response is a good follow-up response? ", "index": 37443, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: Select if the provided response follow the provided conversationSelect if the provided response a good response to the provided dialogue context.\nInput: [CONTEXT] hi @narrativecare do you know your website is broken in chrome ? no login and shared moments show blank page [RESPONSE] we regret hearing this . we 'd like to help . please send us a dm with your mobile number so that we may contact you . [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Select the right option: is the response is a good follow-up response? ", "output": "yes", "all_outputs": ["no"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["hi @narrativecare do you know your website is broken in chrome ? no login and shared moments show blank page"], "response_list": ["we regret hearing this . we 'd like to help . please send us a dm with your mobile number so that we may contact you ."], "metric_score": [{"USR-MLM": -2.5672199726104736}]}
{"input": "[CONTEXT] your internet service / coverage is terrible ! \ud83d\udc4e \ud83c\udffc \ud83d\ude20 \ud83d\udd95 \ud83c\udffc #stepyourshitup #sprint @sprint [RESPONSE] hi <USER> , how can we help you ? [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response a good response to the provided dialogue context? ", "index": 69625, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: In this task you will be shown a context followed by a response. You need to classify if the response is a good response to the context. \nInput: [CONTEXT] your internet service / coverage is terrible ! \ud83d\udc4e \ud83c\udffc \ud83d\ude20 \ud83d\udd95 \ud83c\udffc #stepyourshitup #sprint @sprint [RESPONSE] hi <USER> , how can we help you ? [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response a good response to the provided dialogue context? ", "output": "yes", "all_outputs": ["no"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["your internet service / coverage is terrible ! \ud83d\udc4e \ud83c\udffc \ud83d\ude20 \ud83d\udd95 \ud83c\udffc #stepyourshitup #sprint @sprint"], "response_list": ["hi <USER> , how can we help you ?"], "metric_score": [{"USR-MLM": -2.713181495666504}]}
{"input": "[CONTEXT] #ecommercestaredown with @uniqlousa over - i received my coupon code ! this has been an arduous journey over the last 55 + hours . thank you all [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: we 're sorry to hear this ! please dm us your contact info so we can look into this for you .", "index": 43340, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Given a conversation, a response to the conversation, and a score range, return a rating to the response within in score range\nInput: [CONTEXT] #ecommercestaredown with @uniqlousa over - i received my coupon code ! this has been an arduous journey over the last 55 + hours . thank you all [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: we 're sorry to hear this ! please dm us your contact info so we can look into this for you .", "output": "1", "all_outputs": ["2.4"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] til general napier asked respect indian custom burning widows husband's funeral pyre , replied english custom hang murderers. [ENDOFTURN] read windows instead widows initially understand someone would upset this. [ENDOFTURN] man's window prized possession [RESPONSE] no man should be defenestrated in death. [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Select the right option: is the response is a good follow-up response? ", "index": 13736, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: Given a conversation and a response to the conversation, select is the response is a good response to the context.\nInput: [CONTEXT] til general napier asked respect indian custom burning widows husband's funeral pyre , replied english custom hang murderers. [ENDOFTURN] read windows instead widows initially understand someone would upset this. [ENDOFTURN] man's window prized possession [RESPONSE] no man should be defenestrated in death. [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Select the right option: is the response is a good follow-up response? ", "output": "yes", "all_outputs": ["yes"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["til general napier asked respect indian custom burning widows husband's funeral pyre , replied english custom hang murderers.", "read windows instead widows initially understand someone would upset this.", "man's window prized possession"], "response_list": ["no man should be defenestrated in death."], "metric_score": [{"USR-MLM": -5.367928504943848}]}
{"input": "[CONTEXT] til mother teresa encouraged members order secretly baptise dying patients , many hindus muslims [ENDOFTURN] .. that? like , it\" count? \" spiritual rape. [ENDOFTURN] nothing .. mormons baptize die! [ENDOFTURN] baptize people listed phone book. grandmother use baptize neighborhood kids / babies kitchen sink watching summer. catholic want babies going purgatory / hell. [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: that 's not what we like to hear , <USER> . please let us know if there 's anything we can do to help .||||B: yeah, i know, was just trying to keep the comment short and to the point. side note, this presumably means his criticism of mother teresa was good enough for the catholic church.||||C: yes !||||D: hi <USER> , we will be in touch with you soon . [QUESTION] The correct response is ", "index": 33135, "split": "train", "classes_in_options": ["A", "B", "C", "D"], "candidates": ["that 's not what we like to hear , <USER> . please let us know if there 's anything we can do to help .", "yeah, i know, was just trying to keep the comment short and to the point. side note, this presumably means his criticism of mother teresa was good enough for the catholic church.", "yes !", "hi <USER> , we will be in touch with you soon ."], "dataset": "eval", "task": "eval_ranking", "prompt": "Instruction: In this task you will be shown a conversation followed by some responses. You need to choose the best response from the provided responses. \nInput: [CONTEXT] til mother teresa encouraged members order secretly baptise dying patients , many hindus muslims [ENDOFTURN] .. that? like , it\" count? \" spiritual rape. [ENDOFTURN] nothing .. mormons baptize die! [ENDOFTURN] baptize people listed phone book. grandmother use baptize neighborhood kids / babies kitchen sink watching summer. catholic want babies going purgatory / hell. [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: that 's not what we like to hear , <USER> . please let us know if there 's anything we can do to help .||||B: yeah, i know, was just trying to keep the comment short and to the point. side note, this presumably means his criticism of mother teresa was good enough for the catholic church.||||C: yes !||||D: hi <USER> , we will be in touch with you soon . [QUESTION] The correct response is ", "output": "B", "all_outputs": ["B"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["til mother teresa encouraged members order secretly baptise dying patients , many hindus muslims", ".. that? like , it\" count? \" spiritual rape.", "nothing .. mormons baptize die!", "baptize people listed phone book. grandmother use baptize neighborhood kids / babies kitchen sink watching summer. catholic want babies going purgatory / hell."], "response_list": ["that 's not what we like to hear , <USER> . please let us know if there 's anything we can do to help .", "yeah, i know, was just trying to keep the comment short and to the point. side note, this presumably means his criticism of mother teresa was good enough for the catholic church.", "yes !", "hi <USER> , we will be in touch with you soon ."], "metric_score": [{"USR-MLM": -3.8047962188720703}, {"USR-MLM": -3.576648712158203}, {"USR-MLM": -5.231573581695557}, {"USR-MLM": -4.792670726776123}]}
{"input": "[CONTEXT] very disappointed with @familyvideo tonight \ud83d\ude15 [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: oh no ! sorry to hear this ! can you help us improve by providing some more info in this link <URL> ? thank you !||||B: hi <USER> , apologies for this . @<SERV_ID> will be able to look into this for you .||||C: System: It was really fun! We are a bunch of turkey||||D: we 're glad you like it , <USER> ! we hope you have a great day ! [QUESTION] The most appropriate response to the conversation is ", "index": 3323, "split": "train", "classes_in_options": ["A", "B", "C", "D"], "candidates": ["oh no ! sorry to hear this ! can you help us improve by providing some more info in this link <URL> ? thank you !", "hi <USER> , apologies for this . @<SERV_ID> will be able to look into this for you .", "System: It was really fun! We are a bunch of turkey", "we 're glad you like it , <USER> ! we hope you have a great day !"], "dataset": "eval", "task": "eval_ranking", "prompt": "Instruction: Select the best response from the provided responses to a conversation\nInput: [CONTEXT] very disappointed with @familyvideo tonight \ud83d\ude15 [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: oh no ! sorry to hear this ! can you help us improve by providing some more info in this link <URL> ? thank you !||||B: hi <USER> , apologies for this . @<SERV_ID> will be able to look into this for you .||||C: System: It was really fun! We are a bunch of turkey||||D: we 're glad you like it , <USER> ! we hope you have a great day ! [QUESTION] The most appropriate response to the conversation is ", "output": "B", "all_outputs": ["A"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["very disappointed with @familyvideo tonight \ud83d\ude15"], "response_list": ["oh no ! sorry to hear this ! can you help us improve by providing some more info in this link <URL> ? thank you !", "hi <USER> , apologies for this . @<SERV_ID> will be able to look into this for you .", "System: It was really fun! We are a bunch of turkey", "we 're glad you like it , <USER> ! we hope you have a great day !"], "metric_score": [{"USR-MLM": -2.1725776195526123}, {"USR-MLM": -3.2823917865753174}, {"USR-MLM": -3.7469890117645264}, {"USR-MLM": -2.423704147338867}]}
{"input": "[CONTEXT] ain 't no way i should be paying 200 + for a phone every month @sprint yo @metropcs sign me up thank you for reaching out to us . how can we be of assistance to you today ? lower my bill are you a sprint customer ? obviously [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: you got it ! <USER> , we 'll be watching the fireworks from the hotel pool though !", "index": 51611, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Return a score in the provided range which scores the response to a conversation \nInput: [CONTEXT] ain 't no way i should be paying 200 + for a phone every month @sprint yo @metropcs sign me up thank you for reaching out to us . how can we be of assistance to you today ? lower my bill are you a sprint customer ? obviously [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: you got it ! <USER> , we 'll be watching the fireworks from the hotel pool though !", "output": "not sure yet but i will! see you in 5", "all_outputs": ["2.0"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] til vladimir great russia confronted choice converting russia christianity islam. eventually chose christianity , islamic teaching alcohol , saying ,\" drinking joy rus '. cannot exist without pleasure. \" [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: hi <USER> , we are sorry to hear this . please dm us your contact details and we will look into this for you . thank you .||||B: hi there , please dm us your query , along with your order number , email address and postcode and we will advise further . thanks ! \ud83d\ude4b||||C: i m a belgian and i can t speak for the word.||||D: but does that acknowledgement lead to approval? should your determination of greater good outweigh beneficence? [QUESTION] The correct response is ", "index": 3866, "split": "train", "classes_in_options": ["A", "B", "C", "D"], "candidates": ["hi <USER> , we are sorry to hear this . please dm us your contact details and we will look into this for you . thank you .", "hi there , please dm us your query , along with your order number , email address and postcode and we will advise further . thanks ! \ud83d\ude4b", "i m a belgian and i can t speak for the word.", "but does that acknowledgement lead to approval? should your determination of greater good outweigh beneficence?"], "dataset": "eval", "task": "eval_ranking", "prompt": "Instruction: Select the best response from the provided responses to a conversation\nInput: [CONTEXT] til vladimir great russia confronted choice converting russia christianity islam. eventually chose christianity , islamic teaching alcohol , saying ,\" drinking joy rus '. cannot exist without pleasure. \" [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: hi <USER> , we are sorry to hear this . please dm us your contact details and we will look into this for you . thank you .||||B: hi there , please dm us your query , along with your order number , email address and postcode and we will advise further . thanks ! \ud83d\ude4b||||C: i m a belgian and i can t speak for the word.||||D: but does that acknowledgement lead to approval? should your determination of greater good outweigh beneficence? [QUESTION] The correct response is ", "output": "C", "all_outputs": ["C"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["til vladimir great russia confronted choice converting russia christianity islam. eventually chose christianity , islamic teaching alcohol , saying ,\" drinking joy rus '. cannot exist without pleasure. \""], "response_list": ["hi <USER> , we are sorry to hear this . please dm us your contact details and we will look into this for you . thank you .", "hi there , please dm us your query , along with your order number , email address and postcode and we will advise further . thanks ! \ud83d\ude4b", "i m a belgian and i can t speak for the word.", "but does that acknowledgement lead to approval? should your determination of greater good outweigh beneficence?"], "metric_score": [{"USR-MLM": -3.305164337158203}, {"USR-MLM": -3.645749807357788}, {"USR-MLM": -4.019454479217529}, {"USR-MLM": -4.178452014923096}]}
{"input": "[CONTEXT] just bought my tank and i cannot wait for it to get here \ud83c\udff3 \ufe0f \u200d \ud83c\udf08 \ud83d\ude0d <URL> [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: awesome ! we can 't wait to see what looks you create with your purchases . don 't forget to tag us ! <URL>||||B: now those lyrics in jewel's morning song make sense. thanks, op!||||C: not one of the best characters, rather than age of consent in <numbers>, they have sex with the death penalty.||||D: hi <USER> , we 're sorry to hear this . please dm us your contact details and we will be in touch to assist you further . thanks . [QUESTION] The most appropriate response to the conversation is ", "index": 13624, "split": "train", "classes_in_options": ["A", "B", "C", "D"], "candidates": ["awesome ! we can 't wait to see what looks you create with your purchases . don 't forget to tag us ! <URL>", "now those lyrics in jewel's morning song make sense. thanks, op!", "not one of the best characters, rather than age of consent in <numbers>, they have sex with the death penalty.", "hi <USER> , we 're sorry to hear this . please dm us your contact details and we will be in touch to assist you further . thanks ."], "dataset": "eval", "task": "eval_ranking", "prompt": "Instruction: Given a conversation and some responses to the conversation, select the most appropriate response \nInput: [CONTEXT] just bought my tank and i cannot wait for it to get here \ud83c\udff3 \ufe0f \u200d \ud83c\udf08 \ud83d\ude0d <URL> [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: awesome ! we can 't wait to see what looks you create with your purchases . don 't forget to tag us ! <URL>||||B: now those lyrics in jewel's morning song make sense. thanks, op!||||C: not one of the best characters, rather than age of consent in <numbers>, they have sex with the death penalty.||||D: hi <USER> , we 're sorry to hear this . please dm us your contact details and we will be in touch to assist you further . thanks . [QUESTION] The most appropriate response to the conversation is ", "output": "A", "all_outputs": ["A"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["just bought my tank and i cannot wait for it to get here \ud83c\udff3 \ufe0f \u200d \ud83c\udf08 \ud83d\ude0d <URL>"], "response_list": ["awesome ! we can 't wait to see what looks you create with your purchases . don 't forget to tag us ! <URL>", "now those lyrics in jewel's morning song make sense. thanks, op!", "not one of the best characters, rather than age of consent in <numbers>, they have sex with the death penalty.", "hi <USER> , we 're sorry to hear this . please dm us your contact details and we will be in touch to assist you further . thanks ."], "metric_score": [{"USR-MLM": -2.3972902297973633}, {"USR-MLM": -2.8814730644226074}, {"USR-MLM": -3.1540777683258057}, {"USR-MLM": -2.0186426639556885}]}
{"input": "[CONTEXT] 2k from the redbox didn 't want to work ... smh [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: we 're happy to hear that you 're happy with the service ! have a great day !", "index": 39024, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: In this task you will be shown a conversation followed by a response and score range. You need to give a appropriate rating to the response.\nInput: [CONTEXT] 2k from the redbox didn 't want to work ... smh [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: we 're happy to hear that you 're happy with the service ! have a great day !", "output": "3", "all_outputs": ["1.7"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] does anyone have a lg ultra wide curved monitor ? if so , how tf do i mount it lmao [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: hi <USER> , we 're sorry to hear this . please send us a dm with your registered email address so we can look into this for you .", "index": 14807, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Return a score in the provided range which scores the response to a conversation \nInput: [CONTEXT] does anyone have a lg ultra wide curved monitor ? if so , how tf do i mount it lmao [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: hi <USER> , we 're sorry to hear this . please send us a dm with your registered email address so we can look into this for you .", "output": "hi, i've a lg uw265hm. is it showing up on your phone?", "all_outputs": ["2.6"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] wondering if the @daysinn would cut me a break on a room for next month , only need it for 8 hours to sleep #discountbychance [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: hello <USER> , if you would like to follow us and dm the details we can take a look into this for you . thank you .||||B: sorry to hear about this ! can you dm us with more info so we can look into this for you ? thanks !||||C: oh no ! ! ! ! ! ! ! ! ! ! ! ! !||||D: hi <USER> , we are looking into this for you and will get back to you as soon as we can . [QUESTION] The correct response is ", "index": 7068, "split": "train", "classes_in_options": ["A", "B", "C", "D"], "candidates": ["hello <USER> , if you would like to follow us and dm the details we can take a look into this for you . thank you .", "sorry to hear about this ! can you dm us with more info so we can look into this for you ? thanks !", "oh no ! ! ! ! ! ! ! ! ! ! ! ! !", "hi <USER> , we are looking into this for you and will get back to you as soon as we can ."], "dataset": "eval", "task": "eval_ranking", "prompt": "Instruction: Select the best response from the provided responses to a conversation\nInput: [CONTEXT] wondering if the @daysinn would cut me a break on a room for next month , only need it for 8 hours to sleep #discountbychance [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: hello <USER> , if you would like to follow us and dm the details we can take a look into this for you . thank you .||||B: sorry to hear about this ! can you dm us with more info so we can look into this for you ? thanks !||||C: oh no ! ! ! ! ! ! ! ! ! ! ! ! !||||D: hi <USER> , we are looking into this for you and will get back to you as soon as we can . [QUESTION] The correct response is ", "output": "A", "all_outputs": ["A"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["wondering if the @daysinn would cut me a break on a room for next month , only need it for 8 hours to sleep #discountbychance"], "response_list": ["hello <USER> , if you would like to follow us and dm the details we can take a look into this for you . thank you .", "sorry to hear about this ! can you dm us with more info so we can look into this for you ? thanks !", "oh no ! ! ! ! ! ! ! ! ! ! ! ! !", "hi <USER> , we are looking into this for you and will get back to you as soon as we can ."], "metric_score": [{"USR-MLM": -2.692739248275757}, {"USR-MLM": -2.408745527267456}, {"USR-MLM": -2.220370054244995}, {"USR-MLM": -2.3560662269592285}]}
{"input": "[CONTEXT] .. jet water bright light annoying him. he's also seen juggling hermit crabs , throwing rocks glass re-arranging tank surroundings. imagine kind stuff advanced species would write us. * * edit : * * never life imagine big break reddit would bland comment. people crazy. <3 thanks insisting creative original. \" though cannot perceive , humans never ceased attempts destabilize simulation live in. \" \" simulation 7422 soon able build computers powerful enough create lifelike simulations attempt better understand world , thus perpetuating simulation one layer down. \" \" nested simulations would taxing systems. we'll make physically impossible. \"\" how? \"\" i'm sure , we'll make something like speed light. \" [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the informativeness to the following response: you're right. i'm a pro-bullet trains in denominationpub.", "index": 2988, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: In this task you will be shown a conversation followed by a response and score range. You need to give a appropriate rating to the response.\nInput: [CONTEXT] .. jet water bright light annoying him. he's also seen juggling hermit crabs , throwing rocks glass re-arranging tank surroundings. imagine kind stuff advanced species would write us. * * edit : * * never life imagine big break reddit would bland comment. people crazy. <3 thanks insisting creative original. \" though cannot perceive , humans never ceased attempts destabilize simulation live in. \" \" simulation 7422 soon able build computers powerful enough create lifelike simulations attempt better understand world , thus perpetuating simulation one layer down. \" \" nested simulations would taxing systems. we'll make physically impossible. \"\" how? \"\" i'm sure , we'll make something like speed light. \" [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the informativeness to the following response: you're right. i'm a pro-bullet trains in denominationpub.", "output": "3", "all_outputs": ["3.6666666666666665"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] order in july ' 16 for b / b tel , told by virgin last week that they couldn 't process . several site visits but they don 't care ! ! ! [RESPONSE] we 're sorry to hear this . please send us a dm with your res # so we can look into this for you . [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response a good response to the provided dialogue context? ", "index": 72843, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: Select if the provided response follow the provided conversationSelect if the provided response a good response to the provided dialogue context.\nInput: [CONTEXT] order in july ' 16 for b / b tel , told by virgin last week that they couldn 't process . several site visits but they don 't care ! ! ! [RESPONSE] we 're sorry to hear this . please send us a dm with your res # so we can look into this for you . [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response a good response to the provided dialogue context? ", "output": "yes", "all_outputs": ["no"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["order in july ' 16 for b / b tel , told by virgin last week that they couldn 't process . several site visits but they don 't care ! ! !"], "response_list": ["we 're sorry to hear this . please send us a dm with your res # so we can look into this for you ."], "metric_score": [{"USR-MLM": -2.286752939224243}]}
{"input": "[CONTEXT] Hi how are you today Not good. I hate my job. How are you? I am good do you work I work as a car salesman. What about you? I'm a stay at home mom Oh. Im planning on getting a divorce. My wife spends all my money. Are you married? No I'm not married Good. Stay that way. What are your hobbies? I like to spend time with my family Great. Do you have a favorite food or drink? I do not really have a favorite food [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 0 to 4 about the listen to the following response: Do you listen to music?", "index": 26176, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: In this task you will be shown a conversation followed by a response and score range. You need to give a appropriate rating to the response.\nInput: [CONTEXT] Hi how are you today Not good. I hate my job. How are you? I am good do you work I work as a car salesman. What about you? I'm a stay at home mom Oh. Im planning on getting a divorce. My wife spends all my money. Are you married? No I'm not married Good. Stay that way. What are your hobbies? I like to spend time with my family Great. Do you have a favorite food or drink? I do not really have a favorite food [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 0 to 4 about the listen to the following response: Do you listen to music?", "output": "Sorry.", "all_outputs": ["4.0"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] really happy that @ups lost my axles and that @fedex fucking sent my tie rods to michigan after they were in perrysville ohio . what the fuck [RESPONSE] we are sorry to hear that . please send us a dm so we can look into this for you . [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response a good response to the provided dialogue context? ", "index": 49352, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: Select if the provided response follow the provided conversationSelect if the provided response a good response to the provided dialogue context.\nInput: [CONTEXT] really happy that @ups lost my axles and that @fedex fucking sent my tie rods to michigan after they were in perrysville ohio . what the fuck [RESPONSE] we are sorry to hear that . please send us a dm so we can look into this for you . [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response a good response to the provided dialogue context? ", "output": "yes", "all_outputs": ["yes"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["really happy that @ups lost my axles and that @fedex fucking sent my tie rods to michigan after they were in perrysville ohio . what the fuck"], "response_list": ["we are sorry to hear that . please send us a dm so we can look into this for you ."], "metric_score": [{"USR-MLM": -2.4304440021514893}]}
{"input": "[CONTEXT] til families columbine shooters paid millions settlements victims families. homeowner without kids : umbrella f-ing cheap stupid it. insurance agent , advise everyone never kids. never. insurance agent father 3 year old , agree. someone expecting first child moment , thread terrifies me. insurance broker , advise keep car keys , fireworks , anything incendiary , kid lock key. [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the informativeness to the following response: it's not really fair, but i'm not even sure jewish. nevertheless, you don't prejudice the jews.", "index": 48981, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: In this task you will be shown a conversation followed by a response and score range. You need to give a appropriate rating to the response.\nInput: [CONTEXT] til families columbine shooters paid millions settlements victims families. homeowner without kids : umbrella f-ing cheap stupid it. insurance agent , advise everyone never kids. never. insurance agent father 3 year old , agree. someone expecting first child moment , thread terrifies me. insurance broker , advise keep car keys , fireworks , anything incendiary , kid lock key. [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the informativeness to the following response: it's not really fair, but i'm not even sure jewish. nevertheless, you don't prejudice the jews.", "output": "1", "all_outputs": ["1.6666666666666667"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] pathetic customer service .. sent an email about my problem still no replies .. tried calling them .. without luck [RESPONSE] i don't know what you mean. [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response contextual? ", "index": 38279, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: Given a conversation and a response to the conversation, is it a relevant response to the context?\nInput: [CONTEXT] pathetic customer service .. sent an email about my problem still no replies .. tried calling them .. without luck [RESPONSE] i don't know what you mean. [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response contextual? ", "output": "yes", "all_outputs": ["no"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["pathetic customer service .. sent an email about my problem still no replies .. tried calling them .. without luck"], "response_list": ["i don't know what you mean."], "metric_score": [{"USR-MLM": -1.4753438234329224}]}
{"input": "[CONTEXT] please help . my car is literally melting and now its not starting . i knew i should have bought a @bmw \ud83d\ude29 \ud83d\ude2d [RESPONSE] glad to hear it . thanks for letting us know . we 'll pass this along to the right people . have a great day ! [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Select the right option: is the response is a good follow-up response? ", "index": 15165, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: You will be given a dialogue context and a response. Choose if the response is a contextual response to the context. \nInput: [CONTEXT] please help . my car is literally melting and now its not starting . i knew i should have bought a @bmw \ud83d\ude29 \ud83d\ude2d [RESPONSE] glad to hear it . thanks for letting us know . we 'll pass this along to the right people . have a great day ! [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Select the right option: is the response is a good follow-up response? ", "output": "no", "all_outputs": ["no"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["please help . my car is literally melting and now its not starting . i knew i should have bought a @bmw \ud83d\ude29 \ud83d\ude2d"], "response_list": ["glad to hear it . thanks for letting us know . we 'll pass this along to the right people . have a great day !"], "metric_score": [{"USR-MLM": -1.715598702430725}]}
{"input": "[CONTEXT] That does not sound nice. Mostly I like to listen to music. [ENDOFTURN] What kind of music do you like? [ENDOFTURN] Rock and roll my friend. How about you? What kind of music do you like? [ENDOFTURN] I like all kinds. What about you? [ENDOFTURN] Besides music I like playing video games. Sometimes i stay up way too late playing games. [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: What kind of music do you like?||||B: at the age of stan lee, which is very interesting.||||C: please dm us your surfline number and exact location . we will be happy to assist you .||||D: thats cool [QUESTION] The most appropriate response to the conversation is ", "index": 3336, "split": "train", "classes_in_options": ["A", "B", "C", "D"], "candidates": ["What kind of music do you like?", "at the age of stan lee, which is very interesting.", "please dm us your surfline number and exact location . we will be happy to assist you .", "thats cool"], "dataset": "eval", "task": "eval_ranking", "prompt": "Instruction: In this task you will be shown a conversation followed by some responses. You need to choose the best response from the provided responses. \nInput: [CONTEXT] That does not sound nice. Mostly I like to listen to music. [ENDOFTURN] What kind of music do you like? [ENDOFTURN] Rock and roll my friend. How about you? What kind of music do you like? [ENDOFTURN] I like all kinds. What about you? [ENDOFTURN] Besides music I like playing video games. Sometimes i stay up way too late playing games. [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: What kind of music do you like?||||B: at the age of stan lee, which is very interesting.||||C: please dm us your surfline number and exact location . we will be happy to assist you .||||D: thats cool [QUESTION] The most appropriate response to the conversation is ", "output": "A", "all_outputs": ["A"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["That does not sound nice. Mostly I like to listen to music.", "What kind of music do you like?", "Rock and roll my friend. How about you? What kind of music do you like?", "I like all kinds. What about you?", "Besides music I like playing video games. Sometimes i stay up way too late playing games."], "response_list": ["What kind of music do you like?", "at the age of stan lee, which is very interesting.", "please dm us your surfline number and exact location . we will be happy to assist you .", "thats cool"], "metric_score": [{"USR-MLM": -2.5569095611572266}, {"USR-MLM": -2.5380892753601074}, {"USR-MLM": -2.8095197677612305}, {"USR-MLM": -2.7944650650024414}]}
{"input": "[CONTEXT] i like to take care of myself with expensive things [ENDOFTURN] i'm an alcoholic , but i'm recovering [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: well that's good for you . drinking isn't the healthiest thing in the world||||B: damn. manthing had a cute wife. you know aside from the whole joining aim and getting the extremis virus.||||C: thanks for letting us know ! we 'll be sure to share your feedback with our team .||||D: you 're welcome . [QUESTION] The most appropriate response to the conversation is ", "index": 26315, "split": "train", "classes_in_options": ["A", "B", "C", "D"], "candidates": ["well that's good for you . drinking isn't the healthiest thing in the world", "damn. manthing had a cute wife. you know aside from the whole joining aim and getting the extremis virus.", "thanks for letting us know ! we 'll be sure to share your feedback with our team .", "you 're welcome ."], "dataset": "eval", "task": "eval_ranking", "prompt": "Instruction: Select the best response from the provided responses to a conversation\nInput: [CONTEXT] i like to take care of myself with expensive things [ENDOFTURN] i'm an alcoholic , but i'm recovering [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: well that's good for you . drinking isn't the healthiest thing in the world||||B: damn. manthing had a cute wife. you know aside from the whole joining aim and getting the extremis virus.||||C: thanks for letting us know ! we 'll be sure to share your feedback with our team .||||D: you 're welcome . [QUESTION] The most appropriate response to the conversation is ", "output": "A", "all_outputs": ["A"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["i like to take care of myself with expensive things", "i'm an alcoholic , but i'm recovering"], "response_list": ["well that's good for you . drinking isn't the healthiest thing in the world", "damn. manthing had a cute wife. you know aside from the whole joining aim and getting the extremis virus.", "thanks for letting us know ! we 'll be sure to share your feedback with our team .", "you 're welcome ."], "metric_score": [{"USR-MLM": -1.009888768196106}, {"USR-MLM": -2.766733407974243}, {"USR-MLM": -1.3204060792922974}, {"USR-MLM": -1.2648577690124512}]}
{"input": "[CONTEXT] Hey what's up? How are you doing today Living the life, how bout you What do you do for a living I budget concerts and other events That sounds like a lot of fun What do you do for a living? I'm a stay at home mom Well that must be pretty boring, what do you do for fun? Mostly just hang out with friends That's nice. What do you and your friends do? [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 0 to 4 about the enjoy to the following response: I love to spend time with my family", "index": 46958, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: In this task you will be shown a conversation followed by a response and score range. You need to give a appropriate rating to the response.\nInput: [CONTEXT] Hey what's up? How are you doing today Living the life, how bout you What do you do for a living I budget concerts and other events That sounds like a lot of fun What do you do for a living? I'm a stay at home mom Well that must be pretty boring, what do you do for fun? Mostly just hang out with friends That's nice. What do you and your friends do? [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 0 to 4 about the enjoy to the following response: I love to spend time with my family", "output": "Hobbies are fun, but when my family is home, that's the only thing I do.", "all_outputs": ["1.0"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] hello . my softball game was canceled due to the hurricane . oh how are you doing ? i'm sorry to hear that . doing great . daddy was in the army , he taught me things . i once lived in my moms house . mine passed when i was eight . [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 0 to 5 about the natural to the following response: sorry to hear that ! my boyfriend lost his mom at a young age too !", "index": 19087, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Given a conversation, a response to the conversation, and a score range, return a rating to the response within in score range\nInput: [CONTEXT] hello . my softball game was canceled due to the hurricane . oh how are you doing ? i'm sorry to hear that . doing great . daddy was in the army , he taught me things . i once lived in my moms house . mine passed when i was eight . [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 0 to 5 about the natural to the following response: sorry to hear that ! my boyfriend lost his mom at a young age too !", "output": "just started talking with you", "all_outputs": ["3.0"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] how do you provide service when i have had no resolution and it 's been over a week . no one from sprint has reached out ! #livid ! [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: we 'd like to look into this for you . please send us a dm with your phone number so we can reach out to you .", "index": 41479, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: In this task you will be shown a conversation followed by a response and score range. You need to give a appropriate rating to the response.\nInput: [CONTEXT] how do you provide service when i have had no resolution and it 's been over a week . no one from sprint has reached out ! #livid ! [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: we 'd like to look into this for you . please send us a dm with your phone number so we can reach out to you .", "output": "1", "all_outputs": ["4.3"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] til general napier asked respect indian custom burning widows husband's funeral pyre , replied english custom hang murderers. [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the relevance to the following response: the british economic situation after the cost of the war was absolutely appalling. i think you're over stating the role of politics.", "index": 11549, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Given a conversation, a response to the conversation, and a score range, return a rating to the response within in score range\nInput: [CONTEXT] til general napier asked respect indian custom burning widows husband's funeral pyre , replied english custom hang murderers. [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the relevance to the following response: the british economic situation after the cost of the war was absolutely appalling. i think you're over stating the role of politics.", "output": "i disagree", "all_outputs": ["2.3333333333333335"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] til : approximately 10,00 attended funeral hawaiian musician , israel kamakawiwoole. [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the informativeness to the following response: i m sure he was a good guy.", "index": 3421, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: In this task you will be shown a conversation followed by a response and score range. You need to give a appropriate rating to the response.\nInput: [CONTEXT] til : approximately 10,00 attended funeral hawaiian musician , israel kamakawiwoole. [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the informativeness to the following response: i m sure he was a good guy.", "output": "good musician", "all_outputs": ["3.6666666666666665"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] til name tyrone irish county tyrone [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the informativeness to the following response: meatprocessing towns are chock full of asians.", "index": 16225, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Return a score in the provided range which scores the response to a conversation \nInput: [CONTEXT] til name tyrone irish county tyrone [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the informativeness to the following response: meatprocessing towns are chock full of asians.", "output": "9", "all_outputs": ["3.3333333333333335"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] flt 4317 at gate jetway broken against plane stuck in plane now half hour and counting great job @americanair total joke [RESPONSE] our apologies for the delay , <USER> . we 're working to get you on your way as soon as possible . we appreciate your patience . [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Select the right option: is the response is a good follow-up response? ", "index": 48548, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: In this task you will be shown a context followed by a response. You need to classify if the response is a good response to the context. \nInput: [CONTEXT] flt 4317 at gate jetway broken against plane stuck in plane now half hour and counting great job @americanair total joke [RESPONSE] our apologies for the delay , <USER> . we 're working to get you on your way as soon as possible . we appreciate your patience . [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Select the right option: is the response is a good follow-up response? ", "output": "yes", "all_outputs": ["yes"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["flt 4317 at gate jetway broken against plane stuck in plane now half hour and counting great job @americanair total joke"], "response_list": ["our apologies for the delay , <USER> . we 're working to get you on your way as soon as possible . we appreciate your patience ."], "metric_score": [{"USR-MLM": -3.12797212600708}]}
{"input": "[CONTEXT] til 1995 visit washington d. c. , russian president boris yeltsin found pennsylvania avenue , drunk , underwear trying hail cab order find pizza. relaxed drank fifth vodka every day like old russian proverb :\" everything's okay enough vodka\" including vodka? especially vodka. even vodka. [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the relevance to the following response: it's the only way to go figure.", "index": 31201, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: In this task you will be shown a conversation followed by a response and score range. You need to give a appropriate rating to the response.\nInput: [CONTEXT] til 1995 visit washington d. c. , russian president boris yeltsin found pennsylvania avenue , drunk , underwear trying hail cab order find pizza. relaxed drank fifth vodka every day like old russian proverb :\" everything's okay enough vodka\" including vodka? especially vodka. even vodka. [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the relevance to the following response: it's the only way to go figure.", "output": "random", "all_outputs": ["1.6666666666666667"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] til lisa mcpherson , woman died undergoing an\" introspection rundown\" church scientology's headquarters florida. body found dehydrated , underweight covered hundreds insect bites , presumably cockroaches can't wrap head around scientology still thing. world we're connected , people support / part scientology really unaware insane shit associated it? [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the informativeness to the following response: scientology is a cult.", "index": 51968, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: In this task you will be shown a conversation followed by a response and score range. You need to give a appropriate rating to the response.\nInput: [CONTEXT] til lisa mcpherson , woman died undergoing an\" introspection rundown\" church scientology's headquarters florida. body found dehydrated , underweight covered hundreds insect bites , presumably cockroaches can't wrap head around scientology still thing. world we're connected , people support / part scientology really unaware insane shit associated it? [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the informativeness to the following response: scientology is a cult.", "output": "cult", "all_outputs": ["4.333333333333333"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] i 'm having the same trouble with @sprint . i think it 's time to switch to @verizon [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: we 're here for you , <USER> ! send us a dm and we 'll take a closer look . * ellea", "index": 12822, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Given a conversation, a response to the conversation, and a score range, return a rating to the response within in score range\nInput: [CONTEXT] i 'm having the same trouble with @sprint . i think it 's time to switch to @verizon [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: we 're here for you , <USER> ! send us a dm and we 'll take a closer look . * ellea", "output": "5", "all_outputs": ["4.0"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] if you 're gonna get a puncture - let it be in a pub car park , & all fixed just as you wrap up christmas lunch - many thanks @greenflaguk ! [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: glad to hear it <USER> ! have a great day !", "index": 44065, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Return a score in the provided range which scores the response to a conversation \nInput: [CONTEXT] if you 're gonna get a puncture - let it be in a pub car park , & all fixed just as you wrap up christmas lunch - many thanks @greenflaguk ! [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: glad to hear it <USER> ! have a great day !", "output": "thanks for letting us know", "all_outputs": ["3.8"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] til columbus , ohio larger population cincinnati cleveland combined yet nfl , nba mlb teams. cleveland cincinnati 5 [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the relevance to the following response: i think this season!", "index": 34456, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: In this task you will be shown a conversation followed by a response and score range. You need to give a appropriate rating to the response.\nInput: [CONTEXT] til columbus , ohio larger population cincinnati cleveland combined yet nfl , nba mlb teams. cleveland cincinnati 5 [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the relevance to the following response: i think this season!", "output": "i think this season!", "all_outputs": ["2.6666666666666665"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] til actress mercedes mccambridge dubbed voice demon exorcist swallowed raw eggs , chain smoked drank whiskey make voice harsh. bound chair recordings requested credit film. [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: i don't know what you mean.", "index": 4050, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Given a conversation, a response to the conversation, and a score range, return a rating to the response within in score range\nInput: [CONTEXT] til actress mercedes mccambridge dubbed voice demon exorcist swallowed raw eggs , chain smoked drank whiskey make voice harsh. bound chair recordings requested credit film. [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: i don't know what you mean.", "output": "2", "all_outputs": ["1.8333333333333333"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] til 360 kilogrammes lunar soil samples brought back apollo missions rusted corroding vacuum bottle seals exposed water oxygen earth's atmosphere. [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: i m pretty sure that s why they re not the only ones that have been around.", "index": 1282, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: In this task you will be shown a conversation followed by a response and score range. You need to give a appropriate rating to the response.\nInput: [CONTEXT] til 360 kilogrammes lunar soil samples brought back apollo missions rusted corroding vacuum bottle seals exposed water oxygen earth's atmosphere. [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: i m pretty sure that s why they re not the only ones that have been around.", "output": "4", "all_outputs": ["3.5"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] please don 't buy me a christmas present this year . a twitter card will be fine . x [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: hi <USER> , we 're sorry to hear this . can you dm us your email address so we can look into this for you ? thanks !", "index": 31801, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Given a conversation, a response to the conversation, and a score range, return a rating to the response within in score range\nInput: [CONTEXT] please don 't buy me a christmas present this year . a twitter card will be fine . x [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: hi <USER> , we 're sorry to hear this . can you dm us your email address so we can look into this for you ? thanks !", "output": "1", "all_outputs": ["2.4"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] good morning , miss . good morning , sir . could you tell me please where can i find a currents exchange ? [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the appropriateness to the following response: certainly . the nearest one is at the end of the street .", "index": 18652, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Return a score in the provided range which scores the response to a conversation \nInput: [CONTEXT] good morning , miss . good morning , sir . could you tell me please where can i find a currents exchange ? [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the appropriateness to the following response: certainly . the nearest one is at the end of the street .", "output": "ok.", "all_outputs": ["5.0"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] i requested to return items 12 days ago and i have yet to receive a response . ticket 200852 . pathetic service . [RESPONSE] hi <USER> , we 're sorry to hear this . can you dm us your details and we can look into this for you ? thanks , eq . [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response a good response to the provided dialogue context? ", "index": 13183, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: You will be given a dialogue context and a response. Choose if the response is a contextual response to the context. \nInput: [CONTEXT] i requested to return items 12 days ago and i have yet to receive a response . ticket 200852 . pathetic service . [RESPONSE] hi <USER> , we 're sorry to hear this . can you dm us your details and we can look into this for you ? thanks , eq . [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response a good response to the provided dialogue context? ", "output": "yes", "all_outputs": ["no"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["i requested to return items 12 days ago and i have yet to receive a response . ticket 200852 . pathetic service ."], "response_list": ["hi <USER> , we 're sorry to hear this . can you dm us your details and we can look into this for you ? thanks , eq ."], "metric_score": [{"USR-MLM": -2.5093584060668945}]}
{"input": "[CONTEXT] thanks #fedex for delay my package delivery at your delivery center since yesterday morning . <URL> [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: I produce hip hip hop. What is your favorite food?||||B: can you please send us your email address via dm ?||||C: we 'd like to hear more about your experience ! please dm your reservation number , contact info and branch location . thanks !||||D: our apologies . please send us a dm with your tracking number and we will look into this for you . [QUESTION] The most appropriate response to the conversation is ", "index": 33911, "split": "train", "classes_in_options": ["A", "B", "C", "D"], "candidates": ["I produce hip hip hop. What is your favorite food?", "can you please send us your email address via dm ?", "we 'd like to hear more about your experience ! please dm your reservation number , contact info and branch location . thanks !", "our apologies . please send us a dm with your tracking number and we will look into this for you ."], "dataset": "eval", "task": "eval_ranking", "prompt": "Instruction: Select the best response from the provided responses to a conversation\nInput: [CONTEXT] thanks #fedex for delay my package delivery at your delivery center since yesterday morning . <URL> [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: I produce hip hip hop. What is your favorite food?||||B: can you please send us your email address via dm ?||||C: we 'd like to hear more about your experience ! please dm your reservation number , contact info and branch location . thanks !||||D: our apologies . please send us a dm with your tracking number and we will look into this for you . [QUESTION] The most appropriate response to the conversation is ", "output": "C", "all_outputs": ["D"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["thanks #fedex for delay my package delivery at your delivery center since yesterday morning . <URL>"], "response_list": ["I produce hip hip hop. What is your favorite food?", "can you please send us your email address via dm ?", "we 'd like to hear more about your experience ! please dm your reservation number , contact info and branch location . thanks !", "our apologies . please send us a dm with your tracking number and we will look into this for you ."], "metric_score": [{"USR-MLM": -3.210728406906128}, {"USR-MLM": -2.682192802429199}, {"USR-MLM": -2.7998950481414795}, {"USR-MLM": -2.5481700897216797}]}
{"input": "[CONTEXT] why when i pay a bill online does the money not automtcly become unavalbl ? online banking is suppsd to b easier than a chkbk [ENDOFTURN] we believe in not debiting your account until the biller has gotten the money . thanks for the feedback , i appreciate it . [ENDOFTURN] it 's confusing . why would i want to see money that 's not there ? i don 't want to balance a checkbook . that 's why i online bank ! [ENDOFTURN] if you have a virtual wallet the \" scheduled out \" part of your account shows your balance assuming all bill payments post . [ENDOFTURN] that 's still stupid . you 're basically just making it more possible to incur fees . shocker . #imisschase [RESPONSE] thank you for bringing this to our attention . we will pass it along to our team . thank you for bringing this to our attention . [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response a good response to the provided dialogue context? ", "index": 20953, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: You will be given a dialogue context and a response. Choose if the response is a contextual response to the context. \nInput: [CONTEXT] why when i pay a bill online does the money not automtcly become unavalbl ? online banking is suppsd to b easier than a chkbk [ENDOFTURN] we believe in not debiting your account until the biller has gotten the money . thanks for the feedback , i appreciate it . [ENDOFTURN] it 's confusing . why would i want to see money that 's not there ? i don 't want to balance a checkbook . that 's why i online bank ! [ENDOFTURN] if you have a virtual wallet the \" scheduled out \" part of your account shows your balance assuming all bill payments post . [ENDOFTURN] that 's still stupid . you 're basically just making it more possible to incur fees . shocker . #imisschase [RESPONSE] thank you for bringing this to our attention . we will pass it along to our team . thank you for bringing this to our attention . [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response a good response to the provided dialogue context? ", "output": "yes", "all_outputs": ["no"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["why when i pay a bill online does the money not automtcly become unavalbl ? online banking is suppsd to b easier than a chkbk", "we believe in not debiting your account until the biller has gotten the money . thanks for the feedback , i appreciate it .", "it 's confusing . why would i want to see money that 's not there ? i don 't want to balance a checkbook . that 's why i online bank !", "if you have a virtual wallet the \" scheduled out \" part of your account shows your balance assuming all bill payments post .", "that 's still stupid . you 're basically just making it more possible to incur fees . shocker . #imisschase"], "response_list": ["thank you for bringing this to our attention . we will pass it along to our team . thank you for bringing this to our attention ."], "metric_score": [{"USR-MLM": -1.9713644981384277}]}
{"input": "[CONTEXT] Hello, how are you today? I'm fine, I'm off today, so I have time to game. What do you do for a living? I set up roleplaying games for people.What about you? I am in alabama. Where do you live? I live in Colorado. Do you have any other hobbies? I love listening to the Insance Clown Posse. What do you like doing? I love animals and dogs. What about you? I love animals and my favorite food is donuts. What do you like to eat? My favorite food is tacos. How about you? [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 0 to 4 about the turing to the following response: I'm all about donuts and donut-related foods. Do you have a job?", "index": 33387, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: In this task you will be shown a conversation followed by a response and score range. You need to give a appropriate rating to the response.\nInput: [CONTEXT] Hello, how are you today? I'm fine, I'm off today, so I have time to game. What do you do for a living? I set up roleplaying games for people.What about you? I am in alabama. Where do you live? I live in Colorado. Do you have any other hobbies? I love listening to the Insance Clown Posse. What do you like doing? I love animals and dogs. What about you? I love animals and my favorite food is donuts. What do you like to eat? My favorite food is tacos. How about you? [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 0 to 4 about the turing to the following response: I'm all about donuts and donut-related foods. Do you have a job?", "output": "I am not sure I have a job.", "all_outputs": ["3.0"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] i 'm loving my flip - so easy to use ! [RESPONSE] we 're happy to hear you 're happy with the service , <USER> ! thanks for being a part of the geico family ! [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response contextual? ", "index": 52484, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: You will be given a dialogue context and a response. Choose if the response is a contextual response to the context. \nInput: [CONTEXT] i 'm loving my flip - so easy to use ! [RESPONSE] we 're happy to hear you 're happy with the service , <USER> ! thanks for being a part of the geico family ! [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response contextual? ", "output": "yes", "all_outputs": ["yes"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["i 'm loving my flip - so easy to use !"], "response_list": ["we 're happy to hear you 're happy with the service , <USER> ! thanks for being a part of the geico family !"], "metric_score": [{"USR-MLM": -1.7147164344787598}]}
{"input": "[CONTEXT] glad you got a twitter account . how do these count as #sliced <URL> [ENDOFTURN] sorry to see that <USER> . please let our customer care team know via this form <URL> - they will be in touch . [ENDOFTURN] <URL> i filled in everything as asked and then i was blocked my #redtext ( redtape ! ? ) value added value ? ! [RESPONSE] yes ! [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Select the right option: is the response is a good follow-up response? ", "index": 59029, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: Given a conversation and a response to the conversation, select is the response is a good response to the context.\nInput: [CONTEXT] glad you got a twitter account . how do these count as #sliced <URL> [ENDOFTURN] sorry to see that <USER> . please let our customer care team know via this form <URL> - they will be in touch . [ENDOFTURN] <URL> i filled in everything as asked and then i was blocked my #redtext ( redtape ! ? ) value added value ? ! [RESPONSE] yes ! [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Select the right option: is the response is a good follow-up response? ", "output": "no", "all_outputs": ["no"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["glad you got a twitter account . how do these count as #sliced <URL>", "sorry to see that <USER> . please let our customer care team know via this form <URL> - they will be in touch .", "<URL> i filled in everything as asked and then i was blocked my #redtext ( redtape ! ? ) value added value ? !"], "response_list": ["yes !"], "metric_score": [{"USR-MLM": -2.764228343963623}]}
{"input": "[CONTEXT] hi i bought some bedding and the colour ran and still does , my mattress is pink cause of the sheet . who do i contact ? thanks [RESPONSE] hi <USER> , please can you dm us your order number so we can look into this for you ? thanks , [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response a good response to the provided dialogue context? ", "index": 14608, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: Given a conversation and a response to the conversation, is it a relevant response to the context?\nInput: [CONTEXT] hi i bought some bedding and the colour ran and still does , my mattress is pink cause of the sheet . who do i contact ? thanks [RESPONSE] hi <USER> , please can you dm us your order number so we can look into this for you ? thanks , [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response a good response to the provided dialogue context? ", "output": "yes", "all_outputs": ["yes"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["hi i bought some bedding and the colour ran and still does , my mattress is pink cause of the sheet . who do i contact ? thanks"], "response_list": ["hi <USER> , please can you dm us your order number so we can look into this for you ? thanks ,"], "metric_score": [{"USR-MLM": -2.4734506607055664}]}
{"input": "[CONTEXT] your luggage is two pounds over . i ' m afraid they 'll be in excess luggage charge , sir . how much must i pay ? it ' s ten yuan . here you are . this is your luggage check which you must show when you disembark at your destination and here is your boarding pass and your ticket . [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the grammar to the following response: thank you , sir . now where is it ?", "index": 18971, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Return a score in the provided range which scores the response to a conversation \nInput: [CONTEXT] your luggage is two pounds over . i ' m afraid they 'll be in excess luggage charge , sir . how much must i pay ? it ' s ten yuan . here you are . this is your luggage check which you must show when you disembark at your destination and here is your boarding pass and your ticket . [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the grammar to the following response: thank you , sir . now where is it ?", "output": "the luggage check is in here.", "all_outputs": ["4.75"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] til : nixon sent champagne note saying\" justice ultimately prevails\" mark felt pardoned reagan. 30 years later , revealed mark felt was\" deep throat\" helped bring watergate cover-up light. [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the informativeness to the following response: that's what i was thinking of judy alapen.", "index": 27191, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: In this task you will be shown a conversation followed by a response and score range. You need to give a appropriate rating to the response.\nInput: [CONTEXT] til : nixon sent champagne note saying\" justice ultimately prevails\" mark felt pardoned reagan. 30 years later , revealed mark felt was\" deep throat\" helped bring watergate cover-up light. [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the informativeness to the following response: that's what i was thinking of judy alapen.", "output": "i remember watching the alapen interview.", "all_outputs": ["2.3333333333333335"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] let me tell y 'all about the happiest split second of my life , but of course i take l 's in life so it was too good to be true . walk up to 711 to rent logan from a @redbox and redbox let 's me know that i can rent a free video game on them . my ass got excited af the first disc comes out and it was empty lmao . i can 't even take a simple w . [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: we 're glad you like it , <USER> !", "index": 27341, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: In this task you will be shown a conversation followed by a response and score range. You need to give a appropriate rating to the response.\nInput: [CONTEXT] let me tell y 'all about the happiest split second of my life , but of course i take l 's in life so it was too good to be true . walk up to 711 to rent logan from a @redbox and redbox let 's me know that i can rent a free video game on them . my ass got excited af the first disc comes out and it was empty lmao . i can 't even take a simple w . [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: we 're glad you like it , <USER> !", "output": "thanks you! we're glad you like it!", "all_outputs": ["1.8"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] aaaah @tigoghana paa . u ppl u mess up . how can u change how customers recharge vouchers . i just threw one away cos i knew i was done wit it hi <USER> , we 're here for you . please explain further so we can address your concerns as soon as possible . hope to hear from you soon . this is what i got after i tried to recharge from a voucher . <URL> the code for recharge was charged earlier this year , this was a directive from nca to have one code for all the networks . dial * 134 * scratch card pin number # to recharge your account . exactly wat i did but it didn 't go through . and that 's how i recharge these past months . [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: hi <USER> , please send us a direct message with your number so we can look into this for you . thank you .", "index": 9010, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: In this task you will be shown a conversation followed by a response and score range. You need to give a appropriate rating to the response.\nInput: [CONTEXT] aaaah @tigoghana paa . u ppl u mess up . how can u change how customers recharge vouchers . i just threw one away cos i knew i was done wit it hi <USER> , we 're here for you . please explain further so we can address your concerns as soon as possible . hope to hear from you soon . this is what i got after i tried to recharge from a voucher . <URL> the code for recharge was charged earlier this year , this was a directive from nca to have one code for all the networks . dial * 134 * scratch card pin number # to recharge your account . exactly wat i did but it didn 't go through . and that 's how i recharge these past months . [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: hi <USER> , please send us a direct message with your number so we can look into this for you . thank you .", "output": "0", "all_outputs": ["4.0"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] what about my price @payumoney that i have won ? ? [ENDOFTURN] please share your registered email id with us so that we can look into the same . [ENDOFTURN] my registered email id is \" <E-MAIL> \" [ENDOFTURN] the same has been added in your account , reference : user id - <NUMBERS> . [ENDOFTURN] thanks i got the payumoney points :D may i know the validity of these points ? ? [RESPONSE] yes . [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response contextual? ", "index": 12256, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: Given a conversation and a response to the conversation, is the response a good response to the context?\nInput: [CONTEXT] what about my price @payumoney that i have won ? ? [ENDOFTURN] please share your registered email id with us so that we can look into the same . [ENDOFTURN] my registered email id is \" <E-MAIL> \" [ENDOFTURN] the same has been added in your account , reference : user id - <NUMBERS> . [ENDOFTURN] thanks i got the payumoney points :D may i know the validity of these points ? ? [RESPONSE] yes . [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response contextual? ", "output": "yes", "all_outputs": ["yes"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["what about my price @payumoney that i have won ? ?", "please share your registered email id with us so that we can look into the same .", "my registered email id is \" <E-MAIL> \"", "the same has been added in your account , reference : user id - <NUMBERS> .", "thanks i got the payumoney points :D may i know the validity of these points ? ?"], "response_list": ["yes ."], "metric_score": [{"USR-MLM": -3.0733704566955566}]}
{"input": "[CONTEXT] til : vicodin six times potent codeine , hence name vi ( roman numeran six ) - codin [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the relevance to the following response: it's the only way to switch to tsar nicholas bear.", "index": 6175, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Given a conversation, a response to the conversation, and a score range, return a rating to the response within in score range\nInput: [CONTEXT] til : vicodin six times potent codeine , hence name vi ( roman numeran six ) - codin [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the relevance to the following response: it's the only way to switch to tsar nicholas bear.", "output": "5", "all_outputs": ["1.3333333333333333"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] you cancelled my holiday to cuba in december & tried calling over 20 times & no answer or asks me to call back ! real stressful [RESPONSE] maybe one day - - [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response a good response to the provided dialogue context? ", "index": 25815, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: Given a conversation and a response to the conversation, select is the response is a good response to the context.\nInput: [CONTEXT] you cancelled my holiday to cuba in december & tried calling over 20 times & no answer or asks me to call back ! real stressful [RESPONSE] maybe one day - - [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response a good response to the provided dialogue context? ", "output": "no", "all_outputs": ["no"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["you cancelled my holiday to cuba in december & tried calling over 20 times & no answer or asks me to call back ! real stressful"], "response_list": ["maybe one day - -"], "metric_score": [{"USR-MLM": -2.562680959701538}]}
{"input": "[CONTEXT] nice introduction to life with the new rx , over \u00a3 780 to replace what should just be a just piece of plastic ! ! <URL> [RESPONSE] we are sorry to hear that . please send us a dm so we can look into this for you . [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response a good response to the provided dialogue context? ", "index": 75068, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: Select if the provided response follow the provided conversationSelect if the provided response a good response to the provided dialogue context.\nInput: [CONTEXT] nice introduction to life with the new rx , over \u00a3 780 to replace what should just be a just piece of plastic ! ! <URL> [RESPONSE] we are sorry to hear that . please send us a dm so we can look into this for you . [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response a good response to the provided dialogue context? ", "output": "yes", "all_outputs": ["yes"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["nice introduction to life with the new rx , over \u00a3 780 to replace what should just be a just piece of plastic ! ! <URL>"], "response_list": ["we are sorry to hear that . please send us a dm so we can look into this for you ."], "metric_score": [{"USR-MLM": -2.171137809753418}]}
{"input": "[CONTEXT] hiya , i need to know where my order is , you 've gave me an incorrect tracking number and your contact number doesn 't exist ? ? [ENDOFTURN] hi lucy , could you please provide us with your order number and i can look into this for you <3 [ENDOFTURN] x [RESPONSE] please can you follow us and advise us when you have so we can dm you and assist further ? thanks . [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response a good response to the provided dialogue context? ", "index": 3989, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: In this task you will be shown a dialogue context followed by a response. You need to predict if the response is a good follow-up to the context. \nInput: [CONTEXT] hiya , i need to know where my order is , you 've gave me an incorrect tracking number and your contact number doesn 't exist ? ? [ENDOFTURN] hi lucy , could you please provide us with your order number and i can look into this for you <3 [ENDOFTURN] x [RESPONSE] please can you follow us and advise us when you have so we can dm you and assist further ? thanks . [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response a good response to the provided dialogue context? ", "output": "yes", "all_outputs": ["no"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["hiya , i need to know where my order is , you 've gave me an incorrect tracking number and your contact number doesn 't exist ? ?", "hi lucy , could you please provide us with your order number and i can look into this for you <3", "x"], "response_list": ["please can you follow us and advise us when you have so we can dm you and assist further ? thanks ."], "metric_score": [{"USR-MLM": -2.206789493560791}]}
{"input": "[CONTEXT] i 've gone to renew my @greenflaguk insurance and the price has increased from last year and never used it in the previous 12 months . why ? [RESPONSE] can you please dm us your address and phone number so we can look into this ? [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response a good response to the provided dialogue context? ", "index": 25909, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: In this task you will be shown a context followed by a response. You need to classify if the response is a good response to the context. \nInput: [CONTEXT] i 've gone to renew my @greenflaguk insurance and the price has increased from last year and never used it in the previous 12 months . why ? [RESPONSE] can you please dm us your address and phone number so we can look into this ? [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response a good response to the provided dialogue context? ", "output": "yes", "all_outputs": ["no"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["i 've gone to renew my @greenflaguk insurance and the price has increased from last year and never used it in the previous 12 months . why ?"], "response_list": ["can you please dm us your address and phone number so we can look into this ?"], "metric_score": [{"USR-MLM": -2.059563398361206}]}
{"input": "[CONTEXT] i can 't deal with all white . but then i 'm fat :( #stosa [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: sorry to hear this ! can you help us improve by providing some more info in this link <URL> ? thank you !", "index": 1947, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Return a score in the provided range which scores the response to a conversation \nInput: [CONTEXT] i can 't deal with all white . but then i 'm fat :( #stosa [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: sorry to hear this ! can you help us improve by providing some more info in this link <URL> ? thank you !", "output": "1", "all_outputs": ["3.4"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] ridiculously poor service this afternoon from the local @mercedesbenzuk dealer as per ... we 're sorry to read this , <USER> . would you like to discuss your experience with our customer service team on <NUMBERS> ? booked appt to test drive a gle . kept waiting for 20 mins after timeslot . then salesman couldn 't find key & no fuel in car ! [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: hi <USER> , we 'd like to look into this for you , if you could contact our customer care team at <E-MAIL> thanks", "index": 9648, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Return a score in the provided range which scores the response to a conversation \nInput: [CONTEXT] ridiculously poor service this afternoon from the local @mercedesbenzuk dealer as per ... we 're sorry to read this , <USER> . would you like to discuss your experience with our customer service team on <NUMBERS> ? booked appt to test drive a gle . kept waiting for 20 mins after timeslot . then salesman couldn 't find key & no fuel in car ! [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: hi <USER> , we 'd like to look into this for you , if you could contact our customer care team at <E-MAIL> thanks", "output": "1", "all_outputs": ["4.0"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] y 'all really tried it ! i don 't even want that iphone 8 ! imma trynna pay my bill and the website down ... [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: we are happy to look into this for you ! please send your info via the link below ! <URL>", "index": 38103, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: In this task you will be shown a conversation followed by a response and score range. You need to give a appropriate rating to the response.\nInput: [CONTEXT] y 'all really tried it ! i don 't even want that iphone 8 ! imma trynna pay my bill and the website down ... [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: we are happy to look into this for you ! please send your info via the link below ! <URL>", "output": "3", "all_outputs": ["4.0"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] u guys offer free whatsapp ? yes please <USER> customers on the tigo tribe offer enjoy free whatsapp , facebook , twitter and imo . you may send start to 5060 to join . oh that one . i was removed from that offer [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: hi <USER> , we 're sorry to hear this . please dm us your email address so we can look into this for you . thanks .", "index": 13754, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Given a conversation, a response to the conversation, and a score range, return a rating to the response within in score range\nInput: [CONTEXT] u guys offer free whatsapp ? yes please <USER> customers on the tigo tribe offer enjoy free whatsapp , facebook , twitter and imo . you may send start to 5060 to join . oh that one . i was removed from that offer [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: hi <USER> , we 're sorry to hear this . please dm us your email address so we can look into this for you . thanks .", "output": "1", "all_outputs": ["4.2"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] wanted to spend a vacation on a cruise trio but no idea if there are any perks for platinum card members ? [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: hi <USER> , we 'd like to look into this for you . please email us at <E-MAIL> with your name , twitter handle and phone number .", "index": 47321, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: In this task you will be shown a conversation followed by a response and score range. You need to give a appropriate rating to the response.\nInput: [CONTEXT] wanted to spend a vacation on a cruise trio but no idea if there are any perks for platinum card members ? [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: hi <USER> , we 'd like to look into this for you . please email us at <E-MAIL> with your name , twitter handle and phone number .", "output": "how can i help you?", "all_outputs": ["3.4"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] not getting any service in 33401 area . [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: hello , i can look into this for you . please dm me your full address and phone number so i can better assist .", "index": 20214, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Return a score in the provided range which scores the response to a conversation \nInput: [CONTEXT] not getting any service in 33401 area . [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: hello , i can look into this for you . please dm me your full address and phone number so i can better assist .", "output": "1", "all_outputs": ["4.3"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] User: You really don't seem so. You can tell me what's going on? [ENDOFTURN] System: I'm just fine. [ENDOFTURN] User: ok. wanna go out to eat dessert? [ENDOFTURN] System: I'm not hungry. [ENDOFTURN] User: Okay, I am heading out now [RESPONSE] naw . its just my family farm . i do not need more than one . lol [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response contextual? ", "index": 32611, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: Given a conversation and a response to the conversation, select is the response is a good response to the context.\nInput: [CONTEXT] User: You really don't seem so. You can tell me what's going on? [ENDOFTURN] System: I'm just fine. [ENDOFTURN] User: ok. wanna go out to eat dessert? [ENDOFTURN] System: I'm not hungry. [ENDOFTURN] User: Okay, I am heading out now [RESPONSE] naw . its just my family farm . i do not need more than one . lol [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response contextual? ", "output": "no", "all_outputs": ["no"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["User: You really don't seem so. You can tell me what's going on?", "System: I'm just fine.", "User: ok. wanna go out to eat dessert?", "System: I'm not hungry.", "User: Okay, I am heading out now"], "response_list": ["naw . its just my family farm . i do not need more than one . lol"], "metric_score": [{"USR-MLM": -3.192737102508545}]}
{"input": "[CONTEXT] til english word cereal derived ' ceres ' , roman goddess harvest agriculture. [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the informativeness to the following response: i m a fan of the american word.", "index": 36792, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Given a conversation, a response to the conversation, and a score range, return a rating to the response within in score range\nInput: [CONTEXT] til english word cereal derived ' ceres ' , roman goddess harvest agriculture. [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the informativeness to the following response: i m a fan of the american word.", "output": "3", "all_outputs": ["4.0"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] . @vmbusiness the slowest broadband to instal ever ... #slow #virgin [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: hi <USER> , we are sorry to hear this . please dm us your account number so we can look into this for you . thank you .", "index": 7550, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Given a conversation, a response to the conversation, and a score range, return a rating to the response within in score range\nInput: [CONTEXT] . @vmbusiness the slowest broadband to instal ever ... #slow #virgin [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: hi <USER> , we are sorry to hear this . please dm us your account number so we can look into this for you . thank you .", "output": "#slow", "all_outputs": ["3.2"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] do you have a universal policy regarding the google nexus 5x : lgh 791 bootloop issue ? or i have to negotiate where i live ? [RESPONSE] we 're sorry to hear this . please send us a dm with your order number so we can look into this for you . [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response a good response to the provided dialogue context? ", "index": 51417, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: Given a conversation and a response to the conversation, is the response a good response to the context?\nInput: [CONTEXT] do you have a universal policy regarding the google nexus 5x : lgh 791 bootloop issue ? or i have to negotiate where i live ? [RESPONSE] we 're sorry to hear this . please send us a dm with your order number so we can look into this for you . [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response a good response to the provided dialogue context? ", "output": "yes", "all_outputs": ["no"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["do you have a universal policy regarding the google nexus 5x : lgh 791 bootloop issue ? or i have to negotiate where i live ?"], "response_list": ["we 're sorry to hear this . please send us a dm with your order number so we can look into this for you ."], "metric_score": [{"USR-MLM": -2.6065139770507812}]}
{"input": "[CONTEXT] just the city for me , like now for my kids . [ENDOFTURN] that is nice , i want to go into a city [RESPONSE] please dm us your email address so we can take a look into this for you . [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response contextual? ", "index": 42151, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: Given a conversation and a response to the conversation, is the response a good response to the context?\nInput: [CONTEXT] just the city for me , like now for my kids . [ENDOFTURN] that is nice , i want to go into a city [RESPONSE] please dm us your email address so we can take a look into this for you . [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response contextual? ", "output": "yes", "all_outputs": ["no"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["just the city for me , like now for my kids .", "that is nice , i want to go into a city"], "response_list": ["please dm us your email address so we can take a look into this for you ."], "metric_score": [{"USR-MLM": -1.8728728294372559}]}
{"input": "[CONTEXT] til eleven cases blood alcohol content higher 1 % , poland holds five [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the informativeness to the following response: i m not sure if that s true.", "index": 40866, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Given a conversation, a response to the conversation, and a score range, return a rating to the response within in score range\nInput: [CONTEXT] til eleven cases blood alcohol content higher 1 % , poland holds five [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the informativeness to the following response: i m not sure if that s true.", "output": "i am not sure if that s true.", "all_outputs": ["3.0"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] hi @ukfast thanks for the 3 phone calls and answerphone message but we aren 't interested thanks . please don 't ring again . apologies . our team was hoping we could help after this tweet . we 'll ensure we won 't call again <URL> you could have done with a tweet reply but after that i 'll look elsewhere thanks . [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: you 're welcome , <USER> . we 'll be sure to pass this along to our team .", "index": 22577, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: In this task you will be shown a conversation followed by a response and score range. You need to give a appropriate rating to the response.\nInput: [CONTEXT] hi @ukfast thanks for the 3 phone calls and answerphone message but we aren 't interested thanks . please don 't ring again . apologies . our team was hoping we could help after this tweet . we 'll ensure we won 't call again <URL> you could have done with a tweet reply but after that i 'll look elsewhere thanks . [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: you 're welcome , <USER> . we 'll be sure to pass this along to our team .", "output": "", "all_outputs": ["3.4"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] hey there ! trying to use my @trinet marketplace discount , but @daysinn website isn 't showing the discount . [RESPONSE] we are happy to look into this for you ! please send your info via the link below ! <URL> [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response contextual? ", "index": 16078, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: Given a conversation and a response to the conversation, select is the response is a good response to the context.\nInput: [CONTEXT] hey there ! trying to use my @trinet marketplace discount , but @daysinn website isn 't showing the discount . [RESPONSE] we are happy to look into this for you ! please send your info via the link below ! <URL> [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response contextual? ", "output": "yes", "all_outputs": ["yes"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["hey there ! trying to use my @trinet marketplace discount , but @daysinn website isn 't showing the discount ."], "response_list": ["we are happy to look into this for you ! please send your info via the link below ! <URL>"], "metric_score": [{"USR-MLM": -2.9154224395751953}]}
{"input": "[CONTEXT] how do i check firmware ? and it 's pairing on iphone . [ENDOFTURN] you can check the firmware through the \" firmware \" option in the setup menu of the camera . what ios is the iphone running ? [ENDOFTURN] attached both settings <URL> [ENDOFTURN] perfect . there is a firmware update that is available for this camera that we would recommend : <URL> [ENDOFTURN] does it need hooked up to a computer as the camera did not come with any cables . [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: she was also the first.||||B: you should be able to log in to your device . if you need further assistance , please let us know .||||C: hi <USER> , i 'm sorry to hear this . can you please dm me your account number and i can look into this for you ? thanks ,||||D: we 're sorry to hear about your experience , <USER> . please give us a call at <NUMBERS> if you wish to further discuss your concern . [QUESTION] The response which is the best follow-up to the conversation is ", "index": 5908, "split": "train", "classes_in_options": ["A", "B", "C", "D"], "candidates": ["she was also the first.", "you should be able to log in to your device . if you need further assistance , please let us know .", "hi <USER> , i 'm sorry to hear this . can you please dm me your account number and i can look into this for you ? thanks ,", "we 're sorry to hear about your experience , <USER> . please give us a call at <NUMBERS> if you wish to further discuss your concern ."], "dataset": "eval", "task": "eval_ranking", "prompt": "Instruction: In this task you will be shown a conversation followed by some responses. You need to choose the best response from the provided responses. \nInput: [CONTEXT] how do i check firmware ? and it 's pairing on iphone . [ENDOFTURN] you can check the firmware through the \" firmware \" option in the setup menu of the camera . what ios is the iphone running ? [ENDOFTURN] attached both settings <URL> [ENDOFTURN] perfect . there is a firmware update that is available for this camera that we would recommend : <URL> [ENDOFTURN] does it need hooked up to a computer as the camera did not come with any cables . [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: she was also the first.||||B: you should be able to log in to your device . if you need further assistance , please let us know .||||C: hi <USER> , i 'm sorry to hear this . can you please dm me your account number and i can look into this for you ? thanks ,||||D: we 're sorry to hear about your experience , <USER> . please give us a call at <NUMBERS> if you wish to further discuss your concern . [QUESTION] The response which is the best follow-up to the conversation is ", "output": "B", "all_outputs": ["B"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["how do i check firmware ? and it 's pairing on iphone .", "you can check the firmware through the \" firmware \" option in the setup menu of the camera . what ios is the iphone running ?", "attached both settings <URL>", "perfect . there is a firmware update that is available for this camera that we would recommend : <URL>", "does it need hooked up to a computer as the camera did not come with any cables ."], "response_list": ["she was also the first.", "you should be able to log in to your device . if you need further assistance , please let us know .", "hi <USER> , i 'm sorry to hear this . can you please dm me your account number and i can look into this for you ? thanks ,", "we 're sorry to hear about your experience , <USER> . please give us a call at <NUMBERS> if you wish to further discuss your concern ."], "metric_score": [{"USR-MLM": -2.7598860263824463}, {"USR-MLM": -2.263259172439575}, {"USR-MLM": -2.4094161987304688}, {"USR-MLM": -2.332050323486328}]}
{"input": "[CONTEXT] til one unsung heroes 9/11 guide dog , roselle , yellow labrador led blind owner , michael hingson , 78 storeys north tower home friend. .. realized like dogs alive 9/11 probably dead .. =[ [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the informativeness to the following response: i don't know what you mean.", "index": 20475, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Return a score in the provided range which scores the response to a conversation \nInput: [CONTEXT] til one unsung heroes 9/11 guide dog , roselle , yellow labrador led blind owner , michael hingson , 78 storeys north tower home friend. .. realized like dogs alive 9/11 probably dead .. =[ [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the informativeness to the following response: i don't know what you mean.", "output": "4", "all_outputs": ["2.3333333333333335"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] - not even 10 months got moto g4 ... severe batry issues from past 2 mnths ! ! no way to get it serviced .. want urgetnt solution . hi , a lot factors come into play when it comes to the battery performance of the phone . please check <URL> . battery drains out within 1 hr of fully charged phone ! ! [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: we 'd like to look into this for you . please send us a direct message with your registered email address . <URL>", "index": 35552, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Return a score in the provided range which scores the response to a conversation \nInput: [CONTEXT] - not even 10 months got moto g4 ... severe batry issues from past 2 mnths ! ! no way to get it serviced .. want urgetnt solution . hi , a lot factors come into play when it comes to the battery performance of the phone . please check <URL> . battery drains out within 1 hr of fully charged phone ! ! [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: we 'd like to look into this for you . please send us a direct message with your registered email address . <URL>", "output": "can you tell me where to send it to and what for", "all_outputs": ["3.8"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] can you help me with a sat nav issue and subsequent complaint about my jeep dealership ? [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: i 'm sorry to hear this . please dm me with your vin and contact info so i can look into this further for you .", "index": 15280, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Given a conversation, a response to the conversation, and a score range, return a rating to the response within in score range\nInput: [CONTEXT] can you help me with a sat nav issue and subsequent complaint about my jeep dealership ? [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: i 'm sorry to hear this . please dm me with your vin and contact info so i can look into this further for you .", "output": "i apologize, and what was the matter you are being referred to?", "all_outputs": ["3.7"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] 25 minutes and no bus . this is why i hate the @ttchelps [RESPONSE] thanks <USER> ! [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response contextual? ", "index": 42829, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: In this task you will be shown a context followed by a response. You need to classify if the response is a good response to the context. \nInput: [CONTEXT] 25 minutes and no bus . this is why i hate the @ttchelps [RESPONSE] thanks <USER> ! [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response contextual? ", "output": "no", "all_outputs": ["no"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["25 minutes and no bus . this is why i hate the @ttchelps"], "response_list": ["thanks <USER> !"], "metric_score": [{"USR-MLM": -3.066763162612915}]}
{"input": "[CONTEXT] 3hrs waiting on the side of the m1 for @greenflaguk consequently wasn 't able to get to my job in london & had to pay a fortune to get towed [RESPONSE] hi <USER> , i 'm sorry to hear this . please dm us your contact details so we can look into this for you . thanks , [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response contextual? ", "index": 61041, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: Select if the provided response follow the provided conversationSelect if the provided response a good response to the provided dialogue context.\nInput: [CONTEXT] 3hrs waiting on the side of the m1 for @greenflaguk consequently wasn 't able to get to my job in london & had to pay a fortune to get towed [RESPONSE] hi <USER> , i 'm sorry to hear this . please dm us your contact details so we can look into this for you . thanks , [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response contextual? ", "output": "yes", "all_outputs": ["no"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["3hrs waiting on the side of the m1 for @greenflaguk consequently wasn 't able to get to my job in london & had to pay a fortune to get towed"], "response_list": ["hi <USER> , i 'm sorry to hear this . please dm us your contact details so we can look into this for you . thanks ,"], "metric_score": [{"USR-MLM": -2.4911105632781982}]}
{"input": "[CONTEXT] in loveee with my new business cards . @moo you guys are amazing , i & @ # % ing \u2764 \ufe0f \u2764 \ufe0f \u2764 \ufe0f them ! \u2026 <URL> [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: happy birthday ! ! !", "index": 37074, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Return a score in the provided range which scores the response to a conversation \nInput: [CONTEXT] in loveee with my new business cards . @moo you guys are amazing , i & @ # % ing \u2764 \ufe0f \u2764 \ufe0f \u2764 \ufe0f them ! \u2026 <URL> [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: happy birthday ! ! !", "output": "5", "all_outputs": ["2.0"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] how long is the bogo promo available ? also is it good for all phones incl . iphone 8 & x ? [ENDOFTURN] that 's for a limited time not sure how long will it be for . i 'm not sure if we would be doing it for other iphones . [ENDOFTURN] so you 're saying it 's only for 7 \u2032 s ? [ENDOFTURN] at this moment the promotion is only for the iphone 7 . [ENDOFTURN] ok , thanks . [RESPONSE] you 're welcome ! [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response a good response to the provided dialogue context? ", "index": 62246, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: Select if the provided response follow the provided conversationSelect if the provided response a good response to the provided dialogue context.\nInput: [CONTEXT] how long is the bogo promo available ? also is it good for all phones incl . iphone 8 & x ? [ENDOFTURN] that 's for a limited time not sure how long will it be for . i 'm not sure if we would be doing it for other iphones . [ENDOFTURN] so you 're saying it 's only for 7 \u2032 s ? [ENDOFTURN] at this moment the promotion is only for the iphone 7 . [ENDOFTURN] ok , thanks . [RESPONSE] you 're welcome ! [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response a good response to the provided dialogue context? ", "output": "yes", "all_outputs": ["yes"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["how long is the bogo promo available ? also is it good for all phones incl . iphone 8 & x ?", "that 's for a limited time not sure how long will it be for . i 'm not sure if we would be doing it for other iphones .", "so you 're saying it 's only for 7 \u2032 s ?", "at this moment the promotion is only for the iphone 7 .", "ok , thanks ."], "response_list": ["you 're welcome !"], "metric_score": [{"USR-MLM": -1.1642036437988281}]}
{"input": "[CONTEXT] Hi! Hey! How are you doing today? i am so so That's awesome! What have you been up to? just back to work What do you do? What do you like to do when you aren't at work? i am an engineer What kind of engineer? i go hiking when i am not workig Where do you go hiking? What kind of work do you do? [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 0 to 4 about the likeable to the following response: software engineer", "index": 26496, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Return a score in the provided range which scores the response to a conversation \nInput: [CONTEXT] Hi! Hey! How are you doing today? i am so so That's awesome! What have you been up to? just back to work What do you do? What do you like to do when you aren't at work? i am an engineer What kind of engineer? i go hiking when i am not workig Where do you go hiking? What kind of work do you do? [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 0 to 4 about the likeable to the following response: software engineer", "output": "work type", "all_outputs": ["1.4"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] when will the link got this be up ? i can 't find it on your site <URL> [RESPONSE] hi <USER> , we do not have a release date at this point . we will share it on this page once confirmed . ^ ; sm [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response contextual? ", "index": 55814, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: Given a conversation and a response to the conversation, is it a relevant response to the context?\nInput: [CONTEXT] when will the link got this be up ? i can 't find it on your site <URL> [RESPONSE] hi <USER> , we do not have a release date at this point . we will share it on this page once confirmed . ^ ; sm [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response contextual? ", "output": "yes", "all_outputs": ["yes"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["when will the link got this be up ? i can 't find it on your site <URL>"], "response_list": ["hi <USER> , we do not have a release date at this point . we will share it on this page once confirmed . ^ ; sm"], "metric_score": [{"USR-MLM": -2.5709807872772217}]}
{"input": "[CONTEXT] til slash defibrillator implanted since age 35. years drug alcohol abuse given congestive heart failure , given little 6 days live 2001. [ENDOFTURN] amazingly , every guns n roses band member appetite destruction still alive. [ENDOFTURN] motley too? like f..? [ENDOFTURN] none hold candle ozzy. he's actually donating body science dies figure lived drugs alcohol. [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: i like to watch the little ones play with their heads off .||||B: easy buddy, no need to annex a country over this...||||C: we 're sorry to hear this . can you please dm us your order number so we can look into this for you ? thanks !||||D: sorry to hear this ! can you help us improve by providing some more info in this link <URL> ? thank you ! [QUESTION] The correct response is ", "index": 4125, "split": "train", "classes_in_options": ["A", "B", "C", "D"], "candidates": ["i like to watch the little ones play with their heads off .", "easy buddy, no need to annex a country over this...", "we 're sorry to hear this . can you please dm us your order number so we can look into this for you ? thanks !", "sorry to hear this ! can you help us improve by providing some more info in this link <URL> ? thank you !"], "dataset": "eval", "task": "eval_ranking", "prompt": "Instruction: Select the best response from the provided responses to a conversation\nInput: [CONTEXT] til slash defibrillator implanted since age 35. years drug alcohol abuse given congestive heart failure , given little 6 days live 2001. [ENDOFTURN] amazingly , every guns n roses band member appetite destruction still alive. [ENDOFTURN] motley too? like f..? [ENDOFTURN] none hold candle ozzy. he's actually donating body science dies figure lived drugs alcohol. [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: i like to watch the little ones play with their heads off .||||B: easy buddy, no need to annex a country over this...||||C: we 're sorry to hear this . can you please dm us your order number so we can look into this for you ? thanks !||||D: sorry to hear this ! can you help us improve by providing some more info in this link <URL> ? thank you ! [QUESTION] The correct response is ", "output": "A", "all_outputs": ["B"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["til slash defibrillator implanted since age 35. years drug alcohol abuse given congestive heart failure , given little 6 days live 2001.", "amazingly , every guns n roses band member appetite destruction still alive.", "motley too? like f..?", "none hold candle ozzy. he's actually donating body science dies figure lived drugs alcohol."], "response_list": ["i like to watch the little ones play with their heads off .", "easy buddy, no need to annex a country over this...", "we 're sorry to hear this . can you please dm us your order number so we can look into this for you ? thanks !", "sorry to hear this ! can you help us improve by providing some more info in this link <URL> ? thank you !"], "metric_score": [{"USR-MLM": -5.268912315368652}, {"USR-MLM": -5.723177433013916}, {"USR-MLM": -4.906261920928955}, {"USR-MLM": -4.705450534820557}]}
{"input": "[CONTEXT] cheering on our #aus #basketball team to win at #rio2016 . game on ! #oneteam <URL> [RESPONSE] great photo , <USER> ! thank you for sharing this with us . [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response contextual? ", "index": 6442, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: Given a conversation and a response to the conversation, select is the response is a good response to the context.\nInput: [CONTEXT] cheering on our #aus #basketball team to win at #rio2016 . game on ! #oneteam <URL> [RESPONSE] great photo , <USER> ! thank you for sharing this with us . [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response contextual? ", "output": "yes", "all_outputs": ["yes"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["cheering on our #aus #basketball team to win at #rio2016 . game on ! #oneteam <URL>"], "response_list": ["great photo , <USER> ! thank you for sharing this with us ."], "metric_score": [{"USR-MLM": -3.8032116889953613}]}
{"input": "[CONTEXT] til nintendo sued galoob prevent release nes cheating device , game genie ; legal battle followed. sega genesis version , sega allowed release , officially licensed it. [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the relevance to the following response: it is a good game.", "index": 4964, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Return a score in the provided range which scores the response to a conversation \nInput: [CONTEXT] til nintendo sued galoob prevent release nes cheating device , game genie ; legal battle followed. sega genesis version , sega allowed release , officially licensed it. [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the relevance to the following response: it is a good game.", "output": "I think sega genesis is a very good game.", "all_outputs": ["3.3333333333333335"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] why can 't i open my car windows with my car key ... or the merc me app . followed hbook but doesn 't work ? key isn 't keyless go [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: we 're sorry to hear that , <USER> . please send us a dm and we 'll be happy to look into this for you .||||B: please dm your contact details to our service team @vodacom111 so they can look into this issue for you .||||C: what did your boss say to him ?||||D: hi <USER> , we 're sorry to hear this . can you please dm us your contact details so we can look into this for you ? thanks . [QUESTION] The response which is the best follow-up to the conversation is ", "index": 26944, "split": "train", "classes_in_options": ["A", "B", "C", "D"], "candidates": ["we 're sorry to hear that , <USER> . please send us a dm and we 'll be happy to look into this for you .", "please dm your contact details to our service team @vodacom111 so they can look into this issue for you .", "what did your boss say to him ?", "hi <USER> , we 're sorry to hear this . can you please dm us your contact details so we can look into this for you ? thanks ."], "dataset": "eval", "task": "eval_ranking", "prompt": "Instruction: In this task you will be shown a conversation followed by some responses. You need to choose the best response from the provided responses. \nInput: [CONTEXT] why can 't i open my car windows with my car key ... or the merc me app . followed hbook but doesn 't work ? key isn 't keyless go [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: we 're sorry to hear that , <USER> . please send us a dm and we 'll be happy to look into this for you .||||B: please dm your contact details to our service team @vodacom111 so they can look into this issue for you .||||C: what did your boss say to him ?||||D: hi <USER> , we 're sorry to hear this . can you please dm us your contact details so we can look into this for you ? thanks . [QUESTION] The response which is the best follow-up to the conversation is ", "output": "B", "all_outputs": ["D"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["why can 't i open my car windows with my car key ... or the merc me app . followed hbook but doesn 't work ? key isn 't keyless go"], "response_list": ["we 're sorry to hear that , <USER> . please send us a dm and we 'll be happy to look into this for you .", "please dm your contact details to our service team @vodacom111 so they can look into this issue for you .", "what did your boss say to him ?", "hi <USER> , we 're sorry to hear this . can you please dm us your contact details so we can look into this for you ? thanks ."], "metric_score": [{"USR-MLM": -2.7903637886047363}, {"USR-MLM": -3.325254201889038}, {"USR-MLM": -3.404879570007324}, {"USR-MLM": -2.7614588737487793}]}
{"input": "[CONTEXT] til families columbine shooters paid millions settlements victims families. insurance agent , advise everyone never kids. never. insurance agent father 3 year old , agree. someone expecting first child moment , thread terrifies me. father 4 year old 1.5 year old , kids best. congrats welcome club. father 4 , 1 16 year old girl ; confirm kids best hit teens , blow half shared data plan 8 days think know every fucking thing. edit : data [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the relevance to the following response: ,, .", "index": 790, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: In this task you will be shown a conversation followed by a response and score range. You need to give a appropriate rating to the response.\nInput: [CONTEXT] til families columbine shooters paid millions settlements victims families. insurance agent , advise everyone never kids. never. insurance agent father 3 year old , agree. someone expecting first child moment , thread terrifies me. father 4 year old 1.5 year old , kids best. congrats welcome club. father 4 , 1 16 year old girl ; confirm kids best hit teens , blow half shared data plan 8 days think know every fucking thing. edit : data [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the relevance to the following response: ,, .", "output": "1", "all_outputs": ["1.3333333333333333"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] til hairy frog known the\" wolverine frog\" thought intentionally break toe bones force sharp\" claws\" flesh means defence. [RESPONSE] i think the word \" \" \" is a \" \" \" \". \" \" \" \" \" \" \" \" \" \" \" \" \" \" \". [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Select the right option: is the response is a good follow-up response? ", "index": 42548, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: In this task you will be shown a dialogue context followed by a response. You need to predict if the response is a good follow-up to the context. \nInput: [CONTEXT] til hairy frog known the\" wolverine frog\" thought intentionally break toe bones force sharp\" claws\" flesh means defence. [RESPONSE] i think the word \" \" \" is a \" \" \" \". \" \" \" \" \" \" \" \" \" \" \" \" \" \" \". [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Select the right option: is the response is a good follow-up response? ", "output": "no", "all_outputs": ["yes"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["til hairy frog known the\" wolverine frog\" thought intentionally break toe bones force sharp\" claws\" flesh means defence."], "response_list": ["i think the word \" \" \" is a \" \" \" \". \" \" \" \" \" \" \" \" \" \" \" \" \" \" \"."], "metric_score": [{"USR-MLM": -3.525592565536499}]}
{"input": "[CONTEXT] til 80s hair band winger trace massive mid - 90s downfall popularity mocked relentlessly on\" beavis butt-head\" subsequent mike judge projects [RESPONSE] we 'd be happy to check for you . pls dm us w / your reservation # & branch location . thanks ! [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response contextual? ", "index": 9271, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: Select if the provided response follow the provided conversationSelect if the provided response a good response to the provided dialogue context.\nInput: [CONTEXT] til 80s hair band winger trace massive mid - 90s downfall popularity mocked relentlessly on\" beavis butt-head\" subsequent mike judge projects [RESPONSE] we 'd be happy to check for you . pls dm us w / your reservation # & branch location . thanks ! [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response contextual? ", "output": "no", "all_outputs": ["no"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["til 80s hair band winger trace massive mid - 90s downfall popularity mocked relentlessly on\" beavis butt-head\" subsequent mike judge projects"], "response_list": ["we 'd be happy to check for you . pls dm us w / your reservation # & branch location . thanks !"], "metric_score": [{"USR-MLM": -5.026790142059326}]}
{"input": "[CONTEXT] will you be selling your apple watch bands in canada ? i need the artisan collection blue one ! hi there ! they are available at select jump + stores in canada . thank you ! there isn 't any jump + stores near me , and i didn 't see the artisan on their site . will the bands come to vancouver ? ty ! we don 't have info for toms . ca at this time but we 'll share your feedback with our product team . thank you ! ty ! are these bands le ? the blue artisan band is currently oos on the website - will it come back ? hi ! what do you mean by le ? we don 't have restocking info at this time for any of the bands . feel free to dm us . thx ! limited edition . :) i was waiting to order the artisan from the us website but now it 's oos - so i 'm hoping it will come back [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: hi <USER> , we are sorry to hear this . please can you dm us your order number so we can look into this for you . thanks .", "index": 50356, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Given a conversation, a response to the conversation, and a score range, return a rating to the response within in score range\nInput: [CONTEXT] will you be selling your apple watch bands in canada ? i need the artisan collection blue one ! hi there ! they are available at select jump + stores in canada . thank you ! there isn 't any jump + stores near me , and i didn 't see the artisan on their site . will the bands come to vancouver ? ty ! we don 't have info for toms . ca at this time but we 'll share your feedback with our product team . thank you ! ty ! are these bands le ? the blue artisan band is currently oos on the website - will it come back ? hi ! what do you mean by le ? we don 't have restocking info at this time for any of the bands . feel free to dm us . thx ! limited edition . :) i was waiting to order the artisan from the us website but now it 's oos - so i 'm hoping it will come back [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: hi <USER> , we are sorry to hear this . please can you dm us your order number so we can look into this for you . thanks .", "output": "", "all_outputs": ["2.3"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] i 've been trying <URL> and for months and it 's still broken . sent an email to support with no response . [ENDOFTURN] hi there . is your amex card issued out of us or canada ? [ENDOFTURN] it 's a us-issued card , but i live in canada now . any word on this ? [RESPONSE] pls call <NUMBERS> , 24/7 for assistance . all the best . [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Select the right option: is the response is a good follow-up response? ", "index": 71644, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: Given a conversation and a response to the conversation, is it a relevant response to the context?\nInput: [CONTEXT] i 've been trying <URL> and for months and it 's still broken . sent an email to support with no response . [ENDOFTURN] hi there . is your amex card issued out of us or canada ? [ENDOFTURN] it 's a us-issued card , but i live in canada now . any word on this ? [RESPONSE] pls call <NUMBERS> , 24/7 for assistance . all the best . [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Select the right option: is the response is a good follow-up response? ", "output": "yes", "all_outputs": ["yes"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["i 've been trying <URL> and for months and it 's still broken . sent an email to support with no response .", "hi there . is your amex card issued out of us or canada ?", "it 's a us-issued card , but i live in canada now . any word on this ?"], "response_list": ["pls call <NUMBERS> , 24/7 for assistance . all the best ."], "metric_score": [{"USR-MLM": -1.7282052040100098}]}
{"input": "[CONTEXT] again i say stop stealing my credit ooo [RESPONSE] kindly provide your mobile number for checks and assist . thank you . uo . [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response a good response to the provided dialogue context? ", "index": 31810, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: In this task you will be shown a dialogue context followed by a response. You need to predict if the response is a good follow-up to the context. \nInput: [CONTEXT] again i say stop stealing my credit ooo [RESPONSE] kindly provide your mobile number for checks and assist . thank you . uo . [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response a good response to the provided dialogue context? ", "output": "no", "all_outputs": ["yes"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["again i say stop stealing my credit ooo"], "response_list": ["kindly provide your mobile number for checks and assist . thank you . uo ."], "metric_score": [{"USR-MLM": -3.1282613277435303}]}
{"input": "[CONTEXT] y is it that my pkg was set to be delivered by the end of today & then i check again n now deliv date is 9/5 by @usps ? not happy [RESPONSE] thanks for the love , <USER> ! \u263a [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Select the right option: is the response is a good follow-up response? ", "index": 40339, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: Given a conversation and a response to the conversation, is it a relevant response to the context?\nInput: [CONTEXT] y is it that my pkg was set to be delivered by the end of today & then i check again n now deliv date is 9/5 by @usps ? not happy [RESPONSE] thanks for the love , <USER> ! \u263a [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Select the right option: is the response is a good follow-up response? ", "output": "no", "all_outputs": ["no"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["y is it that my pkg was set to be delivered by the end of today & then i check again n now deliv date is 9/5 by @usps ? not happy"], "response_list": ["thanks for the love , <USER> ! \u263a"], "metric_score": [{"USR-MLM": -2.9999516010284424}]}
{"input": "[CONTEXT] been with you guys under a month and been unfortunate enough to have 2 breakdowns . but you 've been fantastic both times \ud83d\udc4f \ud83c\udffb \ud83d\udc4c \ud83c\udffb [ENDOFTURN] i 'm so pleased we could help ! hopefully you won 't need us for a long time , but i 'm glad you know we 're here if you do . [ENDOFTURN] thank you . please pass regards to kavanagh motor services for their service yesterday . [ENDOFTURN] i 'll be happy to . would you mind dming your reg to help them locate the file ? thanks . [ENDOFTURN] sorted ! [RESPONSE] what about the? [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Select the right option: is the response is a good follow-up response? ", "index": 29151, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: Given a conversation and a response to the conversation, is it a relevant response to the context?\nInput: [CONTEXT] been with you guys under a month and been unfortunate enough to have 2 breakdowns . but you 've been fantastic both times \ud83d\udc4f \ud83c\udffb \ud83d\udc4c \ud83c\udffb [ENDOFTURN] i 'm so pleased we could help ! hopefully you won 't need us for a long time , but i 'm glad you know we 're here if you do . [ENDOFTURN] thank you . please pass regards to kavanagh motor services for their service yesterday . [ENDOFTURN] i 'll be happy to . would you mind dming your reg to help them locate the file ? thanks . [ENDOFTURN] sorted ! [RESPONSE] what about the? [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Select the right option: is the response is a good follow-up response? ", "output": "yes", "all_outputs": ["no"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["been with you guys under a month and been unfortunate enough to have 2 breakdowns . but you 've been fantastic both times \ud83d\udc4f \ud83c\udffb \ud83d\udc4c \ud83c\udffb", "i 'm so pleased we could help ! hopefully you won 't need us for a long time , but i 'm glad you know we 're here if you do .", "thank you . please pass regards to kavanagh motor services for their service yesterday .", "i 'll be happy to . would you mind dming your reg to help them locate the file ? thanks .", "sorted !"], "response_list": ["what about the?"], "metric_score": [{"USR-MLM": -2.6883227825164795}]}
{"input": "[CONTEXT] til tourism sector boomed , kazakhstan's foreign minister thanked sacha baron cohen 2012 release borat country saw 10x increase issued visas. [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the informativeness to the following response: which is pretty much how everything works. yes it's fine until it's me.", "index": 31028, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Return a score in the provided range which scores the response to a conversation \nInput: [CONTEXT] til tourism sector boomed , kazakhstan's foreign minister thanked sacha baron cohen 2012 release borat country saw 10x increase issued visas. [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the informativeness to the following response: which is pretty much how everything works. yes it's fine until it's me.", "output": "5", "all_outputs": ["2.3333333333333335"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] til sean bean scared helicopter flying preferred hike miles mountain full costume film lord rings scenes method acting. helicopters middle earth. really got character. lot work die 1st movie trilogy. people love kill sean bean .. like , thing. great good job sad often happens early stories acting skills squandered , time screen sure fucking great job [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the informativeness to the following response: it's not uncommon.", "index": 6122, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Given a conversation, a response to the conversation, and a score range, return a rating to the response within in score range\nInput: [CONTEXT] til sean bean scared helicopter flying preferred hike miles mountain full costume film lord rings scenes method acting. helicopters middle earth. really got character. lot work die 1st movie trilogy. people love kill sean bean .. like , thing. great good job sad often happens early stories acting skills squandered , time screen sure fucking great job [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the informativeness to the following response: it's not uncommon.", "output": "5", "all_outputs": ["2.6666666666666665"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] Hi! Hi! How are you doing today? Very busy and you? Busy but good. What are you busy with? work, I need to finish bunch of stuff before the day ends Ah, well good luck with that! thanks You're welcome! How's your day been? so far so good, couple meetings and coding Sounds like a productive day to me! I agree So how are the meetings going? [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 0 to 4 about the flexible to the following response: going well, trying to move the projects", "index": 31175, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Given a conversation, a response to the conversation, and a score range, return a rating to the response within in score range\nInput: [CONTEXT] Hi! Hi! How are you doing today? Very busy and you? Busy but good. What are you busy with? work, I need to finish bunch of stuff before the day ends Ah, well good luck with that! thanks You're welcome! How's your day been? so far so good, couple meetings and coding Sounds like a productive day to me! I agree So how are the meetings going? [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 0 to 4 about the flexible to the following response: going well, trying to move the projects", "output": "no", "all_outputs": ["2.0"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] sent a package for overnight delivery to a client in houston . client waited all day no show . i 'm extremely pressed . [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: we 're sorry to hear this . please dm us your order number so we can look into this for you . thank you .||||B: hi <USER> , how can we help you ?||||C: we 're here to help ! send us a dm and we 'll take a closer look . <URL> * alissafast||||D: we are now following you . [QUESTION] The response which is the best follow-up to the conversation is ", "index": 19356, "split": "train", "classes_in_options": ["A", "B", "C", "D"], "candidates": ["we 're sorry to hear this . please dm us your order number so we can look into this for you . thank you .", "hi <USER> , how can we help you ?", "we 're here to help ! send us a dm and we 'll take a closer look . <URL> * alissafast", "we are now following you ."], "dataset": "eval", "task": "eval_ranking", "prompt": "Instruction: Select the best response from the provided responses to a conversation\nInput: [CONTEXT] sent a package for overnight delivery to a client in houston . client waited all day no show . i 'm extremely pressed . [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: we 're sorry to hear this . please dm us your order number so we can look into this for you . thank you .||||B: hi <USER> , how can we help you ?||||C: we 're here to help ! send us a dm and we 'll take a closer look . <URL> * alissafast||||D: we are now following you . [QUESTION] The response which is the best follow-up to the conversation is ", "output": "A", "all_outputs": ["A"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["sent a package for overnight delivery to a client in houston . client waited all day no show . i 'm extremely pressed ."], "response_list": ["we 're sorry to hear this . please dm us your order number so we can look into this for you . thank you .", "hi <USER> , how can we help you ?", "we 're here to help ! send us a dm and we 'll take a closer look . <URL> * alissafast", "we are now following you ."], "metric_score": [{"USR-MLM": -1.8723759651184082}, {"USR-MLM": -2.092864990234375}, {"USR-MLM": -2.441512107849121}, {"USR-MLM": -2.2393810749053955}]}
{"input": "[CONTEXT] don 't expire for another week :( @aldiusa <URL> [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: hi <USER> , we 're sorry to hear about this . can you please dm us your username so we can look into this for you ? thanks .", "index": 14009, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Given a conversation, a response to the conversation, and a score range, return a rating to the response within in score range\nInput: [CONTEXT] don 't expire for another week :( @aldiusa <URL> [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: hi <USER> , we 're sorry to hear about this . can you please dm us your username so we can look into this for you ? thanks .", "output": "i m sorry i can 't help you with anything right now. was there any other way to reach you?", "all_outputs": ["3.2"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] why doesn 't your marketing stop phrase work . i don 't want to receive marketing messages from you ! <URL> [RESPONSE] that 's the best way to spend your day ! [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Select the right option: is the response is a good follow-up response? ", "index": 36177, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: Given a conversation and a response to the conversation, is the response a good response to the context?\nInput: [CONTEXT] why doesn 't your marketing stop phrase work . i don 't want to receive marketing messages from you ! <URL> [RESPONSE] that 's the best way to spend your day ! [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Select the right option: is the response is a good follow-up response? ", "output": "no", "all_outputs": ["no"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["why doesn 't your marketing stop phrase work . i don 't want to receive marketing messages from you ! <URL>"], "response_list": ["that 's the best way to spend your day !"], "metric_score": [{"USR-MLM": -2.394749879837036}]}
{"input": "[CONTEXT] hello , @tigoghana you menez promised to work on the poor network reception in my area months come pass no changes [RESPONSE] we 'd like to hear more about your experience ! please dm your reservation number , contact info and branch location . thanks ! [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response contextual? ", "index": 33335, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: Given a conversation and a response to the conversation, is the response a good response to the context?\nInput: [CONTEXT] hello , @tigoghana you menez promised to work on the poor network reception in my area months come pass no changes [RESPONSE] we 'd like to hear more about your experience ! please dm your reservation number , contact info and branch location . thanks ! [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response contextual? ", "output": "no", "all_outputs": ["no"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["hello , @tigoghana you menez promised to work on the poor network reception in my area months come pass no changes"], "response_list": ["we 'd like to hear more about your experience ! please dm your reservation number , contact info and branch location . thanks !"], "metric_score": [{"USR-MLM": -3.7222609519958496}]}
{"input": "[CONTEXT] Hello! How are you today? I am good, how are you? Pretty good. I'd be better if my kids visited, though. What do you do for a living? I'm a housekeeper now. I used to paint, though. You? I'm a car salesman. Are you married? Yes, I am married. I don't know if my husband sees me the same as he used to, though. How old is your husband? He is 60 and i am 56. That is a lot of money. Do you work? I do work, as a housekeeper. You? [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 0 to 4 about the persona_guess to the following response: I sell cars. Do you have any hobbies?", "index": 30983, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Given a conversation, a response to the conversation, and a score range, return a rating to the response within in score range\nInput: [CONTEXT] Hello! How are you today? I am good, how are you? Pretty good. I'd be better if my kids visited, though. What do you do for a living? I'm a housekeeper now. I used to paint, though. You? I'm a car salesman. Are you married? Yes, I am married. I don't know if my husband sees me the same as he used to, though. How old is your husband? He is 60 and i am 56. That is a lot of money. Do you work? I do work, as a housekeeper. You? [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 0 to 4 about the persona_guess to the following response: I sell cars. Do you have any hobbies?", "output": "I like to play sports.", "all_outputs": ["1.0"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] your 5 steps . of front service need a review at the mountain highway store melb . 17 minutes for a zinger burger . never again . [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: we 're sorry to hear that . please dm us your itinerary number and email address so we can take a look into this for you .||||B: serial killers are not the same thing. it's a very good point.||||C: that 's disappointing to hear ! could you please send us a dm with more info so we can put things right for you ?||||D: please dm us your phone number for further assistance . [QUESTION] The correct response is ", "index": 281, "split": "train", "classes_in_options": ["A", "B", "C", "D"], "candidates": ["we 're sorry to hear that . please dm us your itinerary number and email address so we can take a look into this for you .", "serial killers are not the same thing. it's a very good point.", "that 's disappointing to hear ! could you please send us a dm with more info so we can put things right for you ?", "please dm us your phone number for further assistance ."], "dataset": "eval", "task": "eval_ranking", "prompt": "Instruction: Select the best response from the provided responses to a conversation\nInput: [CONTEXT] your 5 steps . of front service need a review at the mountain highway store melb . 17 minutes for a zinger burger . never again . [ENDOFDIALOGUE] These are the candidate responses: [OPTIONS] A: we 're sorry to hear that . please dm us your itinerary number and email address so we can take a look into this for you .||||B: serial killers are not the same thing. it's a very good point.||||C: that 's disappointing to hear ! could you please send us a dm with more info so we can put things right for you ?||||D: please dm us your phone number for further assistance . [QUESTION] The correct response is ", "output": "C", "all_outputs": ["C"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["your 5 steps . of front service need a review at the mountain highway store melb . 17 minutes for a zinger burger . never again ."], "response_list": ["we 're sorry to hear that . please dm us your itinerary number and email address so we can take a look into this for you .", "serial killers are not the same thing. it's a very good point.", "that 's disappointing to hear ! could you please send us a dm with more info so we can put things right for you ?", "please dm us your phone number for further assistance ."], "metric_score": [{"USR-MLM": -2.8656795024871826}, {"USR-MLM": -3.196878671646118}, {"USR-MLM": -2.918347120285034}, {"USR-MLM": -3.670159339904785}]}
{"input": "[CONTEXT] my order delivered to the wrong address . 7 days later + 5 phone calls w / support i 'm told it 's back at shipper and nothing can be done \ud83d\ude21 [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: we 're so sorry to hear this . please dm us with your order number so we can look into this for you . thanks !", "index": 26648, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Return a score in the provided range which scores the response to a conversation \nInput: [CONTEXT] my order delivered to the wrong address . 7 days later + 5 phone calls w / support i 'm told it 's back at shipper and nothing can be done \ud83d\ude21 [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: we 're so sorry to hear this . please dm us with your order number so we can look into this for you . thanks !", "output": "1", "all_outputs": ["4.1"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] making a complete mountain out of a molehill and won 't confirm where they are sending my bloody tickets to ! awful service ! bought tickets for a group from my own account using my friends card . ridiculous amount of emails back & forth with no answer ! i 'm sick of the emails to a diff member of staff each time . someone contact me immediately \u200b by telephone . dm for my number ! [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: hello , please dm your order ref and full address so we can assist ? thanks mw", "index": 40231, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: In this task you will be shown a conversation followed by a response and score range. You need to give a appropriate rating to the response.\nInput: [CONTEXT] making a complete mountain out of a molehill and won 't confirm where they are sending my bloody tickets to ! awful service ! bought tickets for a group from my own account using my friends card . ridiculous amount of emails back & forth with no answer ! i 'm sick of the emails to a diff member of staff each time . someone contact me immediately \u200b by telephone . dm for my number ! [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: hello , please dm your order ref and full address so we can assist ? thanks mw", "output": "1", "all_outputs": ["3.3"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] first episode of @handmaidsonhulu watched . creepy , oppressive , paranoia dialed up to eleven ! also i feel like buying a @lexus :-) @all4 [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: <URL>", "index": 37033, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Given a conversation, a response to the conversation, and a score range, return a rating to the response within in score range\nInput: [CONTEXT] first episode of @handmaidsonhulu watched . creepy , oppressive , paranoia dialed up to eleven ! also i feel like buying a @lexus :-) @all4 [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: <URL>", "output": "1", "all_outputs": ["1.3"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] good morning ! how are you ? [ENDOFTURN] pretty good and yourself ? i like to try different coffees as a hobby [ENDOFTURN] great here ! just finished a cup of coffee . [ENDOFTURN] wow that's good . i also played football in college [ENDOFTURN] pretty cool ! i played volleyball in high school . [RESPONSE] i play college football , linebacker [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Select the right option: is the response is a good follow-up response? ", "index": 17616, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: In this task you will be shown a context followed by a response. You need to classify if the response is a good response to the context. \nInput: [CONTEXT] good morning ! how are you ? [ENDOFTURN] pretty good and yourself ? i like to try different coffees as a hobby [ENDOFTURN] great here ! just finished a cup of coffee . [ENDOFTURN] wow that's good . i also played football in college [ENDOFTURN] pretty cool ! i played volleyball in high school . [RESPONSE] i play college football , linebacker [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Select the right option: is the response is a good follow-up response? ", "output": "yes", "all_outputs": ["yes"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["good morning ! how are you ?", "pretty good and yourself ? i like to try different coffees as a hobby", "great here ! just finished a cup of coffee .", "wow that's good . i also played football in college", "pretty cool ! i played volleyball in high school ."], "response_list": ["i play college football , linebacker"], "metric_score": [{"USR-MLM": -1.5814741849899292}]}
{"input": "[CONTEXT] just gonna go get a redbox , some candy , and chill tonight [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: sounds like a great plan ! enjoy your movie night ! \u263a", "index": 20018, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Given a conversation, a response to the conversation, and a score range, return a rating to the response within in score range\nInput: [CONTEXT] just gonna go get a redbox , some candy , and chill tonight [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: sounds like a great plan ! enjoy your movie night ! \u263a", "output": "3", "all_outputs": ["4.8"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] til soviet composer dmitri shostakovich obsessive regularly sent cards test well postal service working. [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the informativeness to the following response: i m sure he was a pretty good guy.", "index": 39510, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Return a score in the provided range which scores the response to a conversation \nInput: [CONTEXT] til soviet composer dmitri shostakovich obsessive regularly sent cards test well postal service working. [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the informativeness to the following response: i m sure he was a pretty good guy.", "output": "i am sure he was", "all_outputs": ["2.3333333333333335"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] u guys have the most terrible internet in the country . i hope u r aware of that . u awesomely suck . [ENDOFTURN] quite unfortunate to hear this . may we know the exact challenge you are facing for further assistance . [ENDOFTURN] but u av made it intentionally very poor . so it frustrates one when it 's being used . i 'm on 3g n it can 't send a common message [ENDOFTURN] kindly confirm whether you are facing the challenge on your number that ends with 379 for further checks . [ENDOFTURN] yes that 's my number [RESPONSE] please dm your contact details to our service team @vodacom111 so they can look into this for you . [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response a good response to the provided dialogue context? ", "index": 33092, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: Select if the provided response follow the provided conversationSelect if the provided response a good response to the provided dialogue context.\nInput: [CONTEXT] u guys have the most terrible internet in the country . i hope u r aware of that . u awesomely suck . [ENDOFTURN] quite unfortunate to hear this . may we know the exact challenge you are facing for further assistance . [ENDOFTURN] but u av made it intentionally very poor . so it frustrates one when it 's being used . i 'm on 3g n it can 't send a common message [ENDOFTURN] kindly confirm whether you are facing the challenge on your number that ends with 379 for further checks . [ENDOFTURN] yes that 's my number [RESPONSE] please dm your contact details to our service team @vodacom111 so they can look into this for you . [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response a good response to the provided dialogue context? ", "output": "no", "all_outputs": ["yes"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["u guys have the most terrible internet in the country . i hope u r aware of that . u awesomely suck .", "quite unfortunate to hear this . may we know the exact challenge you are facing for further assistance .", "but u av made it intentionally very poor . so it frustrates one when it 's being used . i 'm on 3g n it can 't send a common message", "kindly confirm whether you are facing the challenge on your number that ends with 379 for further checks .", "yes that 's my number"], "response_list": ["please dm your contact details to our service team @vodacom111 so they can look into this for you ."], "metric_score": [{"USR-MLM": -2.974867343902588}]}
{"input": "[CONTEXT] so over your online ordering , i can never make an order and spend 30-40 minutes every time on the phone with cust serv , nothing ! i am sorry you are having issues placing an order , please give us a call so we can investigate why you are not able too . one of many non resolved calls to customer service , still waiting on the call back ! how exciting \ud83d\ude12 <URL> [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: i am sorry to hear this . please dm me your order number and i will be happy to look into this for you . thanks ,", "index": 49885, "split": "train", "dataset": "eval", "task": "eval_rating", "prompt": "Instruction: Given a conversation, a response to the conversation, and a score range, return a rating to the response within in score range\nInput: [CONTEXT] so over your online ordering , i can never make an order and spend 30-40 minutes every time on the phone with cust serv , nothing ! i am sorry you are having issues placing an order , please give us a call so we can investigate why you are not able too . one of many non resolved calls to customer service , still waiting on the call back ! how exciting \ud83d\ude12 <URL> [ENDOFDIALOGUE] [QUESTION] Please give a rating ranging from 1 to 5 about the overall to the following response: i am sorry to hear this . please dm me your order number and i will be happy to look into this for you . thanks ,", "output": "i will call you back later. thank you.", "all_outputs": ["1.9"], "classes_in_options": [], "candidates": [], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "dialogue_context": ["abc"], "response_list": ["xyz"], "metric_score": [{"USR-MLM": -1.7556592226028442}]}
{"input": "[CONTEXT] hi hof . are you aware trying to shop your website via a smartphone ( ios ) is such a challenging experience ? not trying to troll [RESPONSE] hi <USER> , i 'm sorry to hear this . can you please dm us with further details so we can look into this for you ? thanks . [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response a good response to the provided dialogue context? ", "index": 3410, "split": "train", "candidates": ["yes", "no"], "classes_in_options": ["yes", "no"], "dataset": "eval", "task": "eval_binary", "prompt": "Instruction: Given a conversation and a response to the conversation, select is the response is a good response to the context.\nInput: [CONTEXT] hi hof . are you aware trying to shop your website via a smartphone ( ios ) is such a challenging experience ? not trying to troll [RESPONSE] hi <USER> , i 'm sorry to hear this . can you please dm us with further details so we can look into this for you ? thanks . [ENDOFDIALOGUE] Answer Choices: [OPTIONS] yes||||no [QUESTION] Is the response a good response to the provided dialogue context? ", "output": "yes", "all_outputs": ["yes"], "metadata": {"context": [], "keywords": [], "knowledge": null, "beginswith": null, "persona": null, "endswith": null, "target": null, "domain": ""}, "text": "", "agent_name": "test", "dialogue_context": ["hi hof . are you aware trying to shop your website via a smartphone ( ios ) is such a challenging experience ? not trying to troll"], "response_list": ["hi <USER> , i 'm sorry to hear this . can you please dm us with further details so we can look into this for you ? thanks ."], "metric_score": [{"USR-MLM": -2.2514500617980957}]}
